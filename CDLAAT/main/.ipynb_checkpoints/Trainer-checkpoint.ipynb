{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1422ef97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "def _train_model(train_data, valid_data, test_data,saved_data_file_path=None,checkpoint_path=None):\n",
    "    model = model(vocab, args)\n",
    "    init_state_dict = None\n",
    "    if init_state_dict is not None:\n",
    "        model.load_state_dict(init_state_dict)\n",
    "    model.to(vocab.device)\n",
    "\n",
    "    train_dataset, valid_dataset, test_dataset = _load_and_cache_data(train_data, valid_data, test_data,\n",
    "                                                                      vocab, args, logger, saved_data_file_path)\n",
    "\n",
    "    logger.info(\"{} instances with {} tokens, {} in the train dataset\"\n",
    "                .format(train_dataset.size, train_dataset.n_total_tokens,\n",
    "                        \", \".join([\"Level_{} with {} labels\".format(level, len(train_dataset.labels[level]))\n",
    "                                   for level in range(vocab.n_level())])))\n",
    "\n",
    "    logger.info(\"{} instances with {} tokens, {} in the valid dataset\"\n",
    "                .format(valid_dataset.size, valid_dataset.n_total_tokens,\n",
    "                        \", \".join([\"Level_{} with {} labels\".format(level, len(valid_dataset.labels[level]))\n",
    "                                   for level in range(vocab.n_level())])))\n",
    "\n",
    "    logger.info(\"{} instances with {} tokens, {} in the test dataset\"\n",
    "                .format(test_dataset.size, test_dataset.n_total_tokens,\n",
    "                        \", \".join([\"Level_{} with {} labels\".format(level, len(test_dataset.labels[level]))\n",
    "                                   for level in range(vocab.n_level())])))\n",
    "\n",
    "    train_dataloader = TextDataLoader(dataset=train_dataset, vocab=vocab, batch_size=args.batch_size)\n",
    "\n",
    "    valid_dataloader = TextDataLoader(dataset=valid_dataset, vocab=vocab, batch_size=args.batch_size)\n",
    "\n",
    "    test_dataloader = TextDataLoader(dataset=test_dataset, vocab=vocab, batch_size=args.batch_size)\n",
    "\n",
    "    # Train the model\n",
    "    if args.optimiser.lower() == \"adagrad\":\n",
    "        optimiser = optim.Adagrad(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
    "    elif args.optimiser.lower() == \"adam\":\n",
    "        betas = (0.9, 0.999)\n",
    "        optimiser = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                               lr=args.lr, betas=betas, weight_decay=args.weight_decay)\n",
    "    elif args.optimiser.lower() == \"adamw\":\n",
    "        betas = (0.9, 0.999)\n",
    "        optimiser = AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                          lr=args.lr, betas=betas, weight_decay=args.weight_decay)\n",
    "    elif args.optimiser.lower() == \"sgd\":\n",
    "        optimiser = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                              lr=args.lr, momentum=0.9, weight_decay=args.weight_decay)\n",
    "    elif args.optimiser.lower() == \"adadelta\":\n",
    "        optimiser = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                   lr=args.lr, weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    lr_plateau = None\n",
    "    if args.use_lr_scheduler:\n",
    "        lr_plateau = optim.lr_scheduler.ReduceLROnPlateau(optimiser,\n",
    "                                                          mode=\"max\",\n",
    "                                                          factor=args.lr_scheduler_factor,\n",
    "                                                          patience=args.lr_scheduler_patience,\n",
    "                                                          min_lr=0.0001)\n",
    "    if args.multilabel:\n",
    "        criterions = [nn.BCEWithLogitsLoss() for _ in range(vocab.n_level())]\n",
    "    else:\n",
    "        criterions = [nn.CrossEntropyLoss() for _ in range(vocab.n_level())]\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      valid_dataloader=valid_dataloader,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      criterions=criterions,\n",
    "                      optimiser=optimiser,\n",
    "                      lr_scheduler=lr_plateau,\n",
    "                      vocab=vocab,\n",
    "                      logger=logger,\n",
    "                      args=args,\n",
    "                      checkpoint_path=checkpoint_path)\n",
    "    best_model, scores = trainer.train(n_epoch=args.n_epoch, patience=args.patience)\n",
    "\n",
    "    evaluator = Evaluator(model=best_model,\n",
    "                          vocab=vocab,\n",
    "                          criterions=criterions,\n",
    "                          n_training_labels=get_n_training_labels(train_dataloader))\n",
    "\n",
    "    del model, lr_plateau, optimiser, evaluator, trainer, criterions\n",
    "    return best_model, scores  # either on valid or test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7187b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module,\n",
    "                 train_dataloader: TextDataLoader,\n",
    "                 valid_dataloader: TextDataLoader,\n",
    "                 test_dataloader: TextDataLoader,\n",
    "                 criterions,\n",
    "                 optimiser,\n",
    "                 lr_scheduler,\n",
    "                 vocab,\n",
    "                 checkpoint_path,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        The initialisation model\n",
    "        :param model: The machine learning model\n",
    "        :param train_dataloader: Training dataloader\n",
    "        :param valid_dataloader: Validation dataloader\n",
    "        :param test_dataloader: Test dataloader\n",
    "        :param criterions: Criterion to generate loss\n",
    "        :param optimiser: Adam/AdamW ...\n",
    "        :param lr_scheduler: Reduce 10% of learning rate every 5 epochs\n",
    "        :param vocab: Vocabulary\n",
    "        :param logger:\n",
    "        :param args:\n",
    "        :param checkpoint_path: Path where the model is saved\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.criterions = criterions\n",
    "        self.optimiser = optimiser\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.vocab = vocab\n",
    "        self.args = args\n",
    "        self.save_best_model = save_best_model\n",
    "        self.use_regularisation = use_regularisation\n",
    "        self.penalisation_coeff = penalisation_coeff\n",
    "\n",
    "        self.multilabel = multilabel\n",
    "        self.save_results = save_results\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.n_training_labels = get_n_training_labels(train_dataloader)\n",
    "\n",
    "        if self.save_results:\n",
    "            self.saved_result_path = result_path\n",
    "        self.saved_last_model_path = None\n",
    "        if self.save_best_model:\n",
    "            self.best_model_path = best_model_path\n",
    "\n",
    "        saved_model_dir = os.path.dirname(self.best_model_path)\n",
    "        if not os.path.exists(saved_model_dir):\n",
    "            os.makedirs(saved_model_dir)\n",
    "\n",
    "        self.main_metric = main_metric\n",
    "        self.metric_level = \"level_{}\".format(metric_level)\n",
    "        if metric_level < 0:\n",
    "            self.metric_level = \"average\"\n",
    "\n",
    "        self.start_epoch = 0\n",
    "        self.best_val = None\n",
    "        self.saved_test_scores = None\n",
    "        self.best_epoch_num = 1\n",
    "\n",
    "    def train_single_epoch(self, index):\n",
    "        \"\"\"\n",
    "        This is to train a single epoch\n",
    "        :param index: epoch index\n",
    "        :return: scores\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "\n",
    "        if bool(self.args.shuffle_data):\n",
    "            self.train_dataloader.dataset.shuffle_data()\n",
    "        losses = []\n",
    "        true_labels = [[] for _ in range(self.vocab.n_level())]\n",
    "        pred_probs = [[] for _ in range(self.vocab.n_level())]\n",
    "        ids = []\n",
    "        all_loss_list = []\n",
    "        progress_bar = tqdm(self.train_dataloader, unit=\"batches\", desc=\"Training at epoch #{}\".format(index))\n",
    "        progress_bar.clear()\n",
    "        self.optimiser.zero_grad()\n",
    "        batch_id = 0\n",
    "\n",
    "        for text_batch, label_batch, length_batch, id_batch in progress_bar:\n",
    "            batch_id += 1\n",
    "            text_batch = text_batch.to(device)\n",
    "            for idx in range(len(label_batch)):\n",
    "                label_batch[idx] = label_batch[idx].to(device)\n",
    "\n",
    "            if type(length_batch) == list:\n",
    "                for i in range(len(length_batch)):\n",
    "                    length_batch[i] = length_batch[i].to(device)\n",
    "            else:\n",
    "                length_batch = length_batch.to(device)\n",
    "\n",
    "            output, attn_weights = self.model(text_batch, length_batch)\n",
    "            loss_list = []\n",
    "\n",
    "            for level in range(len(output)):\n",
    "                level_labels = label_batch[level]\n",
    "                true_labels[level].extend(level_labels.cpu().numpy())\n",
    "                loss_list.append(self.criterions[level](output[level], level_labels))\n",
    "\n",
    "            for level in range(len(loss_list)):\n",
    "                if len(all_loss_list) < len(loss_list):\n",
    "                    all_loss_list.append([loss_list[level].item()])\n",
    "                else:\n",
    "                    all_loss_list[level].append(loss_list[level].item())\n",
    "\n",
    "            ids.extend(id_batch)\n",
    "            for level in range(len(output)):\n",
    "                if self.multilabel:\n",
    "                    output[level] = torch.sigmoid(output[level])\n",
    "                    output[level] = output[level].detach().cpu().numpy()\n",
    "                    pred_probs[level].extend(output[level])\n",
    "                else:\n",
    "                    output[level] = torch.softmax(output[level], 1)\n",
    "                    output[level] = output[level].detach().cpu().numpy()\n",
    "                    pred_probs[level].extend(output[level].tolist())\n",
    "            loss = get_loss(loss_list, self.n_training_labels)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            self.optimiser.step()\n",
    "            self.optimiser.zero_grad()\n",
    "\n",
    "        scores = OrderedDict()\n",
    "        for level in range(len(output)):\n",
    "            if self.args.save_results_on_train:\n",
    "                scores[\"level_{}\".format(level)] = calculate_eval_metrics(ids, true_labels[level],\n",
    "                                                                          pred_probs[level], self.multilabel)\n",
    "            else:\n",
    "                scores[\"level_{}\".format(level)] = {}\n",
    "            scores[\"level_{}\".format(level)][\"loss\"] = -np.mean(all_loss_list[level]).item()\n",
    "\n",
    "        scores[\"average\"] = average_scores(scores)\n",
    "        scores[\"average\"][\"loss\"] = np.mean(losses).item()\n",
    "        progress_bar.refresh(True)\n",
    "        progress_bar.clear(True)\n",
    "        progress_bar.close()\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def calculate_penalisation(self, attn_weights, batch_size):\n",
    "        \"\"\"\n",
    "        This is the penalisation for the self attention\n",
    "        :param attn_weights:\n",
    "        :param batch_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        transposed_attn_weights = attn_weights.transpose(1, 2)\n",
    "        identity = torch.eye(attn_weights.size(1))\n",
    "        identity = Variable(identity.unsqueeze(0).expand(batch_size, attn_weights.size(1), attn_weights.size(1))).to(\n",
    "            device)\n",
    "        penal = AttentionLayer.l2_matrix_norm(attn_weights @ transposed_attn_weights - identity)\n",
    "        return penal\n",
    "\n",
    "    def save_checkpoint(self, state, is_best):\n",
    "        torch.save(state, self.checkpoint_path)\n",
    "        if is_best:\n",
    "            shutil.copyfile(self.checkpoint_path, self.best_model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def format_number(number):\n",
    "        return abs(round(number, ndigits=ndigits))\n",
    "\n",
    "    def train(self,\n",
    "              n_epoch: int = 100,\n",
    "              patience: int = 5):\n",
    "\n",
    "        if self.args.resume_training:\n",
    "            if os.path.isfile(self.checkpoint_path):\n",
    "                checkpoint = torch.load(self.checkpoint_path)\n",
    "                self.start_epoch = checkpoint['epoch']\n",
    "                self.best_val = checkpoint['best_val']\n",
    "                self.model.load_state_dict(checkpoint['state_dict'])\n",
    "                self.optimiser.load_state_dict(checkpoint['optimiser'])\n",
    "                self.saved_test_scores = checkpoint['test_scores']\n",
    "                self.best_epoch_num = checkpoint['best_epoch_num']\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "\n",
    "        best_valid_scores = self.best_val\n",
    "        saved_test_scores = self.saved_test_scores\n",
    "        saved_train_scores = None\n",
    "        check_to_stop = 0\n",
    "        best_epoch_num = self.best_epoch_num\n",
    "        # best_state_dict = None\n",
    "        evaluator = Evaluator(self.model, self.vocab, self.criterions, self.n_training_labels)\n",
    "        for e in range(self.start_epoch + 1, n_epoch + 1):\n",
    "            train_scores = self.train_single_epoch(e)\n",
    "            epoch_loss = train_scores[\"average\"][\"loss\"]\n",
    "            valid_scores = evaluator.evaluate(self.valid_dataloader)\n",
    "            test_scores = evaluator.evaluate(self.test_dataloader)\n",
    "\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step(valid_scores[self.metric_level][self.main_metric])\n",
    "\n",
    "            is_best = False\n",
    "            if best_valid_scores is None or best_valid_scores[self.metric_level][self.main_metric] < \\\n",
    "                    valid_scores[self.metric_level][self.main_metric]:\n",
    "                best_valid_scores = valid_scores\n",
    "                saved_test_scores = test_scores\n",
    "                saved_train_scores = train_scores\n",
    "                best_epoch_num = e\n",
    "                if self.save_best_model:\n",
    "                    is_best = True\n",
    "\n",
    "            lr_scheduler_state_dict = None\n",
    "            if self.lr_scheduler is not None:\n",
    "                lr_scheduler_state_dict = self.lr_scheduler.state_dict()\n",
    "\n",
    "            self.save_checkpoint({\n",
    "                'epoch': e,\n",
    "                'state_dict': self.model.state_dict(),\n",
    "                'best_val': best_valid_scores,\n",
    "                'test_scores': saved_test_scores,\n",
    "                'optimiser': self.optimiser.state_dict(),\n",
    "                'best_epoch_num': best_epoch_num,\n",
    "                'lr_scheduler': lr_scheduler_state_dict\n",
    "            }, is_best)\n",
    "\n",
    "            if check_to_stop > patience > 0:\n",
    "                break\n",
    "\n",
    "\n",
    "        if self.save_results:\n",
    "            import pickle\n",
    "            results = {\"train\": saved_train_scores, \"valid\": best_valid_scores, \"test\": saved_test_scores,\n",
    "                       \"params\": self.args, \"index2label\": self.vocab.index2label}\n",
    "\n",
    "            with open(self.saved_result_path, 'wb') as f:\n",
    "                pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        if self.save_best_model and os.path.isfile(self.best_model_path):\n",
    "            best_model = torch.load(self.best_model_path)\n",
    "            self.model.load_state_dict(best_model['state_dict'])\n",
    "        return self.model, best_valid_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
