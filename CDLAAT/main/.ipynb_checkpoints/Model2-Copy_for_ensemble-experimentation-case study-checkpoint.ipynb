{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5ef11f",
   "metadata": {},
   "source": [
    "# Unstructured Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9cb6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:51:47.646050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 18:51:49.947485: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rnn import RNN\n",
    "import torch.nn as nn\n",
    "from vocab import Vocab\n",
    "from torch import optim\n",
    "from util import *\n",
    "from constants import *\n",
    "from evaluator import Evaluator\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n",
    "from transformers import AdamW\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from embedding_layer import EmbeddingLayer\n",
    "from attention_layer import AttentionLayer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from dataloaders import TextDataLoader, TextDataset\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c726f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  6 18:51:59 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla M40 24GB      Off  | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   47C    P0    58W / 250W |  13026MiB / 22945MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla M40 24GB      Off  | 00000000:82:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P8    18W / 250W |      3MiB / 22945MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ca0316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5dfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path) -> list:\n",
    "    data = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "    id_data = data[id_col_name]\n",
    "    text_data = data[text_col_name]\n",
    "    hierarchical_label_data = []\n",
    "    label_data = data[label_col_name].tolist()\n",
    "    output = []\n",
    "    for i in tqdm(range(len(label_data)), desc=\"Reading data\"):\n",
    "        labels = label_data[i].split(';')\n",
    "        output.append((text_data[i], labels, id_data[i]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9c1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeldesc(file_path) -> list:\n",
    "    data = pd.read_csv(file_path)\n",
    "    desc_data = data[desc_col_name].tolist()\n",
    "    label_data = data[label_col_name].tolist()\n",
    "    output = []\n",
    "    for i in tqdm(range(len(label_data)), desc=\"Reading Label Descriptions\"):\n",
    "        output.append((label_data[i], desc_data[i]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07b35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached_data(file_path: str) -> tuple:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        f.close()\n",
    "    return data[\"vocab\"], data[\"training_data\"], data[\"valid_data\"], data[\"test_data\"],data[\"label_desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    cache_folder = \"{}/{}\".format(cache_dir, \"mimic3_single_32\")\n",
    "#     device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    save_vocab_file_name = \"{}.pkl\".format(\"save_vocab\")\n",
    "    cached_file_name = os.path.join(cache_folder, save_vocab_file_name)\n",
    "    if os.path.exists(cached_file_name):\n",
    "        vocab, training_data, valid_data, test_data, label_desc = load_cached_data(cached_file_name)\n",
    "        data = training_data + valid_data + test_data\n",
    "        labels = []\n",
    "        for (feature, l, _) in data:\n",
    "            labels.extend(l)\n",
    "        unique_labels=list(set(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "        labels = unique_labels\n",
    "        labels.extend(['I50.9', 'E78.5', 'E78.0'])\n",
    "        print(labels, len(labels))\n",
    "        vocab.update_labels(labels)\n",
    "        print(\"Loaded vocab and data from file\")\n",
    "    else:\n",
    "        training_data = read_data( data_dir + \"/ensemble_train_32.csv\")\n",
    "        valid_data = read_data( data_dir + \"/ensemble_dev_32.csv\")\n",
    "        test_data = read_data( data_dir + \"/ensemble_test_32.csv\")\n",
    "        label_desc = read_labeldesc(data_dir + \"/D_ICD_32.csv\")\n",
    "        data = training_data + valid_data + test_data\n",
    "        labels = []\n",
    "        for (feature, l, _) in data:\n",
    "            labels.extend(l)\n",
    "        unique_labels=list(set(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "        labels = unique_labels\n",
    "        labels.extend(['I50.9', 'E78.5', 'E78.0'])\n",
    "        print(labels, len(labels))\n",
    "        vocab = Vocab(data, labels,label_desc,min_word_frequency,\n",
    "                          word_embedding_mode=embedding_mode,\n",
    "                          word_embedding_file=embedding_file)\n",
    "        print(\"Preparing the vocab\")\n",
    "        vocab.prepare_vocab()\n",
    "        saved_objects = {\"vocab\": vocab,\n",
    "                         \"training_data\": training_data,\n",
    "                         \"valid_data\": valid_data,\n",
    "                         \"test_data\": test_data,\n",
    "                         \"label_desc\": label_desc}\n",
    "        with open(cached_file_name, 'wb') as f:\n",
    "            pickle.dump(saved_objects, f, pickle.HIGHEST_PROTOCOL)\n",
    "            f.close()\n",
    "        print(\"Saved vocab and data to files\")\n",
    "    return training_data, valid_data, test_data ,label_desc, vocab,cached_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8dcb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I10', 'J18.9', 'E66.01', 'N18.6', 'R65.21', 'I12.0', 'M81.0', 'G47.33', 'R65.20', 'F17.200', 'N17.9', 'F32.9', 'Z95.1', 'D62', 'N39.0', 'D64.9', 'Z79.4', 'E11.9', 'I48.91', 'E46', 'F05', 'E66.9', 'R56.9', 'D69.6', 'R78.81', 'Z87.891', 'J45.909', 'E03.9', 'I25.10', 'I50.9', 'E78.5', 'E78.0'] 32\n",
      "Loaded vocab and data from file\n"
     ]
    }
   ],
   "source": [
    "training_data, valid_data, test_data, label_desc, vocab, saved_vocab_path = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d85c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): EmbeddingLayer(\n",
       "    (embeddings): Embedding(89980, 100)\n",
       "  )\n",
       "  (label_linear): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (rnn): LSTM(100, 256, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (attention): AttentionLayer(\n",
       "    (first_linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (second_linear): Linear(in_features=256, out_features=32, bias=False)\n",
       "    (third_linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "  )\n",
       "  (classification_layer): Linear(in_features=256, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(vocab, device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e2041d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module,\n",
    "                 train_dataloader: TextDataLoader,\n",
    "                 valid_dataloader: TextDataLoader,\n",
    "                 test_dataloader: TextDataLoader,\n",
    "                 criterions,\n",
    "                 optimiser,\n",
    "                 scheduler,\n",
    "                 vocab,\n",
    "                 checkpoint_path,\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.criterions = criterions\n",
    "        self.optimiser = optimiser\n",
    "        self.scheduler = scheduler\n",
    "        self.vocab = vocab\n",
    "        self.multilabel = multilabel\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.n_training_labels = n_labels\n",
    "        self.saved_result_path = '../model/results_32.pkl'\n",
    "        self.main_metric = main_metric\n",
    "        self.start_epoch = 0\n",
    "        self.best_val = None\n",
    "        self.saved_test_scores = None\n",
    "        self.best_epoch_num = 1\n",
    "\n",
    "    def train_single_epoch(self, index):\n",
    "        self.model.train()\n",
    "        self.train_dataloader.dataset.shuffle_data()\n",
    "        losses = []\n",
    "        true_labels = []\n",
    "        pred_probs = []\n",
    "        ids = []\n",
    "        all_loss_list = []\n",
    "        progress_bar = tqdm(self.train_dataloader, unit=\"batches\", desc=\"Training at epoch #{}\".format(index))\n",
    "        progress_bar.clear()\n",
    "        self.optimiser.zero_grad()\n",
    "        batch_id = 0\n",
    "\n",
    "        for text_batch, label_batch, length_batch, id_batch, desc_batch in progress_bar:\n",
    "            batch_id += 1\n",
    "            text_batch = text_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            length_batch = length_batch.to(device)\n",
    "            desc_batch = desc_batch.to(device)\n",
    "            true_labels.extend(label_batch.cpu().numpy())\n",
    "            ids.extend(id_batch)\n",
    "            output = self.model(text_batch, length_batch,desc_batch)\n",
    "            loss_list = []\n",
    "            loss_list = self.criterions(output, label_batch)\n",
    "            all_loss_list.append([loss_list.item()])\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.detach().cpu().numpy()\n",
    "            pred_probs.extend(output)\n",
    "            loss = get_loss(loss_list, self.n_training_labels)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            self.optimiser.step()\n",
    "            self.optimiser.zero_grad()\n",
    "\n",
    "        scores = OrderedDict()\n",
    "        scores = calculate_eval_metrics(ids, true_labels,pred_probs, self.multilabel)\n",
    "        scores[\"loss\"] = np.mean(all_loss_list).item()\n",
    "        scores[\"average\"] = np.mean(losses).item()\n",
    "        progress_bar.refresh(True)\n",
    "        progress_bar.clear(True)\n",
    "        progress_bar.close()\n",
    "        keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1', 'macro_P@5', 'macro_P@8', 'macro_P@15', 'loss']\n",
    "        print({k:v for k,v in scores.items() if k in keys})\n",
    "        return scores\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def format_number(number):\n",
    "        return abs(round(number, ndigits=ndigits))\n",
    "\n",
    "    def train(self,n_epoch: int = 100):\n",
    "        best_valid_scores = self.best_val\n",
    "        saved_test_scores = self.saved_test_scores\n",
    "        saved_train_scores = None\n",
    "        best_epoch_num = self.best_epoch_num\n",
    "        evaluator = Evaluator(self.model, self.vocab, self.criterions, self.n_training_labels, device)\n",
    "        for e in range(self.start_epoch + 1, n_epoch + 1):\n",
    "            train_scores = self.train_single_epoch(e)\n",
    "            epoch_loss = train_scores[\"average\"]\n",
    "            valid_scores = evaluator.evaluate(self.valid_dataloader)\n",
    "            test_scores = evaluator.evaluate(self.test_dataloader)\n",
    "            self.scheduler.step(test_scores[\"average\"])\n",
    "            print('lr {}'.format(self.optimiser.param_groups[0]['lr']))\n",
    "            keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1', 'macro_P@5', 'macro_P@8', 'macro_P@15', 'loss']\n",
    "            print({k:v for k,v in test_scores.items() if k in keys})\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            if best_valid_scores is None or best_valid_scores[self.main_metric] < valid_scores[self.main_metric]:\n",
    "                best_valid_scores = valid_scores\n",
    "                saved_test_scores = test_scores\n",
    "                saved_train_scores = train_scores\n",
    "                best_epoch_num = e\n",
    "                \n",
    "\n",
    "                    \n",
    "        results = {\"train\": saved_train_scores, \"valid\": best_valid_scores, \"test\": saved_test_scores,\n",
    "                    \"index2label\": self.vocab.index2label}\n",
    "        with open(self.saved_result_path, 'wb') as f:\n",
    "            pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "        return self.model, best_valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b54069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_and_cache_data(train_data, valid_data, test_data, label_desc, vocab, saved_data_file_path):\n",
    "    if os.path.exists(saved_data_file_path):\n",
    "        try:\n",
    "            with open(saved_data_file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                data[\"train\"].multilabel = bool(multilabel)\n",
    "                data[\"valid\"].multilabel = bool(multilabel)\n",
    "                data[\"test\"].multilabel = bool(multilabel)\n",
    "\n",
    "                return data[\"train\"], data[\"valid\"], data[\"test\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Build train/valid/test data loaders\n",
    "    train_dataset = TextDataset(train_data, vocab, label_desc,max_seq_length=max_seq_length,min_seq_length=min_seq_length,sort=True,multilabel=multilabel)\n",
    "\n",
    "    valid_dataset = TextDataset(valid_data, vocab, label_desc,max_seq_length=max_seq_length,min_seq_length=min_seq_length,sort=True,multilabel=multilabel)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, vocab, label_desc,max_seq_length=max_seq_length,min_seq_length=min_seq_length,sort=True, multilabel=multilabel)\n",
    "    \n",
    "    # try:\n",
    "    with open(saved_data_file_path, 'wb') as f:\n",
    "        data = {\"train\": train_dataset, \"valid\": valid_dataset, \"test\": test_dataset}\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee0e163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_model(train_data, valid_data, test_data, label_desc, vocab, saved_data_file_path=None,checkpoint_path=None):\n",
    "    model = RNN(vocab,device)\n",
    "    init_state_dict = None\n",
    "    if init_state_dict is not None:\n",
    "        model.load_state_dict(init_state_dict)\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset, valid_dataset, test_dataset = _load_and_cache_data(train_data, valid_data, test_data, label_desc,\n",
    "                                                                      vocab, saved_data_file_path)\n",
    "    \n",
    "    train_dataloader = TextDataLoader(dataset=train_dataset, vocab=vocab, batch_size=batch_size)\n",
    "\n",
    "    valid_dataloader = TextDataLoader(dataset=valid_dataset, vocab=vocab, batch_size=batch_size)\n",
    "\n",
    "    test_dataloader = TextDataLoader(dataset=test_dataset, vocab=vocab, batch_size=batch_size)\n",
    "\n",
    "    optimiser = torch.optim.AdamW(model.parameters(), lr = 0.001)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', patience=1)\n",
    "    \n",
    "    criterions = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(2))\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      valid_dataloader=valid_dataloader,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      criterions=criterions,\n",
    "                      optimiser=optimiser,\n",
    "                      scheduler = scheduler,\n",
    "                      vocab=vocab,\n",
    "                      checkpoint_path=checkpoint_path)\n",
    "    best_model, scores = trainer.train(n_epoch=n_epoch)\n",
    "\n",
    "    evaluator = Evaluator(model=best_model,vocab=vocab,criterions=criterions,\n",
    "                          n_training_labels=n_labels,device = device)\n",
    "\n",
    "    del model, optimiser, evaluator, trainer, criterions\n",
    "    return best_model, scores  # either on valid or test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13164513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_validation(training_data, valid_data, test_data, label_desc, vocab, saved_data_file_path):\n",
    "    best_model, scores = _train_model(\n",
    "        train_data=training_data, valid_data=valid_data, test_data=test_data, label_desc=label_desc,\n",
    "        vocab=vocab, saved_data_file_path=saved_data_file_path, checkpoint_path=\"../model/checkpoint.pkl\")\n",
    "\n",
    "    return best_model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772dacdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best_model, scores = run_with_validation(training_data, valid_data, test_data, label_desc, vocab, saved_data_file_path=\"{}.data.pkl\".format(saved_vocab_path.split(\".pkl\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c271bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(obj = best_model.state_dict(), f = '../model/cdlaat32_for_ensemble.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82fbeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = RNN(vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4027d31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.load_state_dict(state_dict = torch.load(f = '../model/cdlaat32_for_ensemble.pth'))\n",
    "# loaded_model.load_state_dict(state_dict = torch.load(f = '../model/cdlaat32_for_ensemble.pth', map_location={'cuda:3':'cuda:1'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcdae47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): EmbeddingLayer(\n",
       "    (embeddings): Embedding(89980, 100)\n",
       "  )\n",
       "  (label_linear): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (rnn): LSTM(100, 256, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (attention): AttentionLayer(\n",
       "    (first_linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (second_linear): Linear(in_features=256, out_features=32, bias=False)\n",
       "    (third_linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "  )\n",
       "  (classification_layer): Linear(in_features=256, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc887e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434ca7d5471140deaa0fdccaea1fca4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/104 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset = _load_and_cache_data(training_data, valid_data, test_data, label_desc,\n",
    "                                                                      vocab, '{}.teshffhfhthvhdata.pkl')\n",
    "\n",
    "\n",
    "test_dataloader = TextDataLoader(dataset = test_dataset, vocab = vocab, batch_size = 32)\n",
    "\n",
    "criterions = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(2))\n",
    "evaluator = Evaluator(model = loaded_model, vocab = vocab, criterions = criterions,\n",
    "                          n_training_labels = 32, device = device)\n",
    "\n",
    "test_scores = evaluator.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e4c29f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3308, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores['pred_probs'] = np.array(test_scores['pred_probs'])\n",
    "test_scores['true_labels'] = np.array(test_scores['true_labels'])\n",
    "test_scores['pred_probs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9871590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting outputs according to increasing hadm ids\n",
    "# print(np.array(test_scores['true_labels']))\n",
    "test_scores['hadm_ids'] = np.array(test_scores['hadm_ids'])\n",
    "sort = np.argsort(test_scores['hadm_ids'])\n",
    "test_scores['hadm_ids'] = test_scores['hadm_ids'][sort]\n",
    "test_scores['true_labels'] = test_scores['true_labels'][sort]\n",
    "test_scores['pred_probs'] = test_scores['pred_probs'][sort]\n",
    "# print(test_scores['true_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47533c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/dev.csv')\n",
    "# train_ids_df = pd.read_csv('../../Structured/dev_final.csv')\n",
    "# train_ids = list(train_ids_df['HADM_ID'])\n",
    "# len(train_ids)\n",
    "# train_ensemble = df.loc[df['HADM_ID'].isin(train_ids)]\n",
    "# train_ensemble.to_csv('../data/ensemble_dev.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstruct_input = test_scores['pred_probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef53e89",
   "metadata": {},
   "source": [
    "# Strcutured Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94c38dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, jaccard_score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb9fee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9 = ['I10','I50.9','I48.91','I25.10','N17.9','E11.9','E78.5','N39.0','E78.0','D64.9','E03.9','J18.9','D62','R65.20','F32.9','F17.200','D69.6','Z95.1','Z87.891','I12.0','R65.21','Z79.4','G47.33','J45.909','M81.0','R56.9','N18.6','E66.9','R78.81','F05','E46','E66.01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b47ec784",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00a5dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('../data/dev_final_32.csv')\n",
    "# test_df = test_df.sort_values('HADM_ID')\n",
    "\n",
    "# df = pd.read_csv('../data/ensemble_dev_32.csv')\n",
    "# df = df.sort_values('HADM_ID')\n",
    "# df.to_csv('../data/ensemble_dev_32.csv', index = False)\n",
    "\n",
    "# test_df['ICD9_CODE'] = df['ICD9_CODE'].values\n",
    "\n",
    "# test_df.to_csv('../data/dev_final_32.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75e31b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_final_32.csv')\n",
    "train_dataset = train_df.to_dict('records')\n",
    "test_df = pd.read_csv('../data/test_final_32.csv')\n",
    "test_dataset = test_df.to_dict('records')\n",
    "\n",
    "dev_df = pd.read_csv('../data/dev_final_32.csv')\n",
    "dev_dataset = dev_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50146e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(dataset):\n",
    "# convert df icd9_codes column into one hot vector\n",
    "    for row in dataset:\n",
    "        labels = [0] * 32\n",
    "        codes = list(row['ICD9_CODE'].split(\";\"))\n",
    "        for i in range(len(codes)):\n",
    "            labels[icd9.index(codes[i])] = 1\n",
    "        row['ICD9_CODE'] = labels\n",
    "\n",
    "        # get list of features (lab events item ids) \n",
    "        keys = dataset[0].keys()\n",
    "        keys = list(keys)\n",
    "        keys.remove('SUBJECT_ID')\n",
    "        keys.remove('HADM_ID')\n",
    "        keys.remove('ICD9_CODE')\n",
    "\n",
    "    # Create dataset from df feature values\n",
    "    X = []\n",
    "    y = []\n",
    "    for row in dataset:\n",
    "        x = []\n",
    "        for key in keys:\n",
    "            x.append(row[key])\n",
    "        X.append(x)\n",
    "        y.append(row['ICD9_CODE'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b0e6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = generate_dataset(train_dataset)\n",
    "X_test, y_test = generate_dataset(test_dataset)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dffb2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11333, 1529) (3308, 1529) (11333, 32) (3308, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c48d7",
   "metadata": {},
   "source": [
    "# Random Forest Model for Structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bfc9212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(random_state=1,\n",
       "                                                       verbose=True))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=1, verbose = True)\n",
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs = 50)\n",
    "multi_target_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90c12517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_target_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m y_pred\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "y_pred = multi_target_forest.predict_proba(X_test)[:, 1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8745dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(y_pred)):\n",
    "    if y_pred[j].shape[1] == 1:\n",
    "        filler = np.ones((3308, 2))\n",
    "        for i in range(len(filler)):\n",
    "            filler[i][1] = 0\n",
    "        y_pred[j] = filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42dd94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "struct_input = y_pred[:, :, 1]\n",
    "struct_input = struct_input.T\n",
    "test_samples = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddece1",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5db5c019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              gpu_id=None, grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None, ...),\n",
       "                      n_jobs=50)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "gbm = XGBClassifier()\n",
    "multi_target_forest = MultiOutputClassifier(gbm, n_jobs = 50)\n",
    "multi_target_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7cf275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.9413113 , 0.05868872],\n",
       "        [0.9908961 , 0.00910389],\n",
       "        [0.9669882 , 0.03301181],\n",
       "        ...,\n",
       "        [0.9789772 , 0.02102278],\n",
       "        [0.98931396, 0.01068604],\n",
       "        [0.99434286, 0.00565715]], dtype=float32),\n",
       " array([[0.9724955 , 0.02750452],\n",
       "        [0.9798035 , 0.02019651],\n",
       "        [0.98114955, 0.01885042],\n",
       "        ...,\n",
       "        [0.8393789 , 0.16062112],\n",
       "        [0.8367856 , 0.16321439],\n",
       "        [0.84226865, 0.15773134]], dtype=float32),\n",
       " array([[0.99389374, 0.00610627],\n",
       "        [0.9878121 , 0.01218791],\n",
       "        [0.9961813 , 0.00381871],\n",
       "        ...,\n",
       "        [0.8953361 , 0.10466393],\n",
       "        [0.9865399 , 0.01346009],\n",
       "        [0.9673678 , 0.03263215]], dtype=float32),\n",
       " array([[9.9805456e-01, 1.9454419e-03],\n",
       "        [9.9488652e-01, 5.1134867e-03],\n",
       "        [1.4942241e-01, 8.5057759e-01],\n",
       "        ...,\n",
       "        [7.2512805e-01, 2.7487198e-01],\n",
       "        [9.9711764e-01, 2.8823318e-03],\n",
       "        [9.9964505e-01, 3.5495168e-04]], dtype=float32),\n",
       " array([[0.847027  , 0.152973  ],\n",
       "        [0.6984342 , 0.30156583],\n",
       "        [0.9831476 , 0.01685236],\n",
       "        ...,\n",
       "        [0.6700029 , 0.32999712],\n",
       "        [0.26771396, 0.73228604],\n",
       "        [0.82156974, 0.17843026]], dtype=float32),\n",
       " array([[0.9855252 , 0.01447479],\n",
       "        [0.9949874 , 0.00501258],\n",
       "        [0.99842083, 0.00157918],\n",
       "        ...,\n",
       "        [0.9968992 , 0.00310082],\n",
       "        [0.9988838 , 0.00111622],\n",
       "        [0.99715275, 0.00284724]], dtype=float32),\n",
       " array([[9.9013770e-01, 9.8623177e-03],\n",
       "        [9.9626833e-01, 3.7316598e-03],\n",
       "        [9.5516592e-01, 4.4834089e-02],\n",
       "        ...,\n",
       "        [9.9724960e-01, 2.7503802e-03],\n",
       "        [9.8763549e-01, 1.2364490e-02],\n",
       "        [9.9972057e-01, 2.7945117e-04]], dtype=float32),\n",
       " array([[0.9624468 , 0.03755318],\n",
       "        [0.9844372 , 0.0155628 ],\n",
       "        [0.9956733 , 0.00432668],\n",
       "        ...,\n",
       "        [0.9870625 , 0.0129375 ],\n",
       "        [0.97345126, 0.02654875],\n",
       "        [0.99025726, 0.00974273]], dtype=float32),\n",
       " array([[9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        ...,\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05]], dtype=float32),\n",
       " array([[9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        ...,\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05]], dtype=float32),\n",
       " array([[0.8282263 , 0.17177366],\n",
       "        [0.98593694, 0.01406307],\n",
       "        [0.9938027 , 0.00619724],\n",
       "        ...,\n",
       "        [0.9348244 , 0.06517557],\n",
       "        [0.9811488 , 0.0188512 ],\n",
       "        [0.9472743 , 0.0527257 ]], dtype=float32),\n",
       " array([[0.8834578 , 0.11654221],\n",
       "        [0.77077436, 0.2292256 ],\n",
       "        [0.9874759 , 0.01252412],\n",
       "        ...,\n",
       "        [0.942382  , 0.05761802],\n",
       "        [0.99706393, 0.00293604],\n",
       "        [0.76219845, 0.23780157]], dtype=float32),\n",
       " array([[0.97811854, 0.02188147],\n",
       "        [0.8804557 , 0.11954434],\n",
       "        [0.95884055, 0.04115945],\n",
       "        ...,\n",
       "        [0.9079776 , 0.09202243],\n",
       "        [0.50468266, 0.49531737],\n",
       "        [0.9955445 , 0.00445548]], dtype=float32),\n",
       " array([[9.6783388e-01, 3.2166094e-02],\n",
       "        [9.8772442e-01, 1.2275588e-02],\n",
       "        [7.1679270e-01, 2.8320733e-01],\n",
       "        ...,\n",
       "        [9.9234664e-01, 7.6533486e-03],\n",
       "        [7.8029144e-01, 2.1970856e-01],\n",
       "        [9.9966431e-01, 3.3567095e-04]], dtype=float32),\n",
       " array([[0.4396454 , 0.5603546 ],\n",
       "        [0.69058627, 0.30941373],\n",
       "        [0.33728755, 0.66271245],\n",
       "        ...,\n",
       "        [0.69337904, 0.30662093],\n",
       "        [0.96781933, 0.03218068],\n",
       "        [0.34747308, 0.6525269 ]], dtype=float32),\n",
       " array([[9.9983436e-01, 1.6564960e-04],\n",
       "        [9.9909705e-01, 9.0293784e-04],\n",
       "        [9.9919689e-01, 8.0310198e-04],\n",
       "        ...,\n",
       "        [9.9618924e-01, 3.8107452e-03],\n",
       "        [3.7719715e-01, 6.2280285e-01],\n",
       "        [9.9526775e-01, 4.7322325e-03]], dtype=float32),\n",
       " array([[0.8917682 , 0.10823181],\n",
       "        [0.7943585 , 0.20564148],\n",
       "        [0.77408123, 0.22591877],\n",
       "        ...,\n",
       "        [0.9276709 , 0.07232911],\n",
       "        [0.21310902, 0.786891  ],\n",
       "        [0.06922847, 0.9307715 ]], dtype=float32),\n",
       " array([[0.72603804, 0.27396196],\n",
       "        [0.8982918 , 0.10170817],\n",
       "        [0.01465797, 0.985342  ],\n",
       "        ...,\n",
       "        [0.9360897 , 0.06391028],\n",
       "        [0.11313891, 0.8868611 ],\n",
       "        [0.9538892 , 0.04611082]], dtype=float32),\n",
       " array([[9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        ...,\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05],\n",
       "        [9.9991930e-01, 8.0719714e-05]], dtype=float32),\n",
       " array([[0.98942256, 0.01057742],\n",
       "        [0.6469027 , 0.35309732],\n",
       "        [0.9864001 , 0.0135999 ],\n",
       "        ...,\n",
       "        [0.8413588 , 0.15864123],\n",
       "        [0.91166306, 0.08833695],\n",
       "        [0.98500705, 0.01499295]], dtype=float32),\n",
       " array([[0.9944006 , 0.00559939],\n",
       "        [0.9595446 , 0.0404554 ],\n",
       "        [0.9827384 , 0.01726162],\n",
       "        ...,\n",
       "        [0.9675285 , 0.03247146],\n",
       "        [0.9059371 , 0.09406291],\n",
       "        [0.98559755, 0.01440245]], dtype=float32),\n",
       " array([[0.9909732 , 0.00902683],\n",
       "        [0.9733239 , 0.02667613],\n",
       "        [0.94767267, 0.05232735],\n",
       "        ...,\n",
       "        [0.9799875 , 0.02001249],\n",
       "        [0.98787236, 0.01212763],\n",
       "        [0.99851346, 0.00148654]], dtype=float32),\n",
       " array([[0.8818244 , 0.11817564],\n",
       "        [0.9370009 , 0.06299911],\n",
       "        [0.9034372 , 0.09656281],\n",
       "        ...,\n",
       "        [0.5150013 , 0.48499873],\n",
       "        [0.9640858 , 0.03591419],\n",
       "        [0.9858574 , 0.01414255]], dtype=float32),\n",
       " array([[9.9995863e-01, 4.1352629e-05],\n",
       "        [9.9981612e-01, 1.8385152e-04],\n",
       "        [9.9989164e-01, 1.0836716e-04],\n",
       "        ...,\n",
       "        [9.9884576e-01, 1.1542334e-03],\n",
       "        [6.3683629e-02, 9.3631637e-01],\n",
       "        [9.9992388e-01, 7.6093987e-05]], dtype=float32),\n",
       " array([[0.9034027 , 0.09659734],\n",
       "        [0.79405737, 0.20594262],\n",
       "        [0.9507671 , 0.04923287],\n",
       "        ...,\n",
       "        [0.94836235, 0.05163768],\n",
       "        [0.755471  , 0.244529  ],\n",
       "        [0.5482592 , 0.4517408 ]], dtype=float32),\n",
       " array([[0.9987932 , 0.00120679],\n",
       "        [0.9793871 , 0.02061291],\n",
       "        [0.9952642 , 0.00473583],\n",
       "        ...,\n",
       "        [0.9880853 , 0.0119147 ],\n",
       "        [0.99881047, 0.00118954],\n",
       "        [0.99653304, 0.00346698]], dtype=float32),\n",
       " array([[0.9928018 , 0.00719821],\n",
       "        [0.9919192 , 0.0080808 ],\n",
       "        [0.99784034, 0.00215967],\n",
       "        ...,\n",
       "        [0.8080354 , 0.19196463],\n",
       "        [0.94940674, 0.05059328],\n",
       "        [0.9975452 , 0.0024548 ]], dtype=float32),\n",
       " array([[9.9236286e-01, 7.6371203e-03],\n",
       "        [9.9824041e-01, 1.7595909e-03],\n",
       "        [9.9782538e-01, 2.1746412e-03],\n",
       "        ...,\n",
       "        [9.2204463e-01, 7.7955358e-02],\n",
       "        [9.9561286e-01, 4.3871221e-03],\n",
       "        [9.9986476e-01, 1.3526464e-04]], dtype=float32),\n",
       " array([[0.99366915, 0.00633084],\n",
       "        [0.99223   , 0.00776998],\n",
       "        [0.9980255 , 0.00197455],\n",
       "        ...,\n",
       "        [0.67931473, 0.3206853 ],\n",
       "        [0.9963642 , 0.0036358 ],\n",
       "        [0.88453925, 0.11546075]], dtype=float32),\n",
       " array([[9.3531030e-01, 6.4689688e-02],\n",
       "        [9.3137026e-01, 6.8629757e-02],\n",
       "        [9.9955845e-01, 4.4153124e-04],\n",
       "        ...,\n",
       "        [8.6123681e-01, 1.3876319e-01],\n",
       "        [2.4450827e-01, 7.5549173e-01],\n",
       "        [9.9516958e-01, 4.8304461e-03]], dtype=float32),\n",
       " array([[0.99333376, 0.00666625],\n",
       "        [0.99281913, 0.00718089],\n",
       "        [0.9832085 , 0.01679154],\n",
       "        ...,\n",
       "        [0.9124521 , 0.08754788],\n",
       "        [0.91716665, 0.08283333],\n",
       "        [0.9731151 , 0.0268849 ]], dtype=float32),\n",
       " array([[0.9946633 , 0.00533672],\n",
       "        [0.9716315 , 0.02836848],\n",
       "        [0.97819024, 0.02180973],\n",
       "        ...,\n",
       "        [0.98122615, 0.01877383],\n",
       "        [0.8470483 , 0.1529517 ],\n",
       "        [0.9927342 , 0.0072658 ]], dtype=float32)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = multi_target_forest.predict_proba(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "617e4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(y_pred)):\n",
    "    if y_pred[j].shape[1] == 1:\n",
    "        filler = np.ones((3308, 2))\n",
    "        for i in range(len(filler)):\n",
    "            filler[i][1] = 0\n",
    "        y_pred[j] = filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7456332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "struct_input = y_pred[:, :, 1]\n",
    "struct_input = struct_input.T\n",
    "test_samples = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "630ff831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11333, 32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca4a462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>51498</th>\n",
       "      <th>51478</th>\n",
       "      <th>51301</th>\n",
       "      <th>51279</th>\n",
       "      <th>51277</th>\n",
       "      <th>51275</th>\n",
       "      <th>51274</th>\n",
       "      <th>...</th>\n",
       "      <th>Nystatin-Triamcinolone Cream</th>\n",
       "      <th>Phenytoin Sodium (IV)</th>\n",
       "      <th>Activated Charcoal-Sorbitol</th>\n",
       "      <th>5 Syringes (NS)</th>\n",
       "      <th>Amino Acids 4.25%-Dextrose 5%</th>\n",
       "      <th>rocuronium</th>\n",
       "      <th>Sodium Chloride 3% Inhalation Soln</th>\n",
       "      <th>Prazosin</th>\n",
       "      <th>300 mcg Vial</th>\n",
       "      <th>Syringe (Sterile Water)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>533</td>\n",
       "      <td>100009</td>\n",
       "      <td>D64.9;I25.10;I10;E66.9;E11.9;Z79.4;Z87.891</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87977</td>\n",
       "      <td>100011</td>\n",
       "      <td>D62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58128</td>\n",
       "      <td>100018</td>\n",
       "      <td>I25.10;E66.9;I48.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9973</td>\n",
       "      <td>100020</td>\n",
       "      <td>N17.9;F05;N39.0;I10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29971</td>\n",
       "      <td>100021</td>\n",
       "      <td>N39.0;I10;I48.91;D69.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11328</th>\n",
       "      <td>49225</td>\n",
       "      <td>199948</td>\n",
       "      <td>N39.0;F17.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11329</th>\n",
       "      <td>22711</td>\n",
       "      <td>199952</td>\n",
       "      <td>E11.9;E03.9;I10;I48.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11330</th>\n",
       "      <td>5478</td>\n",
       "      <td>199963</td>\n",
       "      <td>D64.9;N17.9;I25.10;I10;E11.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11331</th>\n",
       "      <td>20785</td>\n",
       "      <td>199993</td>\n",
       "      <td>I48.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11332</th>\n",
       "      <td>19412</td>\n",
       "      <td>199995</td>\n",
       "      <td>F17.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11333 rows  1532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID  HADM_ID                                   ICD9_CODE  51498  \\\n",
       "0             533   100009  D64.9;I25.10;I10;E66.9;E11.9;Z79.4;Z87.891      1   \n",
       "1           87977   100011                                         D62      1   \n",
       "2           58128   100018                         I25.10;E66.9;I48.91      1   \n",
       "3            9973   100020                         N17.9;F05;N39.0;I10      0   \n",
       "4           29971   100021                      N39.0;I10;I48.91;D69.6      1   \n",
       "...           ...      ...                                         ...    ...   \n",
       "11328       49225   199948                               N39.0;F17.200      1   \n",
       "11329       22711   199952                      E11.9;E03.9;I10;I48.91      1   \n",
       "11330        5478   199963                D64.9;N17.9;I25.10;I10;E11.9      1   \n",
       "11331       20785   199993                                      I48.91      1   \n",
       "11332       19412   199995                                     F17.200      1   \n",
       "\n",
       "       51478  51301  51279  51277  51275  51274  ...  \\\n",
       "0          1      1      1      1      0      1  ...   \n",
       "1          1      0      0      1      1      0  ...   \n",
       "2          1      1      0      1      1      0  ...   \n",
       "3          1      1      0      1      1      0  ...   \n",
       "4          1      1      0      1      1      0  ...   \n",
       "...      ...    ...    ...    ...    ...    ...  ...   \n",
       "11328      1      0      0      1      1      1  ...   \n",
       "11329      1      0      0      0      1      0  ...   \n",
       "11330      1      0      0      0      1      0  ...   \n",
       "11331      1      0      0      1      0      0  ...   \n",
       "11332      1      0      0      1      1      0  ...   \n",
       "\n",
       "       Nystatin-Triamcinolone Cream  Phenytoin Sodium (IV)  \\\n",
       "0                                 0                      0   \n",
       "1                                 0                      0   \n",
       "2                                 0                      0   \n",
       "3                                 0                      0   \n",
       "4                                 0                      0   \n",
       "...                             ...                    ...   \n",
       "11328                             0                      0   \n",
       "11329                             0                      0   \n",
       "11330                             0                      0   \n",
       "11331                             0                      0   \n",
       "11332                             0                      0   \n",
       "\n",
       "       Activated Charcoal-Sorbitol  5 Syringes (NS)  \\\n",
       "0                                0                0   \n",
       "1                                0                0   \n",
       "2                                0                0   \n",
       "3                                0                0   \n",
       "4                                0                0   \n",
       "...                            ...              ...   \n",
       "11328                            0                0   \n",
       "11329                            0                0   \n",
       "11330                            0                0   \n",
       "11331                            0                0   \n",
       "11332                            0                0   \n",
       "\n",
       "       Amino Acids 4.25%-Dextrose 5%  rocuronium  \\\n",
       "0                                  0           0   \n",
       "1                                  0           0   \n",
       "2                                  0           0   \n",
       "3                                  0           0   \n",
       "4                                  0           0   \n",
       "...                              ...         ...   \n",
       "11328                              0           0   \n",
       "11329                              0           0   \n",
       "11330                              0           0   \n",
       "11331                              0           0   \n",
       "11332                              0           0   \n",
       "\n",
       "       Sodium Chloride 3% Inhalation Soln  Prazosin  300 mcg Vial  \\\n",
       "0                                       0         0             0   \n",
       "1                                       0         0             0   \n",
       "2                                       0         0             0   \n",
       "3                                       0         0             0   \n",
       "4                                       0         0             0   \n",
       "...                                   ...       ...           ...   \n",
       "11328                                   0         0             0   \n",
       "11329                                   0         0             0   \n",
       "11330                                   0         0             0   \n",
       "11331                                   0         0             0   \n",
       "11332                                   0         0             0   \n",
       "\n",
       "       Syringe (Sterile Water)  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "11328                        0  \n",
       "11329                        0  \n",
       "11330                        0  \n",
       "11331                        0  \n",
       "11332                        0  \n",
       "\n",
       "[11333 rows x 1532 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9a744c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Features  Score\n",
      "0                                51498    NaN\n",
      "1                                51478    NaN\n",
      "2                                51301    NaN\n",
      "3                                51279    NaN\n",
      "4                                51277    NaN\n",
      "...                                ...    ...\n",
      "1495                          Colistin    NaN\n",
      "1496                          Adderall    NaN\n",
      "1497                       Fenofibrate    NaN\n",
      "1498  LaMIVudine-Zidovudine (Combivir)    NaN\n",
      "1499                         Moexipril    NaN\n",
      "\n",
      "[1500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "corr= numeric_bin.corr()\n",
    "corr_y = abs(corr['intrusion'])\n",
    "highest_corr = corr_y[corr_y >0.5]\n",
    "highest_corr.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19198c71",
   "metadata": {},
   "source": [
    "### gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86818ca0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/sklearn/multioutput.py\", line 41, in _fit_estimator\n    estimator.fit(X, y, **fit_params)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 423, in fit\n    y = self._validate_y(y, sample_weight)\n  File \"/home3/191it205/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 1107, in _validate_y\n    raise ValueError(\"y contains %d class after sample_weight \"\nValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [102], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m gbm \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier()\n\u001b[1;32m      4\u001b[0m multi_target_forest \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(gbm, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmulti_target_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/multioutput.py:368\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    self : object\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/multioutput.py:178\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier()\n",
    "multi_target_forest = MultiOutputClassifier(gbm, n_jobs = 50)\n",
    "multi_target_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c6b06a",
   "metadata": {},
   "source": [
    "# Basic Ensemble Model with linear weighing of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f7f1fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.0\n",
      "{'macro_f1': '0.56552', 'macro_auc': '0.90803', 'micro_f1': '0.69463', 'micro_auc': '0.94597'}\n",
      "\n",
      "\n",
      "aplha:  0.001\n",
      "{'macro_f1': '0.56559', 'macro_auc': '0.90814', 'micro_f1': '0.69471', 'micro_auc': '0.94604'}\n",
      "\n",
      "\n",
      "aplha:  0.002\n",
      "{'macro_f1': '0.56567', 'macro_auc': '0.90825', 'micro_f1': '0.69484', 'micro_auc': '0.94610'}\n",
      "\n",
      "\n",
      "aplha:  0.003\n",
      "{'macro_f1': '0.56576', 'macro_auc': '0.90835', 'micro_f1': '0.69497', 'micro_auc': '0.94616'}\n",
      "\n",
      "\n",
      "aplha:  0.004\n",
      "{'macro_f1': '0.56573', 'macro_auc': '0.90844', 'micro_f1': '0.69500', 'micro_auc': '0.94621'}\n",
      "\n",
      "\n",
      "aplha:  0.005\n",
      "{'macro_f1': '0.56595', 'macro_auc': '0.90853', 'micro_f1': '0.69526', 'micro_auc': '0.94627'}\n",
      "\n",
      "\n",
      "aplha:  0.006\n",
      "{'macro_f1': '0.56582', 'macro_auc': '0.90862', 'micro_f1': '0.69529', 'micro_auc': '0.94632'}\n",
      "\n",
      "\n",
      "aplha:  0.007\n",
      "{'macro_f1': '0.56537', 'macro_auc': '0.90870', 'micro_f1': '0.69527', 'micro_auc': '0.94637'}\n",
      "\n",
      "\n",
      "aplha:  0.008\n",
      "{'macro_f1': '0.56546', 'macro_auc': '0.90878', 'micro_f1': '0.69533', 'micro_auc': '0.94641'}\n",
      "\n",
      "\n",
      "aplha:  0.009000000000000001\n",
      "{'macro_f1': '0.56555', 'macro_auc': '0.90886', 'micro_f1': '0.69538', 'micro_auc': '0.94646'}\n",
      "\n",
      "\n",
      "aplha:  0.01\n",
      "{'macro_f1': '0.56565', 'macro_auc': '0.90892', 'micro_f1': '0.69546', 'micro_auc': '0.94650'}\n",
      "\n",
      "\n",
      "aplha:  0.011\n",
      "{'macro_f1': '0.56539', 'macro_auc': '0.90899', 'micro_f1': '0.69542', 'micro_auc': '0.94655'}\n",
      "\n",
      "\n",
      "aplha:  0.012\n",
      "{'macro_f1': '0.56557', 'macro_auc': '0.90907', 'micro_f1': '0.69560', 'micro_auc': '0.94659'}\n",
      "\n",
      "\n",
      "aplha:  0.013000000000000001\n",
      "{'macro_f1': '0.56492', 'macro_auc': '0.90913', 'micro_f1': '0.69548', 'micro_auc': '0.94663'}\n",
      "\n",
      "\n",
      "aplha:  0.014\n",
      "{'macro_f1': '0.56508', 'macro_auc': '0.90919', 'micro_f1': '0.69558', 'micro_auc': '0.94667'}\n",
      "\n",
      "\n",
      "aplha:  0.015\n",
      "{'macro_f1': '0.56515', 'macro_auc': '0.90925', 'micro_f1': '0.69572', 'micro_auc': '0.94670'}\n",
      "\n",
      "\n",
      "aplha:  0.016\n",
      "{'macro_f1': '0.56516', 'macro_auc': '0.90931', 'micro_f1': '0.69575', 'micro_auc': '0.94674'}\n",
      "\n",
      "\n",
      "aplha:  0.017\n",
      "{'macro_f1': '0.56512', 'macro_auc': '0.90937', 'micro_f1': '0.69566', 'micro_auc': '0.94678'}\n",
      "\n",
      "\n",
      "aplha:  0.018000000000000002\n",
      "{'macro_f1': '0.56518', 'macro_auc': '0.90942', 'micro_f1': '0.69571', 'micro_auc': '0.94681'}\n",
      "\n",
      "\n",
      "aplha:  0.019\n",
      "{'macro_f1': '0.56517', 'macro_auc': '0.90947', 'micro_f1': '0.69571', 'micro_auc': '0.94685'}\n",
      "\n",
      "\n",
      "aplha:  0.02\n",
      "{'macro_f1': '0.56502', 'macro_auc': '0.90952', 'micro_f1': '0.69572', 'micro_auc': '0.94688'}\n",
      "\n",
      "\n",
      "aplha:  0.021\n",
      "{'macro_f1': '0.56501', 'macro_auc': '0.90958', 'micro_f1': '0.69570', 'micro_auc': '0.94691'}\n",
      "\n",
      "\n",
      "aplha:  0.022\n",
      "{'macro_f1': '0.56486', 'macro_auc': '0.90963', 'micro_f1': '0.69568', 'micro_auc': '0.94694'}\n",
      "\n",
      "\n",
      "aplha:  0.023\n",
      "{'macro_f1': '0.56493', 'macro_auc': '0.90967', 'micro_f1': '0.69574', 'micro_auc': '0.94697'}\n",
      "\n",
      "\n",
      "aplha:  0.024\n",
      "{'macro_f1': '0.56498', 'macro_auc': '0.90971', 'micro_f1': '0.69577', 'micro_auc': '0.94700'}\n",
      "\n",
      "\n",
      "aplha:  0.025\n",
      "{'macro_f1': '0.56482', 'macro_auc': '0.90976', 'micro_f1': '0.69582', 'micro_auc': '0.94703'}\n",
      "\n",
      "\n",
      "aplha:  0.026000000000000002\n",
      "{'macro_f1': '0.56487', 'macro_auc': '0.90980', 'micro_f1': '0.69585', 'micro_auc': '0.94706'}\n",
      "\n",
      "\n",
      "aplha:  0.027\n",
      "{'macro_f1': '0.56502', 'macro_auc': '0.90985', 'micro_f1': '0.69593', 'micro_auc': '0.94709'}\n",
      "\n",
      "\n",
      "aplha:  0.028\n",
      "{'macro_f1': '0.56495', 'macro_auc': '0.90989', 'micro_f1': '0.69594', 'micro_auc': '0.94712'}\n",
      "\n",
      "\n",
      "aplha:  0.029\n",
      "{'macro_f1': '0.56491', 'macro_auc': '0.90993', 'micro_f1': '0.69590', 'micro_auc': '0.94714'}\n",
      "\n",
      "\n",
      "aplha:  0.03\n",
      "{'macro_f1': '0.56501', 'macro_auc': '0.90997', 'micro_f1': '0.69596', 'micro_auc': '0.94717'}\n",
      "\n",
      "\n",
      "aplha:  0.031\n",
      "{'macro_f1': '0.56498', 'macro_auc': '0.91000', 'micro_f1': '0.69599', 'micro_auc': '0.94720'}\n",
      "\n",
      "\n",
      "aplha:  0.032\n",
      "{'macro_f1': '0.56487', 'macro_auc': '0.91004', 'micro_f1': '0.69602', 'micro_auc': '0.94722'}\n",
      "\n",
      "\n",
      "aplha:  0.033\n",
      "{'macro_f1': '0.56484', 'macro_auc': '0.91008', 'micro_f1': '0.69599', 'micro_auc': '0.94725'}\n",
      "\n",
      "\n",
      "aplha:  0.034\n",
      "{'macro_f1': '0.56496', 'macro_auc': '0.91011', 'micro_f1': '0.69610', 'micro_auc': '0.94727'}\n",
      "\n",
      "\n",
      "aplha:  0.035\n",
      "{'macro_f1': '0.56516', 'macro_auc': '0.91014', 'micro_f1': '0.69626', 'micro_auc': '0.94729'}\n",
      "\n",
      "\n",
      "aplha:  0.036000000000000004\n",
      "{'macro_f1': '0.56503', 'macro_auc': '0.91018', 'micro_f1': '0.69627', 'micro_auc': '0.94732'}\n",
      "\n",
      "\n",
      "aplha:  0.037\n",
      "{'macro_f1': '0.56497', 'macro_auc': '0.91021', 'micro_f1': '0.69627', 'micro_auc': '0.94734'}\n",
      "\n",
      "\n",
      "aplha:  0.038\n",
      "{'macro_f1': '0.56501', 'macro_auc': '0.91024', 'micro_f1': '0.69638', 'micro_auc': '0.94736'}\n",
      "\n",
      "\n",
      "aplha:  0.039\n",
      "{'macro_f1': '0.56489', 'macro_auc': '0.91027', 'micro_f1': '0.69636', 'micro_auc': '0.94739'}\n",
      "\n",
      "\n",
      "aplha:  0.04\n",
      "{'macro_f1': '0.56480', 'macro_auc': '0.91030', 'micro_f1': '0.69639', 'micro_auc': '0.94741'}\n",
      "\n",
      "\n",
      "aplha:  0.041\n",
      "{'macro_f1': '0.56501', 'macro_auc': '0.91033', 'micro_f1': '0.69651', 'micro_auc': '0.94743'}\n",
      "\n",
      "\n",
      "aplha:  0.042\n",
      "{'macro_f1': '0.56483', 'macro_auc': '0.91037', 'micro_f1': '0.69651', 'micro_auc': '0.94745'}\n",
      "\n",
      "\n",
      "aplha:  0.043000000000000003\n",
      "{'macro_f1': '0.56501', 'macro_auc': '0.91040', 'micro_f1': '0.69659', 'micro_auc': '0.94747'}\n",
      "\n",
      "\n",
      "aplha:  0.044\n",
      "{'macro_f1': '0.56506', 'macro_auc': '0.91043', 'micro_f1': '0.69657', 'micro_auc': '0.94749'}\n",
      "\n",
      "\n",
      "aplha:  0.045\n",
      "{'macro_f1': '0.56455', 'macro_auc': '0.91046', 'micro_f1': '0.69663', 'micro_auc': '0.94751'}\n",
      "\n",
      "\n",
      "aplha:  0.046\n",
      "{'macro_f1': '0.56441', 'macro_auc': '0.91049', 'micro_f1': '0.69661', 'micro_auc': '0.94753'}\n",
      "\n",
      "\n",
      "aplha:  0.047\n",
      "{'macro_f1': '0.56417', 'macro_auc': '0.91052', 'micro_f1': '0.69643', 'micro_auc': '0.94755'}\n",
      "\n",
      "\n",
      "aplha:  0.048\n",
      "{'macro_f1': '0.56418', 'macro_auc': '0.91054', 'micro_f1': '0.69644', 'micro_auc': '0.94757'}\n",
      "\n",
      "\n",
      "aplha:  0.049\n",
      "{'macro_f1': '0.56430', 'macro_auc': '0.91057', 'micro_f1': '0.69655', 'micro_auc': '0.94759'}\n",
      "\n",
      "\n",
      "aplha:  0.05\n",
      "{'macro_f1': '0.56432', 'macro_auc': '0.91059', 'micro_f1': '0.69653', 'micro_auc': '0.94760'}\n",
      "\n",
      "\n",
      "aplha:  0.051000000000000004\n",
      "{'macro_f1': '0.56434', 'macro_auc': '0.91062', 'micro_f1': '0.69654', 'micro_auc': '0.94762'}\n",
      "\n",
      "\n",
      "aplha:  0.052000000000000005\n",
      "{'macro_f1': '0.56416', 'macro_auc': '0.91065', 'micro_f1': '0.69646', 'micro_auc': '0.94764'}\n",
      "\n",
      "\n",
      "aplha:  0.053\n",
      "{'macro_f1': '0.56344', 'macro_auc': '0.91067', 'micro_f1': '0.69634', 'micro_auc': '0.94766'}\n",
      "\n",
      "\n",
      "aplha:  0.054\n",
      "{'macro_f1': '0.56349', 'macro_auc': '0.91069', 'micro_f1': '0.69637', 'micro_auc': '0.94767'}\n",
      "\n",
      "\n",
      "aplha:  0.055\n",
      "{'macro_f1': '0.56363', 'macro_auc': '0.91072', 'micro_f1': '0.69638', 'micro_auc': '0.94769'}\n",
      "\n",
      "\n",
      "aplha:  0.056\n",
      "{'macro_f1': '0.56370', 'macro_auc': '0.91074', 'micro_f1': '0.69643', 'micro_auc': '0.94770'}\n",
      "\n",
      "\n",
      "aplha:  0.057\n",
      "{'macro_f1': '0.56381', 'macro_auc': '0.91076', 'micro_f1': '0.69649', 'micro_auc': '0.94772'}\n",
      "\n",
      "\n",
      "aplha:  0.058\n",
      "{'macro_f1': '0.56388', 'macro_auc': '0.91078', 'micro_f1': '0.69660', 'micro_auc': '0.94774'}\n",
      "\n",
      "\n",
      "aplha:  0.059000000000000004\n",
      "{'macro_f1': '0.56372', 'macro_auc': '0.91080', 'micro_f1': '0.69660', 'micro_auc': '0.94775'}\n",
      "\n",
      "\n",
      "aplha:  0.06\n",
      "{'macro_f1': '0.56370', 'macro_auc': '0.91082', 'micro_f1': '0.69651', 'micro_auc': '0.94777'}\n",
      "\n",
      "\n",
      "aplha:  0.061\n",
      "{'macro_f1': '0.56374', 'macro_auc': '0.91084', 'micro_f1': '0.69651', 'micro_auc': '0.94778'}\n",
      "\n",
      "\n",
      "aplha:  0.062\n",
      "{'macro_f1': '0.56360', 'macro_auc': '0.91086', 'micro_f1': '0.69649', 'micro_auc': '0.94780'}\n",
      "\n",
      "\n",
      "aplha:  0.063\n",
      "{'macro_f1': '0.56354', 'macro_auc': '0.91088', 'micro_f1': '0.69641', 'micro_auc': '0.94781'}\n",
      "\n",
      "\n",
      "aplha:  0.064\n",
      "{'macro_f1': '0.56329', 'macro_auc': '0.91091', 'micro_f1': '0.69639', 'micro_auc': '0.94782'}\n",
      "\n",
      "\n",
      "aplha:  0.065\n",
      "{'macro_f1': '0.56320', 'macro_auc': '0.91093', 'micro_f1': '0.69642', 'micro_auc': '0.94784'}\n",
      "\n",
      "\n",
      "aplha:  0.066\n",
      "{'macro_f1': '0.56297', 'macro_auc': '0.91095', 'micro_f1': '0.69637', 'micro_auc': '0.94785'}\n",
      "\n",
      "\n",
      "aplha:  0.067\n",
      "{'macro_f1': '0.56285', 'macro_auc': '0.91097', 'micro_f1': '0.69638', 'micro_auc': '0.94787'}\n",
      "\n",
      "\n",
      "aplha:  0.068\n",
      "{'macro_f1': '0.56282', 'macro_auc': '0.91099', 'micro_f1': '0.69638', 'micro_auc': '0.94788'}\n",
      "\n",
      "\n",
      "aplha:  0.069\n",
      "{'macro_f1': '0.56308', 'macro_auc': '0.91101', 'micro_f1': '0.69662', 'micro_auc': '0.94789'}\n",
      "\n",
      "\n",
      "aplha:  0.07\n",
      "{'macro_f1': '0.56327', 'macro_auc': '0.91102', 'micro_f1': '0.69681', 'micro_auc': '0.94790'}\n",
      "\n",
      "\n",
      "aplha:  0.07100000000000001\n",
      "{'macro_f1': '0.56258', 'macro_auc': '0.91104', 'micro_f1': '0.69671', 'micro_auc': '0.94792'}\n",
      "\n",
      "\n",
      "aplha:  0.07200000000000001\n",
      "{'macro_f1': '0.56247', 'macro_auc': '0.91106', 'micro_f1': '0.69664', 'micro_auc': '0.94793'}\n",
      "\n",
      "\n",
      "aplha:  0.073\n",
      "{'macro_f1': '0.56272', 'macro_auc': '0.91108', 'micro_f1': '0.69680', 'micro_auc': '0.94794'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.074\n",
      "{'macro_f1': '0.56257', 'macro_auc': '0.91109', 'micro_f1': '0.69680', 'micro_auc': '0.94795'}\n",
      "\n",
      "\n",
      "aplha:  0.075\n",
      "{'macro_f1': '0.56255', 'macro_auc': '0.91111', 'micro_f1': '0.69678', 'micro_auc': '0.94797'}\n",
      "\n",
      "\n",
      "aplha:  0.076\n",
      "{'macro_f1': '0.56242', 'macro_auc': '0.91113', 'micro_f1': '0.69666', 'micro_auc': '0.94798'}\n",
      "\n",
      "\n",
      "aplha:  0.077\n",
      "{'macro_f1': '0.56239', 'macro_auc': '0.91114', 'micro_f1': '0.69664', 'micro_auc': '0.94799'}\n",
      "\n",
      "\n",
      "aplha:  0.078\n",
      "{'macro_f1': '0.56230', 'macro_auc': '0.91116', 'micro_f1': '0.69651', 'micro_auc': '0.94800'}\n",
      "\n",
      "\n",
      "aplha:  0.079\n",
      "{'macro_f1': '0.56260', 'macro_auc': '0.91118', 'micro_f1': '0.69667', 'micro_auc': '0.94801'}\n",
      "\n",
      "\n",
      "aplha:  0.08\n",
      "{'macro_f1': '0.56254', 'macro_auc': '0.91120', 'micro_f1': '0.69668', 'micro_auc': '0.94802'}\n",
      "\n",
      "\n",
      "aplha:  0.081\n",
      "{'macro_f1': '0.56301', 'macro_auc': '0.91121', 'micro_f1': '0.69690', 'micro_auc': '0.94803'}\n",
      "\n",
      "\n",
      "aplha:  0.082\n",
      "{'macro_f1': '0.56298', 'macro_auc': '0.91123', 'micro_f1': '0.69688', 'micro_auc': '0.94804'}\n",
      "\n",
      "\n",
      "aplha:  0.083\n",
      "{'macro_f1': '0.56298', 'macro_auc': '0.91124', 'micro_f1': '0.69691', 'micro_auc': '0.94805'}\n",
      "\n",
      "\n",
      "aplha:  0.084\n",
      "{'macro_f1': '0.56303', 'macro_auc': '0.91126', 'micro_f1': '0.69694', 'micro_auc': '0.94806'}\n",
      "\n",
      "\n",
      "aplha:  0.085\n",
      "{'macro_f1': '0.56264', 'macro_auc': '0.91128', 'micro_f1': '0.69687', 'micro_auc': '0.94807'}\n",
      "\n",
      "\n",
      "aplha:  0.08600000000000001\n",
      "{'macro_f1': '0.56274', 'macro_auc': '0.91129', 'micro_f1': '0.69696', 'micro_auc': '0.94808'}\n",
      "\n",
      "\n",
      "aplha:  0.08700000000000001\n",
      "{'macro_f1': '0.56286', 'macro_auc': '0.91130', 'micro_f1': '0.69707', 'micro_auc': '0.94809'}\n",
      "\n",
      "\n",
      "aplha:  0.088\n",
      "{'macro_f1': '0.56288', 'macro_auc': '0.91132', 'micro_f1': '0.69719', 'micro_auc': '0.94810'}\n",
      "\n",
      "\n",
      "aplha:  0.089\n",
      "{'macro_f1': '0.56290', 'macro_auc': '0.91134', 'micro_f1': '0.69722', 'micro_auc': '0.94811'}\n",
      "\n",
      "\n",
      "aplha:  0.09\n",
      "{'macro_f1': '0.56269', 'macro_auc': '0.91135', 'micro_f1': '0.69709', 'micro_auc': '0.94812'}\n",
      "\n",
      "\n",
      "aplha:  0.091\n",
      "{'macro_f1': '0.56270', 'macro_auc': '0.91136', 'micro_f1': '0.69715', 'micro_auc': '0.94813'}\n",
      "\n",
      "\n",
      "aplha:  0.092\n",
      "{'macro_f1': '0.56286', 'macro_auc': '0.91138', 'micro_f1': '0.69731', 'micro_auc': '0.94814'}\n",
      "\n",
      "\n",
      "aplha:  0.093\n",
      "{'macro_f1': '0.56282', 'macro_auc': '0.91139', 'micro_f1': '0.69739', 'micro_auc': '0.94815'}\n",
      "\n",
      "\n",
      "aplha:  0.094\n",
      "{'macro_f1': '0.56265', 'macro_auc': '0.91140', 'micro_f1': '0.69735', 'micro_auc': '0.94815'}\n",
      "\n",
      "\n",
      "aplha:  0.095\n",
      "{'macro_f1': '0.56276', 'macro_auc': '0.91141', 'micro_f1': '0.69743', 'micro_auc': '0.94816'}\n",
      "\n",
      "\n",
      "aplha:  0.096\n",
      "{'macro_f1': '0.56286', 'macro_auc': '0.91142', 'micro_f1': '0.69751', 'micro_auc': '0.94817'}\n",
      "\n",
      "\n",
      "aplha:  0.097\n",
      "{'macro_f1': '0.56304', 'macro_auc': '0.91143', 'micro_f1': '0.69767', 'micro_auc': '0.94818'}\n",
      "\n",
      "\n",
      "aplha:  0.098\n",
      "{'macro_f1': '0.56300', 'macro_auc': '0.91144', 'micro_f1': '0.69774', 'micro_auc': '0.94819'}\n",
      "\n",
      "\n",
      "aplha:  0.099\n",
      "{'macro_f1': '0.56316', 'macro_auc': '0.91145', 'micro_f1': '0.69798', 'micro_auc': '0.94820'}\n",
      "\n",
      "\n",
      "aplha:  0.1\n",
      "{'macro_f1': '0.56361', 'macro_auc': '0.91146', 'micro_f1': '0.69825', 'micro_auc': '0.94820'}\n",
      "\n",
      "\n",
      "aplha:  0.101\n",
      "{'macro_f1': '0.56372', 'macro_auc': '0.91148', 'micro_f1': '0.69831', 'micro_auc': '0.94821'}\n",
      "\n",
      "\n",
      "aplha:  0.10200000000000001\n",
      "{'macro_f1': '0.56391', 'macro_auc': '0.91149', 'micro_f1': '0.69845', 'micro_auc': '0.94822'}\n",
      "\n",
      "\n",
      "aplha:  0.10300000000000001\n",
      "{'macro_f1': '0.56409', 'macro_auc': '0.91150', 'micro_f1': '0.69861', 'micro_auc': '0.94823'}\n",
      "\n",
      "\n",
      "aplha:  0.10400000000000001\n",
      "{'macro_f1': '0.56407', 'macro_auc': '0.91151', 'micro_f1': '0.69869', 'micro_auc': '0.94823'}\n",
      "\n",
      "\n",
      "aplha:  0.105\n",
      "{'macro_f1': '0.56381', 'macro_auc': '0.91152', 'micro_f1': '0.69855', 'micro_auc': '0.94824'}\n",
      "\n",
      "\n",
      "aplha:  0.106\n",
      "{'macro_f1': '0.56385', 'macro_auc': '0.91153', 'micro_f1': '0.69861', 'micro_auc': '0.94825'}\n",
      "\n",
      "\n",
      "aplha:  0.107\n",
      "{'macro_f1': '0.56391', 'macro_auc': '0.91154', 'micro_f1': '0.69859', 'micro_auc': '0.94825'}\n",
      "\n",
      "\n",
      "aplha:  0.108\n",
      "{'macro_f1': '0.56393', 'macro_auc': '0.91155', 'micro_f1': '0.69862', 'micro_auc': '0.94826'}\n",
      "\n",
      "\n",
      "aplha:  0.109\n",
      "{'macro_f1': '0.56397', 'macro_auc': '0.91156', 'micro_f1': '0.69868', 'micro_auc': '0.94827'}\n",
      "\n",
      "\n",
      "aplha:  0.11\n",
      "{'macro_f1': '0.56399', 'macro_auc': '0.91157', 'micro_f1': '0.69874', 'micro_auc': '0.94827'}\n",
      "\n",
      "\n",
      "aplha:  0.111\n",
      "{'macro_f1': '0.56379', 'macro_auc': '0.91158', 'micro_f1': '0.69870', 'micro_auc': '0.94828'}\n",
      "\n",
      "\n",
      "aplha:  0.112\n",
      "{'macro_f1': '0.56361', 'macro_auc': '0.91159', 'micro_f1': '0.69873', 'micro_auc': '0.94828'}\n",
      "\n",
      "\n",
      "aplha:  0.113\n",
      "{'macro_f1': '0.56356', 'macro_auc': '0.91160', 'micro_f1': '0.69871', 'micro_auc': '0.94829'}\n",
      "\n",
      "\n",
      "aplha:  0.114\n",
      "{'macro_f1': '0.56365', 'macro_auc': '0.91161', 'micro_f1': '0.69879', 'micro_auc': '0.94830'}\n",
      "\n",
      "\n",
      "aplha:  0.115\n",
      "{'macro_f1': '0.56380', 'macro_auc': '0.91162', 'micro_f1': '0.69882', 'micro_auc': '0.94830'}\n",
      "\n",
      "\n",
      "aplha:  0.116\n",
      "{'macro_f1': '0.56365', 'macro_auc': '0.91163', 'micro_f1': '0.69890', 'micro_auc': '0.94831'}\n",
      "\n",
      "\n",
      "aplha:  0.117\n",
      "{'macro_f1': '0.56374', 'macro_auc': '0.91164', 'micro_f1': '0.69893', 'micro_auc': '0.94831'}\n",
      "\n",
      "\n",
      "aplha:  0.11800000000000001\n",
      "{'macro_f1': '0.56341', 'macro_auc': '0.91165', 'micro_f1': '0.69878', 'micro_auc': '0.94832'}\n",
      "\n",
      "\n",
      "aplha:  0.11900000000000001\n",
      "{'macro_f1': '0.56326', 'macro_auc': '0.91166', 'micro_f1': '0.69878', 'micro_auc': '0.94832'}\n",
      "\n",
      "\n",
      "aplha:  0.12\n",
      "{'macro_f1': '0.56327', 'macro_auc': '0.91166', 'micro_f1': '0.69879', 'micro_auc': '0.94833'}\n",
      "\n",
      "\n",
      "aplha:  0.121\n",
      "{'macro_f1': '0.56319', 'macro_auc': '0.91167', 'micro_f1': '0.69880', 'micro_auc': '0.94833'}\n",
      "\n",
      "\n",
      "aplha:  0.122\n",
      "{'macro_f1': '0.56301', 'macro_auc': '0.91168', 'micro_f1': '0.69864', 'micro_auc': '0.94834'}\n",
      "\n",
      "\n",
      "aplha:  0.123\n",
      "{'macro_f1': '0.56306', 'macro_auc': '0.91169', 'micro_f1': '0.69873', 'micro_auc': '0.94834'}\n",
      "\n",
      "\n",
      "aplha:  0.124\n",
      "{'macro_f1': '0.56307', 'macro_auc': '0.91170', 'micro_f1': '0.69881', 'micro_auc': '0.94835'}\n",
      "\n",
      "\n",
      "aplha:  0.125\n",
      "{'macro_f1': '0.56308', 'macro_auc': '0.91170', 'micro_f1': '0.69887', 'micro_auc': '0.94835'}\n",
      "\n",
      "\n",
      "aplha:  0.126\n",
      "{'macro_f1': '0.56315', 'macro_auc': '0.91171', 'micro_f1': '0.69890', 'micro_auc': '0.94836'}\n",
      "\n",
      "\n",
      "aplha:  0.127\n",
      "{'macro_f1': '0.56303', 'macro_auc': '0.91172', 'micro_f1': '0.69888', 'micro_auc': '0.94836'}\n",
      "\n",
      "\n",
      "aplha:  0.128\n",
      "{'macro_f1': '0.56307', 'macro_auc': '0.91172', 'micro_f1': '0.69897', 'micro_auc': '0.94837'}\n",
      "\n",
      "\n",
      "aplha:  0.129\n",
      "{'macro_f1': '0.56350', 'macro_auc': '0.91173', 'micro_f1': '0.69911', 'micro_auc': '0.94837'}\n",
      "\n",
      "\n",
      "aplha:  0.13\n",
      "{'macro_f1': '0.56371', 'macro_auc': '0.91174', 'micro_f1': '0.69928', 'micro_auc': '0.94837'}\n",
      "\n",
      "\n",
      "aplha:  0.131\n",
      "{'macro_f1': '0.56368', 'macro_auc': '0.91174', 'micro_f1': '0.69926', 'micro_auc': '0.94838'}\n",
      "\n",
      "\n",
      "aplha:  0.132\n",
      "{'macro_f1': '0.56369', 'macro_auc': '0.91175', 'micro_f1': '0.69931', 'micro_auc': '0.94838'}\n",
      "\n",
      "\n",
      "aplha:  0.133\n",
      "{'macro_f1': '0.56379', 'macro_auc': '0.91176', 'micro_f1': '0.69940', 'micro_auc': '0.94839'}\n",
      "\n",
      "\n",
      "aplha:  0.134\n",
      "{'macro_f1': '0.56381', 'macro_auc': '0.91176', 'micro_f1': '0.69939', 'micro_auc': '0.94839'}\n",
      "\n",
      "\n",
      "aplha:  0.135\n",
      "{'macro_f1': '0.56389', 'macro_auc': '0.91177', 'micro_f1': '0.69943', 'micro_auc': '0.94839'}\n",
      "\n",
      "\n",
      "aplha:  0.136\n",
      "{'macro_f1': '0.56370', 'macro_auc': '0.91177', 'micro_f1': '0.69946', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.137\n",
      "{'macro_f1': '0.56392', 'macro_auc': '0.91178', 'micro_f1': '0.69957', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.138\n",
      "{'macro_f1': '0.56398', 'macro_auc': '0.91178', 'micro_f1': '0.69958', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.139\n",
      "{'macro_f1': '0.56403', 'macro_auc': '0.91179', 'micro_f1': '0.69960', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.14\n",
      "{'macro_f1': '0.56392', 'macro_auc': '0.91180', 'micro_f1': '0.69953', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.14100000000000001\n",
      "{'macro_f1': '0.56393', 'macro_auc': '0.91180', 'micro_f1': '0.69962', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.14200000000000002\n",
      "{'macro_f1': '0.56380', 'macro_auc': '0.91181', 'micro_f1': '0.69954', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.14300000000000002\n",
      "{'macro_f1': '0.56391', 'macro_auc': '0.91182', 'micro_f1': '0.69965', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.14400000000000002\n",
      "{'macro_f1': '0.56382', 'macro_auc': '0.91182', 'micro_f1': '0.69968', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.145\n",
      "{'macro_f1': '0.56384', 'macro_auc': '0.91182', 'micro_f1': '0.69969', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.146\n",
      "{'macro_f1': '0.56386', 'macro_auc': '0.91183', 'micro_f1': '0.69974', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.147\n",
      "{'macro_f1': '0.56398', 'macro_auc': '0.91183', 'micro_f1': '0.69977', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.148\n",
      "{'macro_f1': '0.56388', 'macro_auc': '0.91184', 'micro_f1': '0.69988', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.149\n",
      "{'macro_f1': '0.56413', 'macro_auc': '0.91184', 'micro_f1': '0.70013', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.15\n",
      "{'macro_f1': '0.56407', 'macro_auc': '0.91184', 'micro_f1': '0.70019', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.151\n",
      "{'macro_f1': '0.56376', 'macro_auc': '0.91185', 'micro_f1': '0.70020', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.152\n",
      "{'macro_f1': '0.56396', 'macro_auc': '0.91185', 'micro_f1': '0.70042', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.153\n",
      "{'macro_f1': '0.56385', 'macro_auc': '0.91185', 'micro_f1': '0.70046', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.154\n",
      "{'macro_f1': '0.56359', 'macro_auc': '0.91185', 'micro_f1': '0.70036', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.155\n",
      "{'macro_f1': '0.56368', 'macro_auc': '0.91185', 'micro_f1': '0.70042', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.156\n",
      "{'macro_f1': '0.56313', 'macro_auc': '0.91186', 'micro_f1': '0.70022', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.157\n",
      "{'macro_f1': '0.56303', 'macro_auc': '0.91186', 'micro_f1': '0.70026', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.158\n",
      "{'macro_f1': '0.56278', 'macro_auc': '0.91186', 'micro_f1': '0.70026', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.159\n",
      "{'macro_f1': '0.56253', 'macro_auc': '0.91187', 'micro_f1': '0.70014', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.16\n",
      "{'macro_f1': '0.56261', 'macro_auc': '0.91187', 'micro_f1': '0.70017', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.161\n",
      "{'macro_f1': '0.56280', 'macro_auc': '0.91188', 'micro_f1': '0.70026', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.162\n",
      "{'macro_f1': '0.56261', 'macro_auc': '0.91188', 'micro_f1': '0.70019', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.163\n",
      "{'macro_f1': '0.56267', 'macro_auc': '0.91189', 'micro_f1': '0.70024', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.164\n",
      "{'macro_f1': '0.56274', 'macro_auc': '0.91189', 'micro_f1': '0.70033', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.165\n",
      "{'macro_f1': '0.56257', 'macro_auc': '0.91189', 'micro_f1': '0.70024', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.166\n",
      "{'macro_f1': '0.56267', 'macro_auc': '0.91189', 'micro_f1': '0.70035', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.167\n",
      "{'macro_f1': '0.56283', 'macro_auc': '0.91190', 'micro_f1': '0.70049', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.168\n",
      "{'macro_f1': '0.56261', 'macro_auc': '0.91190', 'micro_f1': '0.70041', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.169\n",
      "{'macro_f1': '0.56264', 'macro_auc': '0.91190', 'micro_f1': '0.70044', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.17\n",
      "{'macro_f1': '0.56291', 'macro_auc': '0.91190', 'micro_f1': '0.70059', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.171\n",
      "{'macro_f1': '0.56294', 'macro_auc': '0.91190', 'micro_f1': '0.70068', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.17200000000000001\n",
      "{'macro_f1': '0.56284', 'macro_auc': '0.91190', 'micro_f1': '0.70063', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.17300000000000001\n",
      "{'macro_f1': '0.56296', 'macro_auc': '0.91191', 'micro_f1': '0.70072', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.17400000000000002\n",
      "{'macro_f1': '0.56289', 'macro_auc': '0.91191', 'micro_f1': '0.70072', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.17500000000000002\n",
      "{'macro_f1': '0.56277', 'macro_auc': '0.91191', 'micro_f1': '0.70068', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.176\n",
      "{'macro_f1': '0.56243', 'macro_auc': '0.91191', 'micro_f1': '0.70061', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.177\n",
      "{'macro_f1': '0.56237', 'macro_auc': '0.91192', 'micro_f1': '0.70065', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.178\n",
      "{'macro_f1': '0.56237', 'macro_auc': '0.91192', 'micro_f1': '0.70065', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.179\n",
      "{'macro_f1': '0.56238', 'macro_auc': '0.91192', 'micro_f1': '0.70060', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.18\n",
      "{'macro_f1': '0.56261', 'macro_auc': '0.91192', 'micro_f1': '0.70072', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.181\n",
      "{'macro_f1': '0.56243', 'macro_auc': '0.91192', 'micro_f1': '0.70062', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.182\n",
      "{'macro_f1': '0.56242', 'macro_auc': '0.91193', 'micro_f1': '0.70068', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.183\n",
      "{'macro_f1': '0.56241', 'macro_auc': '0.91193', 'micro_f1': '0.70061', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.184\n",
      "{'macro_f1': '0.56239', 'macro_auc': '0.91193', 'micro_f1': '0.70067', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.185\n",
      "{'macro_f1': '0.56205', 'macro_auc': '0.91193', 'micro_f1': '0.70052', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.186\n",
      "{'macro_f1': '0.56228', 'macro_auc': '0.91193', 'micro_f1': '0.70071', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.187\n",
      "{'macro_f1': '0.56209', 'macro_auc': '0.91193', 'micro_f1': '0.70067', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.188\n",
      "{'macro_f1': '0.56233', 'macro_auc': '0.91193', 'micro_f1': '0.70073', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.189\n",
      "{'macro_f1': '0.56222', 'macro_auc': '0.91193', 'micro_f1': '0.70079', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.19\n",
      "{'macro_f1': '0.56232', 'macro_auc': '0.91194', 'micro_f1': '0.70090', 'micro_auc': '0.94846'}\n",
      "\n",
      "\n",
      "aplha:  0.191\n",
      "{'macro_f1': '0.56165', 'macro_auc': '0.91194', 'micro_f1': '0.70080', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.192\n",
      "{'macro_f1': '0.56124', 'macro_auc': '0.91194', 'micro_f1': '0.70076', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.193\n",
      "{'macro_f1': '0.56099', 'macro_auc': '0.91195', 'micro_f1': '0.70077', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.194\n",
      "{'macro_f1': '0.56107', 'macro_auc': '0.91195', 'micro_f1': '0.70085', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.195\n",
      "{'macro_f1': '0.56115', 'macro_auc': '0.91194', 'micro_f1': '0.70099', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.196\n",
      "{'macro_f1': '0.56112', 'macro_auc': '0.91195', 'micro_f1': '0.70100', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.197\n",
      "{'macro_f1': '0.56120', 'macro_auc': '0.91195', 'micro_f1': '0.70098', 'micro_auc': '0.94845'}\n",
      "\n",
      "\n",
      "aplha:  0.198\n",
      "{'macro_f1': '0.56152', 'macro_auc': '0.91194', 'micro_f1': '0.70124', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.199\n",
      "{'macro_f1': '0.56118', 'macro_auc': '0.91194', 'micro_f1': '0.70109', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.2\n",
      "{'macro_f1': '0.56101', 'macro_auc': '0.91194', 'micro_f1': '0.70098', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.201\n",
      "{'macro_f1': '0.56109', 'macro_auc': '0.91194', 'micro_f1': '0.70115', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.202\n",
      "{'macro_f1': '0.56002', 'macro_auc': '0.91194', 'micro_f1': '0.70118', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.203\n",
      "{'macro_f1': '0.55999', 'macro_auc': '0.91194', 'micro_f1': '0.70116', 'micro_auc': '0.94844'}\n",
      "\n",
      "\n",
      "aplha:  0.20400000000000001\n",
      "{'macro_f1': '0.56019', 'macro_auc': '0.91194', 'micro_f1': '0.70138', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.20500000000000002\n",
      "{'macro_f1': '0.56008', 'macro_auc': '0.91194', 'micro_f1': '0.70133', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.20600000000000002\n",
      "{'macro_f1': '0.56008', 'macro_auc': '0.91194', 'micro_f1': '0.70129', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.20700000000000002\n",
      "{'macro_f1': '0.56014', 'macro_auc': '0.91194', 'micro_f1': '0.70135', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.20800000000000002\n",
      "{'macro_f1': '0.56032', 'macro_auc': '0.91194', 'micro_f1': '0.70146', 'micro_auc': '0.94843'}\n",
      "\n",
      "\n",
      "aplha:  0.209\n",
      "{'macro_f1': '0.56026', 'macro_auc': '0.91194', 'micro_f1': '0.70144', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.21\n",
      "{'macro_f1': '0.56015', 'macro_auc': '0.91194', 'micro_f1': '0.70140', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.211\n",
      "{'macro_f1': '0.55999', 'macro_auc': '0.91194', 'micro_f1': '0.70127', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.212\n",
      "{'macro_f1': '0.55936', 'macro_auc': '0.91194', 'micro_f1': '0.70118', 'micro_auc': '0.94842'}\n",
      "\n",
      "\n",
      "aplha:  0.213\n",
      "{'macro_f1': '0.55922', 'macro_auc': '0.91194', 'micro_f1': '0.70109', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.214\n",
      "{'macro_f1': '0.55954', 'macro_auc': '0.91194', 'micro_f1': '0.70136', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.215\n",
      "{'macro_f1': '0.55967', 'macro_auc': '0.91194', 'micro_f1': '0.70142', 'micro_auc': '0.94841'}\n",
      "\n",
      "\n",
      "aplha:  0.216\n",
      "{'macro_f1': '0.55960', 'macro_auc': '0.91194', 'micro_f1': '0.70146', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.217\n",
      "{'macro_f1': '0.55958', 'macro_auc': '0.91193', 'micro_f1': '0.70147', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.218\n",
      "{'macro_f1': '0.55931', 'macro_auc': '0.91193', 'micro_f1': '0.70129', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.219\n",
      "{'macro_f1': '0.55938', 'macro_auc': '0.91193', 'micro_f1': '0.70138', 'micro_auc': '0.94840'}\n",
      "\n",
      "\n",
      "aplha:  0.22\n",
      "{'macro_f1': '0.55929', 'macro_auc': '0.91193', 'micro_f1': '0.70136', 'micro_auc': '0.94839'}\n",
      "\n",
      "\n",
      "aplha:  0.221\n",
      "{'macro_f1': '0.55939', 'macro_auc': '0.91193', 'micro_f1': '0.70148', 'micro_auc': '0.94839'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.222\n",
      "{'macro_f1': '0.55949', 'macro_auc': '0.91193', 'micro_f1': '0.70154', 'micro_auc': '0.94839'}\n",
      "\n",
      "\n",
      "aplha:  0.223\n",
      "{'macro_f1': '0.55944', 'macro_auc': '0.91192', 'micro_f1': '0.70157', 'micro_auc': '0.94838'}\n",
      "\n",
      "\n",
      "aplha:  0.224\n",
      "{'macro_f1': '0.55928', 'macro_auc': '0.91192', 'micro_f1': '0.70171', 'micro_auc': '0.94838'}\n",
      "\n",
      "\n",
      "aplha:  0.225\n",
      "{'macro_f1': '0.55932', 'macro_auc': '0.91192', 'micro_f1': '0.70169', 'micro_auc': '0.94838'}\n",
      "\n",
      "\n",
      "aplha:  0.226\n",
      "{'macro_f1': '0.55933', 'macro_auc': '0.91192', 'micro_f1': '0.70175', 'micro_auc': '0.94837'}\n",
      "\n",
      "\n",
      "aplha:  0.227\n",
      "{'macro_f1': '0.55938', 'macro_auc': '0.91192', 'micro_f1': '0.70182', 'micro_auc': '0.94837'}\n",
      "\n",
      "\n",
      "aplha:  0.228\n",
      "{'macro_f1': '0.55951', 'macro_auc': '0.91191', 'micro_f1': '0.70183', 'micro_auc': '0.94837'}\n",
      "\n",
      "\n",
      "aplha:  0.229\n",
      "{'macro_f1': '0.55954', 'macro_auc': '0.91191', 'micro_f1': '0.70187', 'micro_auc': '0.94836'}\n",
      "\n",
      "\n",
      "aplha:  0.23\n",
      "{'macro_f1': '0.55914', 'macro_auc': '0.91191', 'micro_f1': '0.70190', 'micro_auc': '0.94836'}\n",
      "\n",
      "\n",
      "aplha:  0.231\n",
      "{'macro_f1': '0.55900', 'macro_auc': '0.91191', 'micro_f1': '0.70202', 'micro_auc': '0.94836'}\n",
      "\n",
      "\n",
      "aplha:  0.232\n",
      "{'macro_f1': '0.55910', 'macro_auc': '0.91191', 'micro_f1': '0.70214', 'micro_auc': '0.94835'}\n",
      "\n",
      "\n",
      "aplha:  0.233\n",
      "{'macro_f1': '0.55895', 'macro_auc': '0.91191', 'micro_f1': '0.70205', 'micro_auc': '0.94835'}\n",
      "\n",
      "\n",
      "aplha:  0.234\n",
      "{'macro_f1': '0.55853', 'macro_auc': '0.91190', 'micro_f1': '0.70187', 'micro_auc': '0.94834'}\n",
      "\n",
      "\n",
      "aplha:  0.23500000000000001\n",
      "{'macro_f1': '0.55831', 'macro_auc': '0.91190', 'micro_f1': '0.70162', 'micro_auc': '0.94834'}\n",
      "\n",
      "\n",
      "aplha:  0.23600000000000002\n",
      "{'macro_f1': '0.55919', 'macro_auc': '0.91190', 'micro_f1': '0.70165', 'micro_auc': '0.94833'}\n",
      "\n",
      "\n",
      "aplha:  0.23700000000000002\n",
      "{'macro_f1': '0.55865', 'macro_auc': '0.91190', 'micro_f1': '0.70153', 'micro_auc': '0.94833'}\n",
      "\n",
      "\n",
      "aplha:  0.23800000000000002\n",
      "{'macro_f1': '0.55840', 'macro_auc': '0.91189', 'micro_f1': '0.70127', 'micro_auc': '0.94833'}\n",
      "\n",
      "\n",
      "aplha:  0.23900000000000002\n",
      "{'macro_f1': '0.55792', 'macro_auc': '0.91189', 'micro_f1': '0.70109', 'micro_auc': '0.94832'}\n",
      "\n",
      "\n",
      "aplha:  0.24\n",
      "{'macro_f1': '0.55770', 'macro_auc': '0.91189', 'micro_f1': '0.70096', 'micro_auc': '0.94832'}\n",
      "\n",
      "\n",
      "aplha:  0.241\n",
      "{'macro_f1': '0.55813', 'macro_auc': '0.91189', 'micro_f1': '0.70122', 'micro_auc': '0.94831'}\n",
      "\n",
      "\n",
      "aplha:  0.242\n",
      "{'macro_f1': '0.55822', 'macro_auc': '0.91188', 'micro_f1': '0.70130', 'micro_auc': '0.94831'}\n",
      "\n",
      "\n",
      "aplha:  0.243\n",
      "{'macro_f1': '0.55782', 'macro_auc': '0.91188', 'micro_f1': '0.70144', 'micro_auc': '0.94830'}\n",
      "\n",
      "\n",
      "aplha:  0.244\n",
      "{'macro_f1': '0.55775', 'macro_auc': '0.91187', 'micro_f1': '0.70134', 'micro_auc': '0.94830'}\n",
      "\n",
      "\n",
      "aplha:  0.245\n",
      "{'macro_f1': '0.55790', 'macro_auc': '0.91186', 'micro_f1': '0.70144', 'micro_auc': '0.94829'}\n",
      "\n",
      "\n",
      "aplha:  0.246\n",
      "{'macro_f1': '0.55720', 'macro_auc': '0.91186', 'micro_f1': '0.70116', 'micro_auc': '0.94829'}\n",
      "\n",
      "\n",
      "aplha:  0.247\n",
      "{'macro_f1': '0.55685', 'macro_auc': '0.91186', 'micro_f1': '0.70097', 'micro_auc': '0.94828'}\n",
      "\n",
      "\n",
      "aplha:  0.248\n",
      "{'macro_f1': '0.55677', 'macro_auc': '0.91186', 'micro_f1': '0.70107', 'micro_auc': '0.94828'}\n",
      "\n",
      "\n",
      "aplha:  0.249\n",
      "{'macro_f1': '0.55696', 'macro_auc': '0.91186', 'micro_f1': '0.70118', 'micro_auc': '0.94827'}\n",
      "\n",
      "\n",
      "aplha:  0.25\n",
      "{'macro_f1': '0.55671', 'macro_auc': '0.91185', 'micro_f1': '0.70098', 'micro_auc': '0.94827'}\n",
      "\n",
      "\n",
      "aplha:  0.251\n",
      "{'macro_f1': '0.55670', 'macro_auc': '0.91185', 'micro_f1': '0.70095', 'micro_auc': '0.94826'}\n",
      "\n",
      "\n",
      "aplha:  0.252\n",
      "{'macro_f1': '0.55657', 'macro_auc': '0.91185', 'micro_f1': '0.70093', 'micro_auc': '0.94826'}\n",
      "\n",
      "\n",
      "aplha:  0.253\n",
      "{'macro_f1': '0.55624', 'macro_auc': '0.91184', 'micro_f1': '0.70088', 'micro_auc': '0.94825'}\n",
      "\n",
      "\n",
      "aplha:  0.254\n",
      "{'macro_f1': '0.55608', 'macro_auc': '0.91184', 'micro_f1': '0.70081', 'micro_auc': '0.94825'}\n",
      "\n",
      "\n",
      "aplha:  0.255\n",
      "{'macro_f1': '0.55617', 'macro_auc': '0.91184', 'micro_f1': '0.70082', 'micro_auc': '0.94824'}\n",
      "\n",
      "\n",
      "aplha:  0.256\n",
      "{'macro_f1': '0.55601', 'macro_auc': '0.91183', 'micro_f1': '0.70080', 'micro_auc': '0.94824'}\n",
      "\n",
      "\n",
      "aplha:  0.257\n",
      "{'macro_f1': '0.55575', 'macro_auc': '0.91183', 'micro_f1': '0.70081', 'micro_auc': '0.94823'}\n",
      "\n",
      "\n",
      "aplha:  0.258\n",
      "{'macro_f1': '0.55549', 'macro_auc': '0.91182', 'micro_f1': '0.70076', 'micro_auc': '0.94823'}\n",
      "\n",
      "\n",
      "aplha:  0.259\n",
      "{'macro_f1': '0.55457', 'macro_auc': '0.91182', 'micro_f1': '0.70071', 'micro_auc': '0.94822'}\n",
      "\n",
      "\n",
      "aplha:  0.26\n",
      "{'macro_f1': '0.55481', 'macro_auc': '0.91181', 'micro_f1': '0.70080', 'micro_auc': '0.94821'}\n",
      "\n",
      "\n",
      "aplha:  0.261\n",
      "{'macro_f1': '0.55479', 'macro_auc': '0.91181', 'micro_f1': '0.70065', 'micro_auc': '0.94821'}\n",
      "\n",
      "\n",
      "aplha:  0.262\n",
      "{'macro_f1': '0.55455', 'macro_auc': '0.91180', 'micro_f1': '0.70069', 'micro_auc': '0.94820'}\n",
      "\n",
      "\n",
      "aplha:  0.263\n",
      "{'macro_f1': '0.55441', 'macro_auc': '0.91180', 'micro_f1': '0.70056', 'micro_auc': '0.94820'}\n",
      "\n",
      "\n",
      "aplha:  0.264\n",
      "{'macro_f1': '0.55401', 'macro_auc': '0.91179', 'micro_f1': '0.70052', 'micro_auc': '0.94819'}\n",
      "\n",
      "\n",
      "aplha:  0.265\n",
      "{'macro_f1': '0.55384', 'macro_auc': '0.91179', 'micro_f1': '0.70042', 'micro_auc': '0.94818'}\n",
      "\n",
      "\n",
      "aplha:  0.266\n",
      "{'macro_f1': '0.55367', 'macro_auc': '0.91178', 'micro_f1': '0.70040', 'micro_auc': '0.94818'}\n",
      "\n",
      "\n",
      "aplha:  0.267\n",
      "{'macro_f1': '0.55356', 'macro_auc': '0.91178', 'micro_f1': '0.70036', 'micro_auc': '0.94817'}\n",
      "\n",
      "\n",
      "aplha:  0.268\n",
      "{'macro_f1': '0.55345', 'macro_auc': '0.91177', 'micro_f1': '0.70034', 'micro_auc': '0.94816'}\n",
      "\n",
      "\n",
      "aplha:  0.269\n",
      "{'macro_f1': '0.55386', 'macro_auc': '0.91177', 'micro_f1': '0.70065', 'micro_auc': '0.94816'}\n",
      "\n",
      "\n",
      "aplha:  0.27\n",
      "{'macro_f1': '0.55377', 'macro_auc': '0.91177', 'micro_f1': '0.70063', 'micro_auc': '0.94815'}\n",
      "\n",
      "\n",
      "aplha:  0.271\n",
      "{'macro_f1': '0.55440', 'macro_auc': '0.91176', 'micro_f1': '0.70086', 'micro_auc': '0.94815'}\n",
      "\n",
      "\n",
      "aplha:  0.272\n",
      "{'macro_f1': '0.55446', 'macro_auc': '0.91176', 'micro_f1': '0.70099', 'micro_auc': '0.94814'}\n",
      "\n",
      "\n",
      "aplha:  0.273\n",
      "{'macro_f1': '0.55458', 'macro_auc': '0.91175', 'micro_f1': '0.70108', 'micro_auc': '0.94813'}\n",
      "\n",
      "\n",
      "aplha:  0.274\n",
      "{'macro_f1': '0.55443', 'macro_auc': '0.91174', 'micro_f1': '0.70108', 'micro_auc': '0.94812'}\n",
      "\n",
      "\n",
      "aplha:  0.275\n",
      "{'macro_f1': '0.55381', 'macro_auc': '0.91174', 'micro_f1': '0.70112', 'micro_auc': '0.94812'}\n",
      "\n",
      "\n",
      "aplha:  0.276\n",
      "{'macro_f1': '0.55396', 'macro_auc': '0.91174', 'micro_f1': '0.70119', 'micro_auc': '0.94811'}\n",
      "\n",
      "\n",
      "aplha:  0.277\n",
      "{'macro_f1': '0.55389', 'macro_auc': '0.91173', 'micro_f1': '0.70111', 'micro_auc': '0.94810'}\n",
      "\n",
      "\n",
      "aplha:  0.278\n",
      "{'macro_f1': '0.55385', 'macro_auc': '0.91173', 'micro_f1': '0.70110', 'micro_auc': '0.94810'}\n",
      "\n",
      "\n",
      "aplha:  0.279\n",
      "{'macro_f1': '0.55380', 'macro_auc': '0.91172', 'micro_f1': '0.70116', 'micro_auc': '0.94809'}\n",
      "\n",
      "\n",
      "aplha:  0.28\n",
      "{'macro_f1': '0.55390', 'macro_auc': '0.91172', 'micro_f1': '0.70118', 'micro_auc': '0.94808'}\n",
      "\n",
      "\n",
      "aplha:  0.281\n",
      "{'macro_f1': '0.55343', 'macro_auc': '0.91171', 'micro_f1': '0.70089', 'micro_auc': '0.94808'}\n",
      "\n",
      "\n",
      "aplha:  0.28200000000000003\n",
      "{'macro_f1': '0.55311', 'macro_auc': '0.91171', 'micro_f1': '0.70076', 'micro_auc': '0.94807'}\n",
      "\n",
      "\n",
      "aplha:  0.28300000000000003\n",
      "{'macro_f1': '0.55315', 'macro_auc': '0.91170', 'micro_f1': '0.70085', 'micro_auc': '0.94806'}\n",
      "\n",
      "\n",
      "aplha:  0.28400000000000003\n",
      "{'macro_f1': '0.55315', 'macro_auc': '0.91169', 'micro_f1': '0.70076', 'micro_auc': '0.94805'}\n",
      "\n",
      "\n",
      "aplha:  0.28500000000000003\n",
      "{'macro_f1': '0.55312', 'macro_auc': '0.91169', 'micro_f1': '0.70077', 'micro_auc': '0.94805'}\n",
      "\n",
      "\n",
      "aplha:  0.28600000000000003\n",
      "{'macro_f1': '0.55290', 'macro_auc': '0.91168', 'micro_f1': '0.70070', 'micro_auc': '0.94804'}\n",
      "\n",
      "\n",
      "aplha:  0.28700000000000003\n",
      "{'macro_f1': '0.55286', 'macro_auc': '0.91167', 'micro_f1': '0.70076', 'micro_auc': '0.94803'}\n",
      "\n",
      "\n",
      "aplha:  0.28800000000000003\n",
      "{'macro_f1': '0.55302', 'macro_auc': '0.91166', 'micro_f1': '0.70082', 'micro_auc': '0.94802'}\n",
      "\n",
      "\n",
      "aplha:  0.289\n",
      "{'macro_f1': '0.55307', 'macro_auc': '0.91166', 'micro_f1': '0.70083', 'micro_auc': '0.94802'}\n",
      "\n",
      "\n",
      "aplha:  0.29\n",
      "{'macro_f1': '0.55321', 'macro_auc': '0.91165', 'micro_f1': '0.70085', 'micro_auc': '0.94801'}\n",
      "\n",
      "\n",
      "aplha:  0.291\n",
      "{'macro_f1': '0.55284', 'macro_auc': '0.91164', 'micro_f1': '0.70081', 'micro_auc': '0.94800'}\n",
      "\n",
      "\n",
      "aplha:  0.292\n",
      "{'macro_f1': '0.55274', 'macro_auc': '0.91163', 'micro_f1': '0.70084', 'micro_auc': '0.94799'}\n",
      "\n",
      "\n",
      "aplha:  0.293\n",
      "{'macro_f1': '0.55273', 'macro_auc': '0.91162', 'micro_f1': '0.70087', 'micro_auc': '0.94798'}\n",
      "\n",
      "\n",
      "aplha:  0.294\n",
      "{'macro_f1': '0.55263', 'macro_auc': '0.91162', 'micro_f1': '0.70097', 'micro_auc': '0.94798'}\n",
      "\n",
      "\n",
      "aplha:  0.295\n",
      "{'macro_f1': '0.55265', 'macro_auc': '0.91161', 'micro_f1': '0.70087', 'micro_auc': '0.94797'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.296\n",
      "{'macro_f1': '0.55244', 'macro_auc': '0.91160', 'micro_f1': '0.70091', 'micro_auc': '0.94796'}\n",
      "\n",
      "\n",
      "aplha:  0.297\n",
      "{'macro_f1': '0.55261', 'macro_auc': '0.91159', 'micro_f1': '0.70098', 'micro_auc': '0.94795'}\n",
      "\n",
      "\n",
      "aplha:  0.298\n",
      "{'macro_f1': '0.55292', 'macro_auc': '0.91159', 'micro_f1': '0.70110', 'micro_auc': '0.94794'}\n",
      "\n",
      "\n",
      "aplha:  0.299\n",
      "{'macro_f1': '0.55265', 'macro_auc': '0.91158', 'micro_f1': '0.70112', 'micro_auc': '0.94793'}\n",
      "\n",
      "\n",
      "aplha:  0.3\n",
      "{'macro_f1': '0.55244', 'macro_auc': '0.91157', 'micro_f1': '0.70110', 'micro_auc': '0.94793'}\n",
      "\n",
      "\n",
      "aplha:  0.301\n",
      "{'macro_f1': '0.55261', 'macro_auc': '0.91157', 'micro_f1': '0.70125', 'micro_auc': '0.94792'}\n",
      "\n",
      "\n",
      "aplha:  0.302\n",
      "{'macro_f1': '0.55281', 'macro_auc': '0.91155', 'micro_f1': '0.70141', 'micro_auc': '0.94791'}\n",
      "\n",
      "\n",
      "aplha:  0.303\n",
      "{'macro_f1': '0.55297', 'macro_auc': '0.91155', 'micro_f1': '0.70164', 'micro_auc': '0.94790'}\n",
      "\n",
      "\n",
      "aplha:  0.304\n",
      "{'macro_f1': '0.55295', 'macro_auc': '0.91154', 'micro_f1': '0.70168', 'micro_auc': '0.94789'}\n",
      "\n",
      "\n",
      "aplha:  0.305\n",
      "{'macro_f1': '0.55309', 'macro_auc': '0.91153', 'micro_f1': '0.70169', 'micro_auc': '0.94788'}\n",
      "\n",
      "\n",
      "aplha:  0.306\n",
      "{'macro_f1': '0.55306', 'macro_auc': '0.91152', 'micro_f1': '0.70164', 'micro_auc': '0.94787'}\n",
      "\n",
      "\n",
      "aplha:  0.307\n",
      "{'macro_f1': '0.55269', 'macro_auc': '0.91151', 'micro_f1': '0.70139', 'micro_auc': '0.94787'}\n",
      "\n",
      "\n",
      "aplha:  0.308\n",
      "{'macro_f1': '0.55296', 'macro_auc': '0.91150', 'micro_f1': '0.70149', 'micro_auc': '0.94786'}\n",
      "\n",
      "\n",
      "aplha:  0.309\n",
      "{'macro_f1': '0.55279', 'macro_auc': '0.91149', 'micro_f1': '0.70155', 'micro_auc': '0.94785'}\n",
      "\n",
      "\n",
      "aplha:  0.31\n",
      "{'macro_f1': '0.55251', 'macro_auc': '0.91149', 'micro_f1': '0.70135', 'micro_auc': '0.94784'}\n",
      "\n",
      "\n",
      "aplha:  0.311\n",
      "{'macro_f1': '0.55261', 'macro_auc': '0.91148', 'micro_f1': '0.70134', 'micro_auc': '0.94783'}\n",
      "\n",
      "\n",
      "aplha:  0.312\n",
      "{'macro_f1': '0.55280', 'macro_auc': '0.91147', 'micro_f1': '0.70138', 'micro_auc': '0.94782'}\n",
      "\n",
      "\n",
      "aplha:  0.313\n",
      "{'macro_f1': '0.55310', 'macro_auc': '0.91146', 'micro_f1': '0.70142', 'micro_auc': '0.94781'}\n",
      "\n",
      "\n",
      "aplha:  0.314\n",
      "{'macro_f1': '0.55222', 'macro_auc': '0.91145', 'micro_f1': '0.70140', 'micro_auc': '0.94780'}\n",
      "\n",
      "\n",
      "aplha:  0.315\n",
      "{'macro_f1': '0.55236', 'macro_auc': '0.91144', 'micro_f1': '0.70144', 'micro_auc': '0.94779'}\n",
      "\n",
      "\n",
      "aplha:  0.316\n",
      "{'macro_f1': '0.55243', 'macro_auc': '0.91143', 'micro_f1': '0.70150', 'micro_auc': '0.94778'}\n",
      "\n",
      "\n",
      "aplha:  0.317\n",
      "{'macro_f1': '0.55257', 'macro_auc': '0.91142', 'micro_f1': '0.70159', 'micro_auc': '0.94777'}\n",
      "\n",
      "\n",
      "aplha:  0.318\n",
      "{'macro_f1': '0.55217', 'macro_auc': '0.91142', 'micro_f1': '0.70146', 'micro_auc': '0.94776'}\n",
      "\n",
      "\n",
      "aplha:  0.319\n",
      "{'macro_f1': '0.55219', 'macro_auc': '0.91141', 'micro_f1': '0.70131', 'micro_auc': '0.94775'}\n",
      "\n",
      "\n",
      "aplha:  0.32\n",
      "{'macro_f1': '0.55240', 'macro_auc': '0.91140', 'micro_f1': '0.70157', 'micro_auc': '0.94774'}\n",
      "\n",
      "\n",
      "aplha:  0.321\n",
      "{'macro_f1': '0.55215', 'macro_auc': '0.91139', 'micro_f1': '0.70153', 'micro_auc': '0.94773'}\n",
      "\n",
      "\n",
      "aplha:  0.322\n",
      "{'macro_f1': '0.55228', 'macro_auc': '0.91138', 'micro_f1': '0.70162', 'micro_auc': '0.94772'}\n",
      "\n",
      "\n",
      "aplha:  0.323\n",
      "{'macro_f1': '0.55211', 'macro_auc': '0.91137', 'micro_f1': '0.70157', 'micro_auc': '0.94771'}\n",
      "\n",
      "\n",
      "aplha:  0.324\n",
      "{'macro_f1': '0.55205', 'macro_auc': '0.91136', 'micro_f1': '0.70155', 'micro_auc': '0.94770'}\n",
      "\n",
      "\n",
      "aplha:  0.325\n",
      "{'macro_f1': '0.55167', 'macro_auc': '0.91135', 'micro_f1': '0.70134', 'micro_auc': '0.94769'}\n",
      "\n",
      "\n",
      "aplha:  0.326\n",
      "{'macro_f1': '0.55162', 'macro_auc': '0.91134', 'micro_f1': '0.70120', 'micro_auc': '0.94768'}\n",
      "\n",
      "\n",
      "aplha:  0.327\n",
      "{'macro_f1': '0.55169', 'macro_auc': '0.91133', 'micro_f1': '0.70116', 'micro_auc': '0.94767'}\n",
      "\n",
      "\n",
      "aplha:  0.328\n",
      "{'macro_f1': '0.55183', 'macro_auc': '0.91132', 'micro_f1': '0.70125', 'micro_auc': '0.94766'}\n",
      "\n",
      "\n",
      "aplha:  0.329\n",
      "{'macro_f1': '0.55149', 'macro_auc': '0.91130', 'micro_f1': '0.70115', 'micro_auc': '0.94765'}\n",
      "\n",
      "\n",
      "aplha:  0.33\n",
      "{'macro_f1': '0.55136', 'macro_auc': '0.91130', 'micro_f1': '0.70099', 'micro_auc': '0.94764'}\n",
      "\n",
      "\n",
      "aplha:  0.331\n",
      "{'macro_f1': '0.55067', 'macro_auc': '0.91129', 'micro_f1': '0.70084', 'micro_auc': '0.94763'}\n",
      "\n",
      "\n",
      "aplha:  0.332\n",
      "{'macro_f1': '0.55063', 'macro_auc': '0.91128', 'micro_f1': '0.70085', 'micro_auc': '0.94762'}\n",
      "\n",
      "\n",
      "aplha:  0.333\n",
      "{'macro_f1': '0.55086', 'macro_auc': '0.91127', 'micro_f1': '0.70103', 'micro_auc': '0.94761'}\n",
      "\n",
      "\n",
      "aplha:  0.334\n",
      "{'macro_f1': '0.55064', 'macro_auc': '0.91126', 'micro_f1': '0.70090', 'micro_auc': '0.94760'}\n",
      "\n",
      "\n",
      "aplha:  0.335\n",
      "{'macro_f1': '0.55059', 'macro_auc': '0.91125', 'micro_f1': '0.70102', 'micro_auc': '0.94758'}\n",
      "\n",
      "\n",
      "aplha:  0.336\n",
      "{'macro_f1': '0.55059', 'macro_auc': '0.91124', 'micro_f1': '0.70101', 'micro_auc': '0.94757'}\n",
      "\n",
      "\n",
      "aplha:  0.337\n",
      "{'macro_f1': '0.55030', 'macro_auc': '0.91123', 'micro_f1': '0.70089', 'micro_auc': '0.94756'}\n",
      "\n",
      "\n",
      "aplha:  0.338\n",
      "{'macro_f1': '0.55053', 'macro_auc': '0.91122', 'micro_f1': '0.70090', 'micro_auc': '0.94755'}\n",
      "\n",
      "\n",
      "aplha:  0.339\n",
      "{'macro_f1': '0.55080', 'macro_auc': '0.91121', 'micro_f1': '0.70091', 'micro_auc': '0.94754'}\n",
      "\n",
      "\n",
      "aplha:  0.34\n",
      "{'macro_f1': '0.55107', 'macro_auc': '0.91120', 'micro_f1': '0.70090', 'micro_auc': '0.94753'}\n",
      "\n",
      "\n",
      "aplha:  0.341\n",
      "{'macro_f1': '0.55126', 'macro_auc': '0.91119', 'micro_f1': '0.70098', 'micro_auc': '0.94752'}\n",
      "\n",
      "\n",
      "aplha:  0.342\n",
      "{'macro_f1': '0.55107', 'macro_auc': '0.91118', 'micro_f1': '0.70082', 'micro_auc': '0.94750'}\n",
      "\n",
      "\n",
      "aplha:  0.343\n",
      "{'macro_f1': '0.55072', 'macro_auc': '0.91117', 'micro_f1': '0.70064', 'micro_auc': '0.94749'}\n",
      "\n",
      "\n",
      "aplha:  0.34400000000000003\n",
      "{'macro_f1': '0.55069', 'macro_auc': '0.91116', 'micro_f1': '0.70065', 'micro_auc': '0.94748'}\n",
      "\n",
      "\n",
      "aplha:  0.34500000000000003\n",
      "{'macro_f1': '0.55071', 'macro_auc': '0.91115', 'micro_f1': '0.70066', 'micro_auc': '0.94747'}\n",
      "\n",
      "\n",
      "aplha:  0.34600000000000003\n",
      "{'macro_f1': '0.55049', 'macro_auc': '0.91114', 'micro_f1': '0.70070', 'micro_auc': '0.94746'}\n",
      "\n",
      "\n",
      "aplha:  0.34700000000000003\n",
      "{'macro_f1': '0.55067', 'macro_auc': '0.91113', 'micro_f1': '0.70083', 'micro_auc': '0.94745'}\n",
      "\n",
      "\n",
      "aplha:  0.34800000000000003\n",
      "{'macro_f1': '0.55036', 'macro_auc': '0.91111', 'micro_f1': '0.70078', 'micro_auc': '0.94743'}\n",
      "\n",
      "\n",
      "aplha:  0.34900000000000003\n",
      "{'macro_f1': '0.54998', 'macro_auc': '0.91111', 'micro_f1': '0.70054', 'micro_auc': '0.94742'}\n",
      "\n",
      "\n",
      "aplha:  0.35000000000000003\n",
      "{'macro_f1': '0.54982', 'macro_auc': '0.91109', 'micro_f1': '0.70020', 'micro_auc': '0.94741'}\n",
      "\n",
      "\n",
      "aplha:  0.35100000000000003\n",
      "{'macro_f1': '0.54987', 'macro_auc': '0.91108', 'micro_f1': '0.70013', 'micro_auc': '0.94740'}\n",
      "\n",
      "\n",
      "aplha:  0.352\n",
      "{'macro_f1': '0.55006', 'macro_auc': '0.91107', 'micro_f1': '0.70022', 'micro_auc': '0.94738'}\n",
      "\n",
      "\n",
      "aplha:  0.353\n",
      "{'macro_f1': '0.55052', 'macro_auc': '0.91106', 'micro_f1': '0.70043', 'micro_auc': '0.94737'}\n",
      "\n",
      "\n",
      "aplha:  0.354\n",
      "{'macro_f1': '0.55067', 'macro_auc': '0.91105', 'micro_f1': '0.70055', 'micro_auc': '0.94736'}\n",
      "\n",
      "\n",
      "aplha:  0.355\n",
      "{'macro_f1': '0.55070', 'macro_auc': '0.91104', 'micro_f1': '0.70058', 'micro_auc': '0.94735'}\n",
      "\n",
      "\n",
      "aplha:  0.356\n",
      "{'macro_f1': '0.55069', 'macro_auc': '0.91102', 'micro_f1': '0.70046', 'micro_auc': '0.94733'}\n",
      "\n",
      "\n",
      "aplha:  0.357\n",
      "{'macro_f1': '0.55033', 'macro_auc': '0.91102', 'micro_f1': '0.70029', 'micro_auc': '0.94732'}\n",
      "\n",
      "\n",
      "aplha:  0.358\n",
      "{'macro_f1': '0.55021', 'macro_auc': '0.91100', 'micro_f1': '0.69995', 'micro_auc': '0.94731'}\n",
      "\n",
      "\n",
      "aplha:  0.359\n",
      "{'macro_f1': '0.55002', 'macro_auc': '0.91099', 'micro_f1': '0.70005', 'micro_auc': '0.94730'}\n",
      "\n",
      "\n",
      "aplha:  0.36\n",
      "{'macro_f1': '0.54965', 'macro_auc': '0.91098', 'micro_f1': '0.69995', 'micro_auc': '0.94728'}\n",
      "\n",
      "\n",
      "aplha:  0.361\n",
      "{'macro_f1': '0.54902', 'macro_auc': '0.91096', 'micro_f1': '0.70027', 'micro_auc': '0.94727'}\n",
      "\n",
      "\n",
      "aplha:  0.362\n",
      "{'macro_f1': '0.54904', 'macro_auc': '0.91095', 'micro_f1': '0.70028', 'micro_auc': '0.94726'}\n",
      "\n",
      "\n",
      "aplha:  0.363\n",
      "{'macro_f1': '0.54864', 'macro_auc': '0.91094', 'micro_f1': '0.70014', 'micro_auc': '0.94724'}\n",
      "\n",
      "\n",
      "aplha:  0.364\n",
      "{'macro_f1': '0.54879', 'macro_auc': '0.91093', 'micro_f1': '0.70013', 'micro_auc': '0.94723'}\n",
      "\n",
      "\n",
      "aplha:  0.365\n",
      "{'macro_f1': '0.54825', 'macro_auc': '0.91091', 'micro_f1': '0.69984', 'micro_auc': '0.94722'}\n",
      "\n",
      "\n",
      "aplha:  0.366\n",
      "{'macro_f1': '0.54815', 'macro_auc': '0.91090', 'micro_f1': '0.69980', 'micro_auc': '0.94720'}\n",
      "\n",
      "\n",
      "aplha:  0.367\n",
      "{'macro_f1': '0.54766', 'macro_auc': '0.91089', 'micro_f1': '0.69953', 'micro_auc': '0.94719'}\n",
      "\n",
      "\n",
      "aplha:  0.368\n",
      "{'macro_f1': '0.54760', 'macro_auc': '0.91088', 'micro_f1': '0.69939', 'micro_auc': '0.94718'}\n",
      "\n",
      "\n",
      "aplha:  0.369\n",
      "{'macro_f1': '0.54768', 'macro_auc': '0.91086', 'micro_f1': '0.69945', 'micro_auc': '0.94716'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.37\n",
      "{'macro_f1': '0.54731', 'macro_auc': '0.91085', 'micro_f1': '0.69936', 'micro_auc': '0.94715'}\n",
      "\n",
      "\n",
      "aplha:  0.371\n",
      "{'macro_f1': '0.54664', 'macro_auc': '0.91083', 'micro_f1': '0.69922', 'micro_auc': '0.94713'}\n",
      "\n",
      "\n",
      "aplha:  0.372\n",
      "{'macro_f1': '0.54639', 'macro_auc': '0.91082', 'micro_f1': '0.69909', 'micro_auc': '0.94712'}\n",
      "\n",
      "\n",
      "aplha:  0.373\n",
      "{'macro_f1': '0.54650', 'macro_auc': '0.91080', 'micro_f1': '0.69914', 'micro_auc': '0.94711'}\n",
      "\n",
      "\n",
      "aplha:  0.374\n",
      "{'macro_f1': '0.54694', 'macro_auc': '0.91079', 'micro_f1': '0.69938', 'micro_auc': '0.94709'}\n",
      "\n",
      "\n",
      "aplha:  0.375\n",
      "{'macro_f1': '0.54653', 'macro_auc': '0.91077', 'micro_f1': '0.69904', 'micro_auc': '0.94708'}\n",
      "\n",
      "\n",
      "aplha:  0.376\n",
      "{'macro_f1': '0.54650', 'macro_auc': '0.91076', 'micro_f1': '0.69889', 'micro_auc': '0.94706'}\n",
      "\n",
      "\n",
      "aplha:  0.377\n",
      "{'macro_f1': '0.54670', 'macro_auc': '0.91075', 'micro_f1': '0.69893', 'micro_auc': '0.94705'}\n",
      "\n",
      "\n",
      "aplha:  0.378\n",
      "{'macro_f1': '0.54655', 'macro_auc': '0.91074', 'micro_f1': '0.69886', 'micro_auc': '0.94704'}\n",
      "\n",
      "\n",
      "aplha:  0.379\n",
      "{'macro_f1': '0.54599', 'macro_auc': '0.91072', 'micro_f1': '0.69846', 'micro_auc': '0.94702'}\n",
      "\n",
      "\n",
      "aplha:  0.38\n",
      "{'macro_f1': '0.54494', 'macro_auc': '0.91071', 'micro_f1': '0.69805', 'micro_auc': '0.94701'}\n",
      "\n",
      "\n",
      "aplha:  0.381\n",
      "{'macro_f1': '0.54481', 'macro_auc': '0.91069', 'micro_f1': '0.69801', 'micro_auc': '0.94699'}\n",
      "\n",
      "\n",
      "aplha:  0.382\n",
      "{'macro_f1': '0.54448', 'macro_auc': '0.91068', 'micro_f1': '0.69789', 'micro_auc': '0.94698'}\n",
      "\n",
      "\n",
      "aplha:  0.383\n",
      "{'macro_f1': '0.54407', 'macro_auc': '0.91067', 'micro_f1': '0.69790', 'micro_auc': '0.94696'}\n",
      "\n",
      "\n",
      "aplha:  0.384\n",
      "{'macro_f1': '0.54417', 'macro_auc': '0.91065', 'micro_f1': '0.69781', 'micro_auc': '0.94695'}\n",
      "\n",
      "\n",
      "aplha:  0.385\n",
      "{'macro_f1': '0.54333', 'macro_auc': '0.91064', 'micro_f1': '0.69775', 'micro_auc': '0.94693'}\n",
      "\n",
      "\n",
      "aplha:  0.386\n",
      "{'macro_f1': '0.54350', 'macro_auc': '0.91062', 'micro_f1': '0.69784', 'micro_auc': '0.94692'}\n",
      "\n",
      "\n",
      "aplha:  0.387\n",
      "{'macro_f1': '0.54346', 'macro_auc': '0.91061', 'micro_f1': '0.69768', 'micro_auc': '0.94690'}\n",
      "\n",
      "\n",
      "aplha:  0.388\n",
      "{'macro_f1': '0.54329', 'macro_auc': '0.91059', 'micro_f1': '0.69755', 'micro_auc': '0.94689'}\n",
      "\n",
      "\n",
      "aplha:  0.389\n",
      "{'macro_f1': '0.54231', 'macro_auc': '0.91058', 'micro_f1': '0.69700', 'micro_auc': '0.94687'}\n",
      "\n",
      "\n",
      "aplha:  0.39\n",
      "{'macro_f1': '0.54194', 'macro_auc': '0.91056', 'micro_f1': '0.69673', 'micro_auc': '0.94686'}\n",
      "\n",
      "\n",
      "aplha:  0.391\n",
      "{'macro_f1': '0.54147', 'macro_auc': '0.91055', 'micro_f1': '0.69651', 'micro_auc': '0.94684'}\n",
      "\n",
      "\n",
      "aplha:  0.392\n",
      "{'macro_f1': '0.54111', 'macro_auc': '0.91053', 'micro_f1': '0.69639', 'micro_auc': '0.94683'}\n",
      "\n",
      "\n",
      "aplha:  0.393\n",
      "{'macro_f1': '0.54033', 'macro_auc': '0.91052', 'micro_f1': '0.69594', 'micro_auc': '0.94681'}\n",
      "\n",
      "\n",
      "aplha:  0.394\n",
      "{'macro_f1': '0.54013', 'macro_auc': '0.91050', 'micro_f1': '0.69601', 'micro_auc': '0.94679'}\n",
      "\n",
      "\n",
      "aplha:  0.395\n",
      "{'macro_f1': '0.53984', 'macro_auc': '0.91048', 'micro_f1': '0.69577', 'micro_auc': '0.94678'}\n",
      "\n",
      "\n",
      "aplha:  0.396\n",
      "{'macro_f1': '0.53977', 'macro_auc': '0.91047', 'micro_f1': '0.69565', 'micro_auc': '0.94676'}\n",
      "\n",
      "\n",
      "aplha:  0.397\n",
      "{'macro_f1': '0.53990', 'macro_auc': '0.91045', 'micro_f1': '0.69575', 'micro_auc': '0.94675'}\n",
      "\n",
      "\n",
      "aplha:  0.398\n",
      "{'macro_f1': '0.53868', 'macro_auc': '0.91044', 'micro_f1': '0.69540', 'micro_auc': '0.94673'}\n",
      "\n",
      "\n",
      "aplha:  0.399\n",
      "{'macro_f1': '0.53901', 'macro_auc': '0.91042', 'micro_f1': '0.69528', 'micro_auc': '0.94671'}\n",
      "\n",
      "\n",
      "aplha:  0.4\n",
      "{'macro_f1': '0.53862', 'macro_auc': '0.91041', 'micro_f1': '0.69501', 'micro_auc': '0.94670'}\n",
      "\n",
      "\n",
      "aplha:  0.401\n",
      "{'macro_f1': '0.53823', 'macro_auc': '0.91039', 'micro_f1': '0.69494', 'micro_auc': '0.94668'}\n",
      "\n",
      "\n",
      "aplha:  0.402\n",
      "{'macro_f1': '0.53799', 'macro_auc': '0.91038', 'micro_f1': '0.69487', 'micro_auc': '0.94667'}\n",
      "\n",
      "\n",
      "aplha:  0.403\n",
      "{'macro_f1': '0.53791', 'macro_auc': '0.91036', 'micro_f1': '0.69474', 'micro_auc': '0.94665'}\n",
      "\n",
      "\n",
      "aplha:  0.404\n",
      "{'macro_f1': '0.53771', 'macro_auc': '0.91035', 'micro_f1': '0.69463', 'micro_auc': '0.94663'}\n",
      "\n",
      "\n",
      "aplha:  0.405\n",
      "{'macro_f1': '0.53830', 'macro_auc': '0.91033', 'micro_f1': '0.69487', 'micro_auc': '0.94662'}\n",
      "\n",
      "\n",
      "aplha:  0.406\n",
      "{'macro_f1': '0.53842', 'macro_auc': '0.91031', 'micro_f1': '0.69489', 'micro_auc': '0.94660'}\n",
      "\n",
      "\n",
      "aplha:  0.40700000000000003\n",
      "{'macro_f1': '0.53826', 'macro_auc': '0.91030', 'micro_f1': '0.69493', 'micro_auc': '0.94658'}\n",
      "\n",
      "\n",
      "aplha:  0.40800000000000003\n",
      "{'macro_f1': '0.53801', 'macro_auc': '0.91028', 'micro_f1': '0.69485', 'micro_auc': '0.94657'}\n",
      "\n",
      "\n",
      "aplha:  0.40900000000000003\n",
      "{'macro_f1': '0.53777', 'macro_auc': '0.91027', 'micro_f1': '0.69467', 'micro_auc': '0.94655'}\n",
      "\n",
      "\n",
      "aplha:  0.41000000000000003\n",
      "{'macro_f1': '0.53770', 'macro_auc': '0.91025', 'micro_f1': '0.69472', 'micro_auc': '0.94653'}\n",
      "\n",
      "\n",
      "aplha:  0.41100000000000003\n",
      "{'macro_f1': '0.53762', 'macro_auc': '0.91024', 'micro_f1': '0.69465', 'micro_auc': '0.94651'}\n",
      "\n",
      "\n",
      "aplha:  0.41200000000000003\n",
      "{'macro_f1': '0.53667', 'macro_auc': '0.91022', 'micro_f1': '0.69433', 'micro_auc': '0.94650'}\n",
      "\n",
      "\n",
      "aplha:  0.41300000000000003\n",
      "{'macro_f1': '0.53633', 'macro_auc': '0.91021', 'micro_f1': '0.69445', 'micro_auc': '0.94648'}\n",
      "\n",
      "\n",
      "aplha:  0.41400000000000003\n",
      "{'macro_f1': '0.53605', 'macro_auc': '0.91019', 'micro_f1': '0.69433', 'micro_auc': '0.94646'}\n",
      "\n",
      "\n",
      "aplha:  0.41500000000000004\n",
      "{'macro_f1': '0.53519', 'macro_auc': '0.91017', 'micro_f1': '0.69412', 'micro_auc': '0.94644'}\n",
      "\n",
      "\n",
      "aplha:  0.41600000000000004\n",
      "{'macro_f1': '0.53468', 'macro_auc': '0.91015', 'micro_f1': '0.69385', 'micro_auc': '0.94643'}\n",
      "\n",
      "\n",
      "aplha:  0.417\n",
      "{'macro_f1': '0.53410', 'macro_auc': '0.91014', 'micro_f1': '0.69350', 'micro_auc': '0.94641'}\n",
      "\n",
      "\n",
      "aplha:  0.418\n",
      "{'macro_f1': '0.53367', 'macro_auc': '0.91012', 'micro_f1': '0.69322', 'micro_auc': '0.94639'}\n",
      "\n",
      "\n",
      "aplha:  0.419\n",
      "{'macro_f1': '0.53352', 'macro_auc': '0.91010', 'micro_f1': '0.69329', 'micro_auc': '0.94637'}\n",
      "\n",
      "\n",
      "aplha:  0.42\n",
      "{'macro_f1': '0.53316', 'macro_auc': '0.91008', 'micro_f1': '0.69302', 'micro_auc': '0.94635'}\n",
      "\n",
      "\n",
      "aplha:  0.421\n",
      "{'macro_f1': '0.53224', 'macro_auc': '0.91006', 'micro_f1': '0.69272', 'micro_auc': '0.94634'}\n",
      "\n",
      "\n",
      "aplha:  0.422\n",
      "{'macro_f1': '0.53174', 'macro_auc': '0.91005', 'micro_f1': '0.69247', 'micro_auc': '0.94632'}\n",
      "\n",
      "\n",
      "aplha:  0.423\n",
      "{'macro_f1': '0.53149', 'macro_auc': '0.91003', 'micro_f1': '0.69185', 'micro_auc': '0.94630'}\n",
      "\n",
      "\n",
      "aplha:  0.424\n",
      "{'macro_f1': '0.53126', 'macro_auc': '0.91001', 'micro_f1': '0.69166', 'micro_auc': '0.94628'}\n",
      "\n",
      "\n",
      "aplha:  0.425\n",
      "{'macro_f1': '0.53131', 'macro_auc': '0.90999', 'micro_f1': '0.69179', 'micro_auc': '0.94626'}\n",
      "\n",
      "\n",
      "aplha:  0.426\n",
      "{'macro_f1': '0.53065', 'macro_auc': '0.90998', 'micro_f1': '0.69155', 'micro_auc': '0.94624'}\n",
      "\n",
      "\n",
      "aplha:  0.427\n",
      "{'macro_f1': '0.53157', 'macro_auc': '0.90996', 'micro_f1': '0.69179', 'micro_auc': '0.94622'}\n",
      "\n",
      "\n",
      "aplha:  0.428\n",
      "{'macro_f1': '0.53109', 'macro_auc': '0.90995', 'micro_f1': '0.69160', 'micro_auc': '0.94621'}\n",
      "\n",
      "\n",
      "aplha:  0.429\n",
      "{'macro_f1': '0.53096', 'macro_auc': '0.90993', 'micro_f1': '0.69139', 'micro_auc': '0.94619'}\n",
      "\n",
      "\n",
      "aplha:  0.43\n",
      "{'macro_f1': '0.53091', 'macro_auc': '0.90991', 'micro_f1': '0.69140', 'micro_auc': '0.94617'}\n",
      "\n",
      "\n",
      "aplha:  0.431\n",
      "{'macro_f1': '0.53045', 'macro_auc': '0.90990', 'micro_f1': '0.69110', 'micro_auc': '0.94615'}\n",
      "\n",
      "\n",
      "aplha:  0.432\n",
      "{'macro_f1': '0.53036', 'macro_auc': '0.90988', 'micro_f1': '0.69092', 'micro_auc': '0.94613'}\n",
      "\n",
      "\n",
      "aplha:  0.433\n",
      "{'macro_f1': '0.52968', 'macro_auc': '0.90986', 'micro_f1': '0.69082', 'micro_auc': '0.94611'}\n",
      "\n",
      "\n",
      "aplha:  0.434\n",
      "{'macro_f1': '0.52896', 'macro_auc': '0.90984', 'micro_f1': '0.69052', 'micro_auc': '0.94609'}\n",
      "\n",
      "\n",
      "aplha:  0.435\n",
      "{'macro_f1': '0.52841', 'macro_auc': '0.90982', 'micro_f1': '0.69033', 'micro_auc': '0.94607'}\n",
      "\n",
      "\n",
      "aplha:  0.436\n",
      "{'macro_f1': '0.52753', 'macro_auc': '0.90980', 'micro_f1': '0.69002', 'micro_auc': '0.94605'}\n",
      "\n",
      "\n",
      "aplha:  0.437\n",
      "{'macro_f1': '0.52801', 'macro_auc': '0.90978', 'micro_f1': '0.69013', 'micro_auc': '0.94603'}\n",
      "\n",
      "\n",
      "aplha:  0.438\n",
      "{'macro_f1': '0.52795', 'macro_auc': '0.90976', 'micro_f1': '0.69020', 'micro_auc': '0.94601'}\n",
      "\n",
      "\n",
      "aplha:  0.439\n",
      "{'macro_f1': '0.52758', 'macro_auc': '0.90974', 'micro_f1': '0.69019', 'micro_auc': '0.94599'}\n",
      "\n",
      "\n",
      "aplha:  0.44\n",
      "{'macro_f1': '0.52742', 'macro_auc': '0.90972', 'micro_f1': '0.69002', 'micro_auc': '0.94597'}\n",
      "\n",
      "\n",
      "aplha:  0.441\n",
      "{'macro_f1': '0.52718', 'macro_auc': '0.90970', 'micro_f1': '0.68989', 'micro_auc': '0.94595'}\n",
      "\n",
      "\n",
      "aplha:  0.442\n",
      "{'macro_f1': '0.52722', 'macro_auc': '0.90968', 'micro_f1': '0.68962', 'micro_auc': '0.94593'}\n",
      "\n",
      "\n",
      "aplha:  0.443\n",
      "{'macro_f1': '0.52663', 'macro_auc': '0.90966', 'micro_f1': '0.68931', 'micro_auc': '0.94591'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplha:  0.444\n",
      "{'macro_f1': '0.52480', 'macro_auc': '0.90964', 'micro_f1': '0.68846', 'micro_auc': '0.94589'}\n",
      "\n",
      "\n",
      "aplha:  0.445\n",
      "{'macro_f1': '0.52371', 'macro_auc': '0.90962', 'micro_f1': '0.68805', 'micro_auc': '0.94587'}\n",
      "\n",
      "\n",
      "aplha:  0.446\n",
      "{'macro_f1': '0.52381', 'macro_auc': '0.90960', 'micro_f1': '0.68802', 'micro_auc': '0.94584'}\n",
      "\n",
      "\n",
      "aplha:  0.447\n",
      "{'macro_f1': '0.52302', 'macro_auc': '0.90958', 'micro_f1': '0.68763', 'micro_auc': '0.94582'}\n",
      "\n",
      "\n",
      "aplha:  0.448\n",
      "{'macro_f1': '0.52261', 'macro_auc': '0.90956', 'micro_f1': '0.68755', 'micro_auc': '0.94580'}\n",
      "\n",
      "\n",
      "aplha:  0.449\n",
      "{'macro_f1': '0.52169', 'macro_auc': '0.90954', 'micro_f1': '0.68695', 'micro_auc': '0.94578'}\n",
      "\n",
      "\n",
      "aplha:  0.45\n",
      "{'macro_f1': '0.52069', 'macro_auc': '0.90952', 'micro_f1': '0.68659', 'micro_auc': '0.94576'}\n",
      "\n",
      "\n",
      "aplha:  0.451\n",
      "{'macro_f1': '0.51980', 'macro_auc': '0.90950', 'micro_f1': '0.68598', 'micro_auc': '0.94574'}\n",
      "\n",
      "\n",
      "aplha:  0.452\n",
      "{'macro_f1': '0.51914', 'macro_auc': '0.90948', 'micro_f1': '0.68561', 'micro_auc': '0.94571'}\n",
      "\n",
      "\n",
      "aplha:  0.453\n",
      "{'macro_f1': '0.51863', 'macro_auc': '0.90946', 'micro_f1': '0.68531', 'micro_auc': '0.94569'}\n",
      "\n",
      "\n",
      "aplha:  0.454\n",
      "{'macro_f1': '0.51821', 'macro_auc': '0.90944', 'micro_f1': '0.68508', 'micro_auc': '0.94567'}\n",
      "\n",
      "\n",
      "aplha:  0.455\n",
      "{'macro_f1': '0.51861', 'macro_auc': '0.90942', 'micro_f1': '0.68510', 'micro_auc': '0.94565'}\n",
      "\n",
      "\n",
      "aplha:  0.456\n",
      "{'macro_f1': '0.51796', 'macro_auc': '0.90940', 'micro_f1': '0.68458', 'micro_auc': '0.94563'}\n",
      "\n",
      "\n",
      "aplha:  0.457\n",
      "{'macro_f1': '0.51721', 'macro_auc': '0.90938', 'micro_f1': '0.68421', 'micro_auc': '0.94560'}\n",
      "\n",
      "\n",
      "aplha:  0.458\n",
      "{'macro_f1': '0.51600', 'macro_auc': '0.90936', 'micro_f1': '0.68340', 'micro_auc': '0.94558'}\n",
      "\n",
      "\n",
      "aplha:  0.459\n",
      "{'macro_f1': '0.51411', 'macro_auc': '0.90934', 'micro_f1': '0.68271', 'micro_auc': '0.94556'}\n",
      "\n",
      "\n",
      "aplha:  0.46\n",
      "{'macro_f1': '0.51324', 'macro_auc': '0.90932', 'micro_f1': '0.68213', 'micro_auc': '0.94554'}\n",
      "\n",
      "\n",
      "aplha:  0.461\n",
      "{'macro_f1': '0.51240', 'macro_auc': '0.90930', 'micro_f1': '0.68176', 'micro_auc': '0.94551'}\n",
      "\n",
      "\n",
      "aplha:  0.462\n",
      "{'macro_f1': '0.50834', 'macro_auc': '0.90927', 'micro_f1': '0.68103', 'micro_auc': '0.94549'}\n",
      "\n",
      "\n",
      "aplha:  0.463\n",
      "{'macro_f1': '0.50743', 'macro_auc': '0.90925', 'micro_f1': '0.68051', 'micro_auc': '0.94547'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [101], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.001\u001b[39m):\n\u001b[1;32m      7\u001b[0m     final_output \u001b[38;5;241m=\u001b[39m struct_input \u001b[38;5;241m*\u001b[39m alpha \u001b[38;5;241m+\u001b[39m unstruct_input \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha)\n\u001b[0;32m----> 8\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_eval_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhadm_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro_f1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maplha: \u001b[39m\u001b[38;5;124m'\u001b[39m, alpha)\n",
      "File \u001b[0;32m~/project/home/CDLAAT/main/util.py:22\u001b[0m, in \u001b[0;36mcalculate_eval_metrics\u001b[0;34m(ids, true_labels, pred_probs, is_multilabel)\u001b[0m\n\u001b[1;32m     19\u001b[0m pred_probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(pred_probs)\n\u001b[1;32m     20\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrint(pred_probs)\n\u001b[0;32m---> 22\u001b[0m macro_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_multilabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m micro_scores \u001b[38;5;241m=\u001b[39m calculate_scores(true_labels, pred_labels, pred_probs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m, is_multilabel)\n\u001b[1;32m     25\u001b[0m scores \u001b[38;5;241m=\u001b[39m macro_scores\n",
      "File \u001b[0;32m~/project/home/CDLAAT/main/util.py:46\u001b[0m, in \u001b[0;36mcalculate_scores\u001b[0;34m(true_labels, pred_labels, pred_probs, average, is_multilabel)\u001b[0m\n\u001b[1;32m     44\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m macro_accuracy(true_labels, pred_labels)  \u001b[38;5;66;03m# categorical accuracy\u001b[39;00m\n\u001b[1;32m     45\u001b[0m precision, recall, f1 \u001b[38;5;241m=\u001b[39m macro_f1(true_labels, pred_labels)\n\u001b[0;32m---> 46\u001b[0m p_ks \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_at_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m p_1 \u001b[38;5;241m=\u001b[39m p_ks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     48\u001b[0m p_5 \u001b[38;5;241m=\u001b[39m p_ks[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/project/home/CDLAAT/main/util.py:159\u001b[0m, in \u001b[0;36mprecision_at_k\u001b[0;34m(true_labels, pred_probs, ks)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(topk):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tk) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m         num_true_in_top_k \u001b[38;5;241m=\u001b[39m \u001b[43mtrue_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tk)\n\u001b[1;32m    161\u001b[0m         vals\u001b[38;5;241m.\u001b[39mappend(num_true_in_top_k \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(denom))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mi_auc = []\n",
    "ma_auc = []\n",
    "mi_f1 = []\n",
    "ma_f1 = []\n",
    "\n",
    "for alpha in np.arange(0.0, 1.0, 0.001):\n",
    "    final_output = struct_input * alpha + unstruct_input * (1 - alpha)\n",
    "    scores = calculate_eval_metrics(test_scores['hadm_ids'], y_test, final_output, True)\n",
    "    keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1']\n",
    "    print('aplha: ', alpha)\n",
    "    print({k:\"{:.5f}\".format(v) for k,v in scores.items() if k in keys})\n",
    "    mi_auc.append(scores['micro_auc'])\n",
    "    ma_auc.append(scores['macro_auc'])\n",
    "    mi_f1.append(scores['micro_f1'])\n",
    "    ma_f1.append(scores['macro_f1'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a066a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1, 0.001)\n",
    "mi_auc = np.array(mi_auc)\n",
    "ma_auc = np.array(ma_auc)\n",
    "mi_f1 = np.array(mi_f1)\n",
    "ma_f1 = np.array(ma_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61a93549",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value:  0.9479564037311676 , at alpha =  [0.168]\n"
     ]
    }
   ],
   "source": [
    "y = mi_auc\n",
    "plt.plot(alphas, y)\n",
    "ymax = max(y)\n",
    "xpos = np.where(y == ymax)\n",
    "xmax = alphas[xpos]\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Max value: ', ymax, ', at alpha = ', xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a391783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = np.add(mi_auc, ma_auc)\n",
    "summ = np.add(summ, mi_f1)\n",
    "summ = np.add(summ, ma_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1501af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: (array([152]),)\n",
      "alpha: [0.152]\n"
     ]
    }
   ],
   "source": [
    "pos = np.where(summ == max(summ))\n",
    "print('pos:', pos)\n",
    "print('alpha:', alphas[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "004742a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_auc: [0.94794953]\n",
      "macro_auc: [0.91145506]\n",
      "micro-f1: [0.69878568]\n",
      "macro-f1: [0.56193437]\n"
     ]
    }
   ],
   "source": [
    "print('micro_auc:', mi_auc[pos])\n",
    "print('macro_auc:', ma_auc[pos])\n",
    "print('micro-f1:', mi_f1[pos])\n",
    "print('macro-f1:', ma_f1[pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7da458",
   "metadata": {},
   "source": [
    "# Training Structured Data on neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddcef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../Structured/train_final.csv')\n",
    "train_dataset = train_df.to_dict('records')\n",
    "\n",
    "test_df = pd.read_csv('../../Structured/test_final.csv')\n",
    "test_dataset = test_df.to_dict('records')\n",
    "\n",
    "dev_df = pd.read_csv('../../Structured/dev_final.csv')\n",
    "dev_dataset = dev_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(dataset):\n",
    "# convert df icd9_codes column into one hot vector\n",
    "    for row in dataset:\n",
    "        labels = [0] * 50\n",
    "        codes = list(row['ICD9_CODE'].split(\";\"))\n",
    "        for i in range(len(codes)):\n",
    "            labels[icd9.index(codes[i])] = 1\n",
    "        row['ICD9_CODE'] = labels\n",
    "\n",
    "        # get list of features (lab events item ids) \n",
    "        keys = dataset[0].keys()\n",
    "        keys = list(keys)\n",
    "        keys.remove('SUBJECT_ID')\n",
    "        keys.remove('HADM_ID')\n",
    "        keys.remove('ICD9_CODE')\n",
    "\n",
    "    # Create dataset from df feature values\n",
    "    X = []\n",
    "    y = []\n",
    "    for row in dataset:\n",
    "        x = []\n",
    "        for key in keys:\n",
    "            x.append(row[key])\n",
    "        X.append(x)\n",
    "        y.append(row['ICD9_CODE'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = generate_dataset(train_dataset)\n",
    "X_test, y_test = generate_dataset(test_dataset)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7608f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e054439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer1 = nn.Linear(in_features = 1530, out_features = 1024)\n",
    "        self.linear_layer2 = nn.Linear(in_features = 1024, out_features = 512)\n",
    "        self.linear_layer3 = nn.Linear(in_features = 512, out_features = 256)\n",
    "        self.linear_layer4 = nn.Linear(in_features = 256, out_features = 128)\n",
    "        self.linear_layer5 = nn.Linear(in_features = 128, out_features = 64)\n",
    "        self.linear_layer6 = nn.Linear(in_features = 64, out_features = 50)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        op1 = self.linear_layer1(x)\n",
    "        op1a = torch.tanh(op1)\n",
    "        op2 = self.linear_layer2(op1a)\n",
    "        op2a = torch.tanh(op2)\n",
    "        op3 = self.linear_layer3(op2a)\n",
    "        op3a = torch.tanh(op3)        \n",
    "        op4 = self.linear_layer4(op3a)\n",
    "        op4a = torch.tanh(op4)\n",
    "        op5 = self.linear_layer5(op4a)\n",
    "        op5a = torch.tanh(op5)\n",
    "        op6 = self.linear_layer6(op5a)\n",
    "        output = torch.sigmoid(op6)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7680441",
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel = StructuredModel()\n",
    "smodel.to(device)\n",
    "    \n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(params = smodel.parameters(), lr = 0.001)\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    smodel.train()\n",
    "    y_pred = smodel(X_train.float())\n",
    "    loss = loss_fn(y_pred, y_train.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    smodel.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred_test = smodel(X_test.float())\n",
    "        loss_test = loss_fn(y_pred_test, y_test.float())\n",
    "        \n",
    "    if epoch %50==0:\n",
    "        print(f\"Epoch: {epoch} | Training Loss: {loss} | Test Loss: {loss_test}\")\n",
    "        scores = calculate_eval_metrics(test_scores['hadm_ids'], y_test.cpu(), y_pred_test.cpu(), True)\n",
    "        keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1']\n",
    "        print({k:\"{:.3f}\".format(v) for k,v in scores.items() if k in keys})\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_input = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_input = struct_input.cpu().numpy()\n",
    "struct_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be913ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_auc = []\n",
    "ma_auc = []\n",
    "mi_f1 = []\n",
    "ma_f1 = []\n",
    "\n",
    "for alpha in np.arange(0.0, 1.0, 0.001):\n",
    "    final_output = struct_input * alpha + unstruct_input * (1 - alpha)\n",
    "    scores = calculate_eval_metrics(test_scores['hadm_ids'], y_test.cpu(), final_output, True)\n",
    "    keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1']\n",
    "    print('aplha: ', alpha)\n",
    "    print({k:\"{:.3f}\".format(v) for k,v in scores.items() if k in keys})\n",
    "    mi_auc.append(scores['micro_auc'])\n",
    "    ma_auc.append(scores['macro_auc'])\n",
    "    mi_f1.append(scores['micro_f1'])\n",
    "    ma_f1.append(scores['macro_f1'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1, 0.001)\n",
    "mi_auc = np.array(mi_auc)\n",
    "ma_auc = np.array(ma_auc)\n",
    "mi_f1 = np.array(mi_f1)\n",
    "ma_f1 = np.array(ma_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mi_auc\n",
    "plt.plot(alphas, y)\n",
    "ymax = max(y)\n",
    "xpos = np.where(y == ymax)\n",
    "xmax = alphas[xpos]\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Max value: ', ymax, ', at alpha = ', xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = np.add(mi_auc, ma_auc)\n",
    "summ = np.add(summ, mi_f1)\n",
    "summ = np.add(summ, ma_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16cdc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.where(summ == max(summ))\n",
    "print('pos:', pos)\n",
    "print('alpha:', alphas[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('micro_auc:', mi_auc[pos])\n",
    "print('macro_auc:', ma_auc[pos])\n",
    "print('micro-f1:', mi_f1[pos])\n",
    "print('macro-f1:', ma_f1[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3bdeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
