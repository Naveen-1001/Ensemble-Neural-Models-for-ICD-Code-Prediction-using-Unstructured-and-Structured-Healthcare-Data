{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71afa6b7",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a9cb6ed",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import tqdm.notebook as tqdm\n",
    "from torch import optim\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from collections import Counter\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7cbab24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac72555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir =  \"../cache\"\n",
    "data_dir = \"../data/mimic3_new\"\n",
    "id_col_name = \"HADM_ID\"\n",
    "label_col_name = \"ICD9_CODE\"\n",
    "text_col_name= \"TEXT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a75cd2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 30 17:42:58 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   73C    P0   209W / 300W |  32504MiB / 32508MiB |     87%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   74C    P0   282W / 300W |  15969MiB / 32508MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   74C    P0   280W / 300W |  18449MiB / 32508MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   75C    P0   280W / 300W |  19019MiB / 32508MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   3223538      C   /usr/bin/python3                16137MiB |\n",
      "|    0   N/A  N/A   3650185      C   /usr/bin/python3                15569MiB |\n",
      "|    0   N/A  N/A   3727785      C   /usr/bin/python3                  795MiB |\n",
      "|    1   N/A  N/A   3223538      C   /usr/bin/python3                  461MiB |\n",
      "|    1   N/A  N/A   3650186      C   /usr/bin/python3                15505MiB |\n",
      "|    2   N/A  N/A   3223538      C   /usr/bin/python3                  461MiB |\n",
      "|    2   N/A  N/A   3650187      C   /usr/bin/python3                17985MiB |\n",
      "|    3   N/A  N/A   3223538      C   /usr/bin/python3                  461MiB |\n",
      "|    3   N/A  N/A   3650188      C   /usr/bin/python3                18555MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69129c7b",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7afed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "n_epoch=50\n",
    "optimiser=\"adamw\" # \"adam\", \"sgd\", \"adadelta\", \"adamw\",\"adagrad\"\n",
    "main_metric=\"micro_f1\"\n",
    "multilabel=1\n",
    "shuffle_data=1\n",
    "dropout=0.3\n",
    "max_seq_length=2500\n",
    "min_seq_length=-1\n",
    "min_word_frequency=-1\n",
    "embedding_mode=\"word2vec\"\n",
    "embedding_size=100\n",
    "embedding_file=\"../data/mimic3_new/processed_50.embed\"\n",
    "d_a=256 #\"The dimension of the first dense layer for self attention\"\n",
    "n_labels=50\n",
    "\n",
    "#RNN\n",
    "hidden_size =  256\n",
    "n_layers = 1\n",
    "bidirectional =1\n",
    "use_last_hidden_state=0\n",
    "rnn_model=\"LSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d3ef67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self,\n",
    "                 training_data: list,\n",
    "                 training_labels: list,\n",
    "                 min_word_frequency: int = -1,\n",
    "                 max_vocab_size: int = -1,\n",
    "                 word_embedding_mode: str = \"word2vec\",\n",
    "                 word_embedding_file: str = None,\n",
    "                 use_gpu: bool = True\n",
    "                 ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
    "        self.word_embedding_mode = word_embedding_mode\n",
    "        self.word_embedding_file = word_embedding_file\n",
    "        self.word_embedding_size = 100\n",
    "        self.word_embeddings = None\n",
    "\n",
    "        self.training_data = training_data\n",
    "\n",
    "        self.PAD_TOKEN = '_PAD'\n",
    "        self.UNK_TOKEN = '_UNK'\n",
    "        self.word2index = None\n",
    "        self.index2word = None\n",
    "\n",
    "        self.label2index = None\n",
    "        self.index2label = None\n",
    "\n",
    "        self.vocab_words = [self.PAD_TOKEN, self.UNK_TOKEN]\n",
    "        self.all_labels = []\n",
    "\n",
    "        self.min_word_frequency = min_word_frequency\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "\n",
    "        self.update_labels(training_labels)\n",
    "\n",
    "    def index_of_word(self,word: str) -> int:\n",
    "        try:\n",
    "            return self.word2index[word]\n",
    "        except:\n",
    "            return self.word2index[self.UNK_TOKEN]\n",
    "\n",
    "    def index_of_label(self,label: str) -> int:\n",
    "        try:\n",
    "            return self.label2index[label]\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    def update_labels(self, labels):\n",
    "        self.all_labels = []\n",
    "        self.index2label = []\n",
    "        self.label2index = []\n",
    "        all_labels = list(sorted(labels))\n",
    "        self.label2index = {label: idx for idx, label in enumerate(all_labels)}\n",
    "        self.index2label = {idx: label for idx, label in enumerate(all_labels)}\n",
    "        self.all_labels = all_labels\n",
    "            \n",
    "    def prepare_vocab(self):\n",
    "        self._build_vocab()\n",
    "\n",
    "        # load pretrain word embeddings\n",
    "        if self.word_embedding_file is not None:\n",
    "            self.word_embeddings = torch.FloatTensor(self._load_embeddings())\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        all_words_df = pd.read_csv('../data/mimic3_new/vocab.csv',header=None)\n",
    "        all_words = all_words_df.iloc[:,0].tolist()\n",
    "        all_words.sort()\n",
    "\n",
    "        self.vocab_words += all_words\n",
    "\n",
    "        self.word2index = {word: idx for idx, word in enumerate(self.vocab_words)}\n",
    "        self.index2word = {idx: word for idx, word in enumerate(self.vocab_words)}\n",
    "\n",
    "\n",
    "    def _load_embeddings(self):\n",
    "        if self.word_embedding_file is None:\n",
    "            return None\n",
    "        return self._load_word_embeddings()\n",
    "\n",
    "    def _load_word_embeddings(self):\n",
    "        unknown_vec = np.random.uniform(-0.25, 0.25, self.word_embedding_size)\n",
    "        embeddings = [unknown_vec] * (len(self.vocab_words))\n",
    "        embeddings[0] = np.zeros(self.word_embedding_size)\n",
    "        for line in open(self.word_embedding_file, \"rt\"):\n",
    "            split = line.rstrip().split(\" \")\n",
    "            word = split[0]\n",
    "            vector = np.array([float(num) for num in split[1:]]).astype(np.float32)\n",
    "#             print(word,': ',vector)\n",
    "            if len(vector) > 0:\n",
    "                if word in self.word2index:\n",
    "                    embeddings[self.word2index[word]] = vector\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "        return embeddings\n",
    "    def n_words(self):\n",
    "        return len(self.vocab_words)\n",
    "\n",
    "    def n_labels(self):\n",
    "        return len(self.all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc5dfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path) -> list:\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    id_data = data[id_col_name]\n",
    "    text_data = data[text_col_name]\n",
    "\n",
    "    hierarchical_label_data = []\n",
    "    label_data = data[label_col_name].tolist()\n",
    "    \n",
    "    output = []\n",
    "    for i in tqdm.tqdm(range(len(label_data)), desc=\"Reading data\"):\n",
    "        labels = label_data[i].split(';')\n",
    "        print(labels)\n",
    "        output.append((text_data[i], labels, id_data[i]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a07b35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached_data(file_path: str) -> tuple:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        f.close()\n",
    "    return data[\"vocab\"], data[\"training_data\"], data[\"valid_data\"], data[\"test_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f6718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    cache_folder = \"{}/{}\".format(cache_dir, \"mimic3_single_50\")\n",
    "#     device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    save_vocab_file_name = \"{}.pkl\".format(\"save_vocab\")\n",
    "    cached_file_name = os.path.join(cache_folder, save_vocab_file_name)\n",
    "    if os.path.exists(cached_file_name):\n",
    "        vocab, training_data, valid_data, test_data = load_cached_data(cached_file_name)\n",
    "        data = training_data + valid_data + test_data\n",
    "        labels = []\n",
    "        for (feature, l, _) in data:\n",
    "            labels.extend(l)\n",
    "        unique_labels=list(set(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "        labels = unique_labels\n",
    "        vocab.update_labels(labels)\n",
    "        print(\"Loaded vocab and data from file\")\n",
    "    else:\n",
    "        training_data = read_data( data_dir + \"/train.csv\")\n",
    "        valid_data = read_data( data_dir + \"/dev.csv\")\n",
    "        test_data = read_data( data_dir + \"/test.csv\")\n",
    "    #     print(len(training_data),len(valid_data),len(test_data))\n",
    "        data = training_data + valid_data + test_data\n",
    "        labels = []\n",
    "        for (feature, l, _) in data:\n",
    "            labels.extend(l)\n",
    "        unique_labels=list(set(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "        labels = unique_labels\n",
    "        vocab = Vocab(data, labels,\n",
    "                          min_word_frequency,\n",
    "                          word_embedding_mode=embedding_mode,\n",
    "                          word_embedding_file=embedding_file)\n",
    "        print(\"Preparing the vocab\")\n",
    "        vocab.prepare_vocab()\n",
    "        saved_objects = {\"vocab\": vocab,\n",
    "                         \"training_data\": training_data,\n",
    "                         \"valid_data\": valid_data,\n",
    "                         \"test_data\": test_data}\n",
    "        with open(cached_file_name, 'wb') as f:\n",
    "            pickle.dump(saved_objects, f, pickle.HIGHEST_PROTOCOL)\n",
    "            f.close()\n",
    "        print(\"Saved vocab and data to files\")\n",
    "    return training_data, valid_data, test_data, vocab, cached_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb8dcb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab and data from file\n"
     ]
    }
   ],
   "source": [
    "training_data, valid_data, test_data, vocab, saved_vocab_path = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "095d5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5278, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "pos_labels = defaultdict(int)\n",
    "for val in training_data:\n",
    "    labels = val[1]\n",
    "    for label in labels:\n",
    "        pos_labels[label]+=1\n",
    "\n",
    "for key in pos_labels.keys():\n",
    "    pos_labels[key] = (len(training_data)-pos_labels[key])/pos_labels[key]\n",
    "\n",
    "weights = []\n",
    "for key in vocab.label2index.keys():\n",
    "    weights.append(pos_labels[key])\n",
    "# print(weights)\n",
    "weights = torch.FloatTensor(weights)\n",
    "weights = weights.to(device)\n",
    "print(weights.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55dbe24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_mode: str,\n",
    "                 pretrained_word_embeddings: torch.Tensor,\n",
    "                 vocab_size: int,\n",
    "                 embedding_size: int):\n",
    "        \n",
    "        self.embedding_mode = embedding_mode\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embeddings.weight = nn.Parameter(copy.deepcopy(pretrained_word_embeddings), requires_grad=False)\n",
    "        self.output_size = embedding_size\n",
    "        \n",
    "    def forward(self, batch_data: torch.LongTensor): # batch_data shape: [batch_size x max_padded_text_length]\n",
    "        embeds = self.embeddings(batch_data)  # [batch_size x max_seq_size x embedding_size]\n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca2f6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, size: int, n_labels=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.d_a = d_a\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "#         self.linear = nn.Linear(self.size, self.n_labels, bias = True)\n",
    "        \n",
    "        self.first_linear = nn.Linear(self.size, self.d_a, bias=False)\n",
    "        self.second_linear = nn.Linear(self.d_a, n_labels, bias=False)\n",
    "        self.third_linear = nn.Linear(self.size , n_labels, bias=True)\n",
    "        self._init_weights(mean=0.0, std=0.03)\n",
    "\n",
    "    def _init_weights(self, mean=0.0, std=0.03) -> None:\n",
    "#         torch.nn.init.normal_(self.linear.weight,mean, std)\n",
    "#         self.linear.bias.data.fill_(0)\n",
    "        torch.nn.init.normal_(self.first_linear.weight, mean, std)\n",
    "        torch.nn.init.normal_(self.second_linear.weight, mean, std)\n",
    "        torch.nn.init.normal_(self.third_linear.weight, mean, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print('RNN output:- ', x.shape)\n",
    "        weights = torch.tanh(self.first_linear(x))\n",
    "#         print('first linear:- (Z)',weights.shape)\n",
    "        att_weights = self.second_linear(weights)\n",
    "        att_weights = F.softmax(att_weights, 1).transpose(1, 2)\n",
    "#         print('second linear:- (A)',att_weights.shape)\n",
    "        weighted_output = att_weights @ x\n",
    "#         print('V:- ',weighted_output.shape)\n",
    "        weighted_output = self.third_linear.weight.mul(weighted_output).sum(dim=2).add(self.third_linear.bias)\n",
    "#         print('final shpae:- ', weighted_output.shape)\n",
    "#         weighted_output = x.sum(dim = 1)\n",
    "#         print('wo before linear:- ', weighted_output.shape)\n",
    "#         weighted_output = self.linear(x)   \n",
    "#         print('wo:- ', weighted_output.shape)\n",
    "        return weighted_output\n",
    "        \n",
    "#         return weighted_output, att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64846a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_attention(model, all_output):\n",
    "    attention_outputs = model.attention(all_output)\n",
    "    weighted_outputs = attention_outputs\n",
    "#     attention_weights = attention_outputs[1]\n",
    "#     return weighted_outputs, attention_weights\n",
    "    return weighted_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46f47efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab: Vocab):\n",
    "        super(RNN, self).__init__()\n",
    "        self.vocab_size = vocab.n_words()\n",
    "        self.vocab = vocab\n",
    "        self.use_last_hidden_state = use_last_hidden_state\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bool(bidirectional)\n",
    "        self.n_directions = int(self.bidirectional) + 1\n",
    "        self.output_size = self.hidden_size * self.n_directions\n",
    "        self.rnn_model = rnn_model\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.embedding = EmbeddingLayer(embedding_mode=embedding_mode,\n",
    "                                     embedding_size=embedding_size,\n",
    "                                     pretrained_word_embeddings=vocab.word_embeddings,\n",
    "                                     vocab_size=vocab.n_words())\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.embedding.output_size, self.hidden_size, num_layers=self.n_layers,\n",
    "                               bidirectional=self.bidirectional, dropout=(self.dropout if self.n_layers > 1 else 0))\n",
    "        \n",
    "        self.use_dropout = dropout > 0\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attention = AttentionLayer(size=self.output_size, n_labels=self.vocab.n_labels())\n",
    "\n",
    "    def init_hidden(self, batch_size: int = 32) -> Variable:\n",
    "        # [(n_layers x n_directions) x batch_size x hidden_size]\n",
    "        h = Variable(torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)).to(device)\n",
    "        c = Variable(torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)).to(device)\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, batch_data: torch.LongTensor, lengths: torch.LongTensor) -> tuple:\n",
    "        batch_size = batch_data.size()[0]\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.embedding(batch_data)\n",
    "        \n",
    "        if self.use_dropout:\n",
    "            embeds = self.dropout(embeds)\n",
    "            \n",
    "        self.rnn.flatten_parameters()\n",
    "        \n",
    "        embeds = pack_padded_sequence(embeds, lengths.cpu(), batch_first=True)\n",
    "\n",
    "        rnn_output, hidden = self.rnn(embeds, hidden)\n",
    "#         print(hidden[0].shape)\n",
    "        if self.rnn_model.lower() == \"lstm\":\n",
    "            hidden = hidden[0]\n",
    "\n",
    "        rnn_output = pad_packed_sequence(rnn_output)[0]\n",
    "#         print(rnn_output.shape)\n",
    "\n",
    "        rnn_output = rnn_output.permute(1, 0, 2)\n",
    "                \n",
    "        weighted_outputs = perform_attention(self, rnn_output)\n",
    "        \n",
    "#         print('lro:-',last_rnn_output.shape)\n",
    "        return weighted_outputs\n",
    "\n",
    "    def get_last_hidden_output(self, hidden):\n",
    "        hidden_forward = hidden[-1]\n",
    "        hidden_backward = hidden[0]        \n",
    "        last_rnn_output = torch.cat((hidden_forward, hidden_backward), 1)\n",
    "        return last_rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1d85c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): EmbeddingLayer(\n",
       "    (embeddings): Embedding(66322, 100)\n",
       "  )\n",
       "  (rnn): LSTM(100, 256, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (attention): AttentionLayer(\n",
       "    (first_linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (second_linear): Linear(in_features=256, out_features=50, bias=False)\n",
       "    (third_linear): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(vocab)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c79c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_data: list, vocab, sort: bool = True):\n",
    "        super(TextDataset, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.multilabel = multilabel\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.min_seq_length = min_seq_length\n",
    "        self.PAD_ID = self.vocab.index_of_word(self.vocab.PAD_TOKEN) # 0\n",
    "        indexed_data = []\n",
    "        self.n_instances = len(text_data)\n",
    "        print('Length of text data:- ', self.n_instances)\n",
    "        self.n_total_tokens = 0\n",
    "\n",
    "        n_label_level = 1\n",
    "        self.label_count = dict()\n",
    "        self.labels = set()\n",
    "        for text, labels, _id in tqdm.tqdm(text_data, unit=\"samples\", desc=\"Processing data\"):\n",
    "            label_list = []\n",
    "            for label in labels:\n",
    "                if label in self.vocab.label2index:\n",
    "                    label = self.vocab.index_of_label(label)\n",
    "                    if label not in self.label_count:\n",
    "                        self.label_count[label] = 1\n",
    "                    else:\n",
    "                        self.label_count[label] += 1\n",
    "                    self.labels.add(label)\n",
    "                    label_list.append(label)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if len(label_list) == 0:\n",
    "                continue\n",
    "\n",
    "            word_seq = []\n",
    "            sent_words = text.strip().split()\n",
    "#             print('sent words:- ', len(sent_words))\n",
    "            for word in sent_words:\n",
    "                word_idx = vocab.index_of_word(word)\n",
    "                word_seq.append(word_idx)\n",
    "                self.n_total_tokens += 1\n",
    "                if len(word_seq) >= self.max_seq_length:\n",
    "                    break\n",
    "            if len(word_seq) > 0:\n",
    "                indexed_data.append((word_seq, label_list, _id))\n",
    "#             print('word sequence:- ', len(word_seq))\n",
    "\n",
    "        if sort:\n",
    "            self.indexed_data = sorted(indexed_data, key=lambda x: -len(x[0]))\n",
    "        else:\n",
    "            self.indexed_data = indexed_data\n",
    "            self.shuffle_data()\n",
    "\n",
    "        self.labels = sorted(list(self.labels))\n",
    "        self.size = len(self.indexed_data)\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        random.shuffle(self.indexed_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        word_seq, label_list, _id = self.indexed_data[index]\n",
    "        if len(word_seq) > self.max_seq_length:\n",
    "            word_seq = word_seq[:self.max_seq_length]\n",
    "\n",
    "        one_hot_label_list = [0] * self.vocab.n_labels()\n",
    "        for label in label_list:\n",
    "            one_hot_label_list[label] = 1\n",
    "        return word_seq, one_hot_label_list, _id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b54069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_and_cache_data(train_data, valid_data, test_data, vocab, saved_data_file_path):\n",
    "    if os.path.exists(saved_data_file_path):\n",
    "        try:\n",
    "            with open(saved_data_file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                data[\"train\"].multilabel = bool(multilabel)\n",
    "                data[\"valid\"].multilabel = bool(multilabel)\n",
    "                data[\"test\"].multilabel = bool(multilabel)\n",
    "\n",
    "                return data[\"train\"], data[\"valid\"], data[\"test\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Build train/valid/test data loaders\n",
    "    train_dataset = TextDataset(train_data, vocab,sort=True)\n",
    "\n",
    "    valid_dataset = TextDataset(valid_data, vocab,sort=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, vocab, sort=True)\n",
    "    # try:\n",
    "    with open(saved_data_file_path, 'wb') as f:\n",
    "        data = {\"train\": train_dataset, \"valid\": valid_dataset, \"test\": test_dataset}\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8167d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataLoader(DataLoader):\n",
    "    def __init__(self, vocab, **kwargs):\n",
    "        super(TextDataLoader, self).__init__( **kwargs)\n",
    "        self.collate_fn = self._collate_fn # recieves is a list of tuples of (word seq, one_hot_label_list, _id)\n",
    "        self.PAD_ID = vocab.index_of_word(vocab.PAD_TOKEN)\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "#         print('collate_fn called:- ')\n",
    "#         print(len(batch[0][0]))\n",
    "        length_batch = []\n",
    "\n",
    "#         self.first_linear = nn.Linear(self.size, self.d_a, bias=False)\n",
    "#         self.second_linear = nn.Linear(self.d_a, n_labels, bias=False)\n",
    "#         self.third_linear = nn.Linear(self.size , n_labels, bias=True)\n",
    "        feature_batch = []\n",
    "        label_batch = []\n",
    "\n",
    "        id_batch = []\n",
    "        multilabel = True\n",
    "        for features, labels, _id in batch: # labels are one-hot encoded\n",
    "            feature_length = len(features)\n",
    "            feature_batch.append(torch.LongTensor(features))\n",
    "\n",
    "            length_batch.append(feature_length)\n",
    "            label_batch.append(labels)\n",
    "            id_batch.append(_id)\n",
    "\n",
    "        feature_batch, label_batch, length_batch, id_batch = \\\n",
    "            self.sort_batch(feature_batch, label_batch, length_batch, id_batch)\n",
    "        \n",
    "        padded_batch = pad_sequence(feature_batch, batch_first=True)\n",
    "        feature_batch = torch.LongTensor(padded_batch)\n",
    "        \n",
    "        label_batch = np.stack(label_batch, axis=0)\n",
    "        \n",
    "        label_batch = torch.FloatTensor(label_batch.tolist()) # converts list to tensor\n",
    "#         print('before longtensor length batch',length_batch)\n",
    "        length_batch = torch.LongTensor(length_batch)\n",
    "#         print('after longtensor length batch',length_batch)\n",
    "\n",
    "#         print('shape of feature batch:-', feature_batch.shape)\n",
    "#         print('length batch:-', length_batch)\n",
    "#         print('shape of label batch:-', label_batch.shape)\n",
    "#         print('id batch:-', id_batch)\n",
    "#         print('type of length batch:- ', type(length_batch))\n",
    "        return feature_batch, label_batch, length_batch, id_batch\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_batch(features, labels, lengths, id_batch):\n",
    "        sorted_indices = sorted(range(len(features)), key=lambda i: features[i].size(0), reverse=True)\n",
    "        sorted_features = []\n",
    "        sorted_labels = []\n",
    "        sorted_lengths = []\n",
    "        sorted_ids = []\n",
    "\n",
    "        for index in sorted_indices:\n",
    "            sorted_features.append(features[index])\n",
    "\n",
    "            sorted_labels.append(labels[index])\n",
    "            sorted_lengths.append(lengths[index])\n",
    "\n",
    "            sorted_ids.append(id_batch[index])\n",
    "\n",
    "        return sorted_features, sorted_labels, sorted_lengths, sorted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f66ab735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self,model: torch.nn.Module, vocab, criterions, n_training_labels):\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.index_to_label = vocab.index2label\n",
    "        self.multilabel = multilabel\n",
    "        self.criterions = criterions\n",
    "        self.n_training_labels = n_training_labels\n",
    "\n",
    "    def evaluate(self, dataloader: TextDataLoader) -> dict:\n",
    "\n",
    "        self.model.eval()\n",
    "        pred_probs = []\n",
    "        true_labels = []\n",
    "        ids = []\n",
    "\n",
    "        losses = []\n",
    "        all_loss_list = []\n",
    "\n",
    "        for text_batch, label_batch, length_batch, id_batch in tqdm.tqdm(dataloader, unit=\"batches\", desc=\"Evaluating\"):\n",
    "\n",
    "            text_batch = text_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            length_batch = length_batch.to(device)\n",
    "            \n",
    "            true_labels.extend(label_batch.cpu().numpy())\n",
    "            ids.extend(id_batch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(text_batch, length_batch)\n",
    "#                 output, attn_weights = self.model(text_batch, length_batch)\n",
    "\n",
    "            probs = [None] * len(output)\n",
    "            \n",
    "            loss = self.criterions(output, label_batch)\n",
    "            output = torch.sigmoid(output)\n",
    "            all_loss_list.append(loss.item())\n",
    "            output = output.detach().cpu().numpy()\n",
    "            probs = output.tolist()\n",
    "            pred_probs.extend(output)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        scores = OrderedDict()\n",
    "        scores = calculate_eval_metrics(ids, true_labels, pred_probs, self.multilabel)\n",
    "        scores[\"loss\"] = np.mean(all_loss_list).item()\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0075522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eval_metrics(ids, true_labels, pred_probs, is_multilabel):\n",
    "    true_labels = np.asarray(true_labels)\n",
    "    pred_probs = np.asarray(pred_probs)\n",
    "    pred_labels = np.rint(pred_probs)\n",
    "    \n",
    "    macro_scores = calculate_scores(true_labels, pred_labels, pred_probs, \"macro\", is_multilabel)\n",
    "    micro_scores = calculate_scores(true_labels, pred_labels, pred_probs, \"micro\", is_multilabel)\n",
    "    \n",
    "    scores = macro_scores\n",
    "    scores.update(micro_scores)\n",
    "    scores[\"ids\"] = ids\n",
    "    scores[\"true_labels\"] = true_labels\n",
    "    scores[\"pred_probs\"] = pred_probs\n",
    "    return scores\n",
    "\n",
    "def calculate_scores(true_labels, pred_labels, pred_probs, average=\"macro\", is_multilabel=True):\n",
    "    max_size = min(len(true_labels), len(pred_labels))\n",
    "    true_labels = true_labels[: max_size]\n",
    "    pred_labels = pred_labels[: max_size]\n",
    "    pred_probs = pred_probs[: max_size]\n",
    "    p_1 = 0\n",
    "    p_5 = 0\n",
    "    p_8 = 0\n",
    "    p_10 = 0\n",
    "    p_15 = 0\n",
    "    if pred_probs is not None:\n",
    "        if average == \"macro\":\n",
    "            accuracy = macro_accuracy(true_labels, pred_labels)  # categorical accuracy\n",
    "            precision, recall, f1 = macro_f1(true_labels, pred_labels)\n",
    "            p_ks = precision_at_k(true_labels, pred_probs, [1, 5, 8, 10, 15])\n",
    "            p_1 = p_ks[0]\n",
    "            p_5 = p_ks[1]\n",
    "            p_8 = p_ks[2]\n",
    "            p_10 = p_ks[3]\n",
    "            p_15 = p_ks[4]\n",
    "\n",
    "        else:\n",
    "            accuracy = micro_accuracy(true_labels, pred_labels)\n",
    "            precision, recall, f1 = micro_f1(true_labels, pred_labels)\n",
    "        auc_score = roc_auc(true_labels, pred_probs, average)\n",
    "    else:\n",
    "        auc_score = -1\n",
    "\n",
    "    output = {\"{}_precision\".format(average): precision, \"{}_recall\".format(average): recall,\n",
    "              \"{}_f1\".format(average): f1, \"{}_accuracy\".format(average): accuracy,\n",
    "              \"{}_auc\".format(average): auc_score, \"{}_P@1\".format(average): p_1, \"{}_P@5\".format(average): p_5,\n",
    "              \"{}_P@8\".format(average): p_8, \"{}_P@10\".format(average): p_10, \"{}_P@15\".format(average): p_15}\n",
    "    \n",
    "    return output\n",
    "\n",
    "def average_scores(scores):\n",
    "    avg_scores = dict()\n",
    "    for key in scores:\n",
    "        if key.startswith(\"level\"):\n",
    "            for metric in scores[key]:\n",
    "                if metric.startswith(\"macro\") or metric.startswith(\"micro\") or metric == \"loss\":\n",
    "                    if metric not in avg_scores:\n",
    "                        avg_scores[metric] = []\n",
    "                    avg_scores[metric].append(scores[key][metric])\n",
    "\n",
    "    for metric in avg_scores:\n",
    "        avg_scores[metric] = sum(avg_scores[metric]) / len(avg_scores[metric])\n",
    "    return avg_scores\n",
    "\n",
    "def union_size(x, y, axis):\n",
    "    return np.logical_or(x, y).sum(axis=axis).astype(float)\n",
    "\n",
    "\n",
    "def intersect_size(x, y, axis):\n",
    "    return np.logical_and(x, y).sum(axis=axis).astype(float)\n",
    "\n",
    "def macro_precision(true_labels, pred_labels):\n",
    "    num = intersect_size(true_labels, pred_labels, 0) / (pred_labels.sum(axis=0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "\n",
    "def macro_recall(true_labels, pred_labels):\n",
    "    num = intersect_size(true_labels, pred_labels, 0) / (true_labels.sum(axis=0) + 1e-10)\n",
    "#     print('macro recall num:- ', num)\n",
    "    return np.mean(num)\n",
    "\n",
    "\n",
    "def macro_f1(true_labels, pred_labels):\n",
    "    prec = macro_precision(true_labels, pred_labels)\n",
    "    rec = macro_recall(true_labels, pred_labels)\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.\n",
    "    else:\n",
    "        f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def macro_accuracy(true_labels, pred_labels):\n",
    "    num = intersect_size(true_labels, pred_labels, 0) / (union_size(true_labels, pred_labels, 0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "\n",
    "def micro_precision(true_labels, pred_labels):\n",
    "    flat_true = true_labels.ravel()\n",
    "    flat_pred = pred_labels.ravel()\n",
    "    if flat_pred.sum(axis=0) == 0:\n",
    "        return 0.0\n",
    "    return intersect_size(flat_true, flat_pred, 0) / flat_pred.sum(axis=0)\n",
    "\n",
    "\n",
    "def micro_recall(true_labels, pred_labels):\n",
    "#     print('true_labels:- ', true_labels)\n",
    "#     print('pred labels:- ', pred_labels)\n",
    "#     print('labels shape:- ',true_labels.shape)\n",
    "    flat_true = true_labels.ravel()\n",
    "    flat_pred = pred_labels.ravel()\n",
    "#     count=0\n",
    "#     all_ = 0\n",
    "#     for i in range(len(true_labels)):\n",
    "#         if flat_true[i]==1.0:\n",
    "#             all_+=1\n",
    "#             if flat_true[i]==flat_pred[i]:\n",
    "#                 count+=1\n",
    "#     print('all ones:- ', all_)\n",
    "#     print('correct preds:- ', count)\n",
    "#     print('flattened shape:- ', flat_true.shape)\n",
    "    return intersect_size(flat_true, flat_pred, 0) / flat_true.sum(axis=0)\n",
    "\n",
    "def micro_f1(true_labels, pred_labels):\n",
    "    prec = micro_precision(true_labels, pred_labels)\n",
    "    rec = micro_recall(true_labels, pred_labels)\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.\n",
    "    else:\n",
    "        f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def micro_accuracy(true_labels, pred_labels):\n",
    "    flat_true = true_labels.ravel()\n",
    "    flat_pred = pred_labels.ravel()\n",
    "    return intersect_size(flat_true, flat_pred, 0) / union_size(flat_true, flat_pred, 0)\n",
    "\n",
    "\n",
    "def recall_at_k(true_labels, pred_probs, k):\n",
    "    # num true labels in top k predictions / num true labels\n",
    "    sortd = np.argsort(pred_probs)[:, ::-1]\n",
    "    topk = sortd[:, :k]\n",
    "\n",
    "    # get recall at k for each example\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = true_labels[i, tk].sum()\n",
    "        denom = true_labels[i, :].sum()\n",
    "        vals.append(num_true_in_top_k / float(denom))\n",
    "\n",
    "    vals = np.array(vals)\n",
    "    vals[np.isnan(vals)] = 0.\n",
    "\n",
    "    return np.mean(vals)\n",
    "\n",
    "\n",
    "def precision_at_k(true_labels, pred_probs, ks=[1, 5, 8, 10, 15]):\n",
    "    # num true labels in top k predictions / k\n",
    "    sorted_pred = np.argsort(pred_probs)[:, ::-1]\n",
    "    output = []\n",
    "    for k in ks:\n",
    "        topk = sorted_pred[:, :k]\n",
    "\n",
    "        # get precision at k for each example\n",
    "        vals = []\n",
    "        for i, tk in enumerate(topk):\n",
    "            if len(tk) > 0:\n",
    "                num_true_in_top_k = true_labels[i, tk].sum()\n",
    "                denom = len(tk)\n",
    "                vals.append(num_true_in_top_k / float(denom))\n",
    "\n",
    "        output.append(np.mean(vals))\n",
    "    return output\n",
    "\n",
    "\n",
    "def roc_auc(true_labels, pred_probs, average=\"macro\"):\n",
    "    if pred_probs.shape[0] <= 1:\n",
    "        return\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    if average == \"macro\":\n",
    "        # get AUC for each label individually\n",
    "        relevant_labels = []\n",
    "        auc_labels = {}\n",
    "        for i in range(true_labels.shape[1]):\n",
    "            # only if there are true positives for this label\n",
    "            if true_labels[:, i].sum() > 0:\n",
    "                fpr[i], tpr[i], _ = roc_curve(true_labels[:, i], pred_probs[:, i])\n",
    "                if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
    "                    auc_score = auc(fpr[i], tpr[i])\n",
    "                    if not np.isnan(auc_score):\n",
    "                        auc_labels[\"auc_%d\" % i] = auc_score\n",
    "                        relevant_labels.append(i)\n",
    "\n",
    "        # macro-AUC: just average the auc scores\n",
    "        aucs = []\n",
    "        for i in relevant_labels:\n",
    "            aucs.append(auc_labels['auc_%d' % i])\n",
    "        score = np.mean(aucs)\n",
    "    else:\n",
    "        # micro-AUC: just look at each individual prediction\n",
    "        flat_pred = pred_probs.ravel()\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(true_labels.ravel(), flat_pred)\n",
    "        score = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def multiclass_roc_auc(true_labels, pred_labels, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(true_labels)\n",
    "    true_labels = lb.transform(true_labels)\n",
    "    pred_labels = lb.transform(pred_labels)\n",
    "    return roc_auc_score(true_labels, pred_labels, average=average)\n",
    "\n",
    "def average_scores(scores):\n",
    "    avg_scores = dict()\n",
    "    for key in scores:\n",
    "        if key.startswith(\"level\"):\n",
    "            for metric in scores[key]:\n",
    "                if metric.startswith(\"macro\") or metric.startswith(\"micro\") or metric == \"loss\":\n",
    "                    if metric not in avg_scores:\n",
    "                        avg_scores[metric] = []\n",
    "                    avg_scores[metric].append(scores[key][metric])\n",
    "\n",
    "    for metric in avg_scores:\n",
    "        avg_scores[metric] = sum(avg_scores[metric]) / len(avg_scores[metric])\n",
    "    return avg_scores\n",
    "\n",
    "def normalise_labels(labels, n_label):\n",
    "    norm_labels = []\n",
    "    for label in labels:\n",
    "        one_hot_vector_label = [0] * n_label\n",
    "        one_hot_vector_label[label] = 1\n",
    "        norm_labels.append(one_hot_vector_label)\n",
    "    return np.asarray(norm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e2041d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module,\n",
    "                 train_dataloader: TextDataLoader,\n",
    "                 valid_dataloader: TextDataLoader,\n",
    "                 test_dataloader: TextDataLoader,\n",
    "                 criterions,\n",
    "                 optimiser,\n",
    "                 scheduler,\n",
    "                 vocab,\n",
    "                 checkpoint_path,\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.criterions = criterions\n",
    "        self.optimiser = optimiser\n",
    "        self.scheduler = scheduler\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.multilabel = multilabel\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.n_training_labels = n_labels\n",
    "        self.main_metric = main_metric\n",
    "        self.start_epoch = 0\n",
    "\n",
    "    def train_single_epoch(self, index):\n",
    "        self.model.train()\n",
    "        self.train_dataloader.dataset.shuffle_data()\n",
    "        losses = []\n",
    "        true_labels = []\n",
    "        pred_probs = []\n",
    "        ids = []\n",
    "        all_loss_list = []\n",
    "        progress_bar = tqdm.tqdm(self.train_dataloader, unit=\"batches\", desc=\"Training at epoch #{}\".format(index))\n",
    "        progress_bar.clear()\n",
    "        self.optimiser.zero_grad()\n",
    "        batch_id = 0\n",
    "\n",
    "        for text_batch, label_batch, length_batch, id_batch in progress_bar:\n",
    "            batch_id += 1\n",
    "            text_batch = text_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            length_batch = length_batch.to(device)\n",
    "\n",
    "#             output, attn_weights = self.model(text_batch, length_batch)\n",
    "            \n",
    "            output = self.model(text_batch, length_batch)\n",
    "            true_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "            ids.extend(id_batch)\n",
    "\n",
    "            loss = self.criterions(output, label_batch)\n",
    "            output = torch.sigmoid(output)\n",
    "            all_loss_list.append(loss.item())\n",
    "            output = output.detach().cpu().numpy()\n",
    "            pred_probs.extend(output)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "#             print('pred probs:- ', output)\n",
    "#             print('true labels:- ', label_batch)\n",
    "\n",
    "            self.optimiser.step()\n",
    "#             self.lr_scheduler.step()\n",
    "            self.optimiser.zero_grad()\n",
    "        \n",
    "#         print('pred labels', pred_probs[0:3])\n",
    "\n",
    "        scores = OrderedDict()\n",
    "        scores = calculate_eval_metrics(ids, true_labels, pred_probs, self.multilabel)\n",
    "        scores[\"loss\"] = np.mean(all_loss_list).item()\n",
    "\n",
    "        progress_bar.refresh(True)\n",
    "        progress_bar.clear(True)\n",
    "        progress_bar.close()\n",
    "        keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1', 'macro_P@5', 'macro_P@8', 'macro_P@15', 'loss']\n",
    "        print('lr {}'.format(self.optimiser.param_groups[0]['lr']))\n",
    "        print({k:v for k,v in scores.items() if k in keys})\n",
    "        return scores\n",
    "\n",
    "    @staticmethod\n",
    "    def format_number(number):\n",
    "        return abs(round(number, ndigits=ndigits))\n",
    "\n",
    "    def train(self, n_epoch: int = 100):\n",
    "        evaluator = Evaluator(self.model, self.vocab, self.criterions, self.n_training_labels)\n",
    "        for e in range(self.start_epoch + 1, n_epoch + 1):\n",
    "            train_scores = self.train_single_epoch(e)\n",
    "#             valid_scores = evaluator.evaluate(self.valid_dataloader)\n",
    "            test_scores = evaluator.evaluate(self.test_dataloader)\n",
    "            self.scheduler.step(test_scores[\"loss\"])\n",
    "            print('lr {}'.format(self.optimiser.param_groups[0]['lr']))\n",
    "            keys = ['micro_auc', 'macro_auc', 'micro_f1', 'macro_f1', 'macro_P@5', 'macro_P@8', 'macro_P@15', 'loss']\n",
    "            print({k:v for k,v in test_scores.items() if k in keys})\n",
    "            print('\\n\\n')\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee0e163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_model(train_data, valid_data, test_data, vocab, saved_data_file_path=None,checkpoint_path=None):\n",
    "    model = RNN(vocab)\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset, valid_dataset, test_dataset = _load_and_cache_data(train_data, valid_data, test_data,\n",
    "                                                                      vocab, saved_data_file_path)\n",
    "    train_dataloader = TextDataLoader(dataset=train_dataset, vocab=vocab, batch_size=batch_size)\n",
    "\n",
    "    valid_dataloader = TextDataLoader(dataset=valid_dataset, vocab=vocab, batch_size=batch_size)\n",
    "\n",
    "    test_dataloader = TextDataLoader(dataset=test_dataset, vocab=vocab, batch_size=batch_size)\n",
    "\n",
    "    optimiser = torch.optim.AdamW(model.parameters(), lr = 0.001)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', patience=1)    \n",
    "    \n",
    "    criterions = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(2))\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      valid_dataloader=valid_dataloader,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      criterions=criterions,\n",
    "                      optimiser=optimiser,\n",
    "                      scheduler = scheduler,\n",
    "                      vocab=vocab,\n",
    "                      checkpoint_path=checkpoint_path)\n",
    "    best_model = trainer.train(n_epoch=n_epoch)\n",
    "\n",
    "    evaluator = Evaluator(model=best_model,vocab=vocab,criterions=criterions,\n",
    "                          n_training_labels=n_labels)\n",
    "\n",
    "    del model, optimiser, evaluator, trainer, criterions\n",
    "    return best_model, scores  # either on valid or test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13164513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_validation(training_data, valid_data, test_data, vocab, saved_data_file_path):\n",
    "    best_model, scores = _train_model(\n",
    "        train_data=training_data, valid_data=valid_data, test_data=test_data,\n",
    "        vocab=vocab, saved_data_file_path=saved_data_file_path, checkpoint_path=\"../model/checkpoint.pkl\")\n",
    "\n",
    "    return best_model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3473ef67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01878046989440918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #1",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ca93336a3140b095f83d7c9c60f5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #1:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.22754516129314215, 'macro_auc': 0.7257383154043049, 'macro_P@5': 0.3991817505578974, 'macro_P@8': 0.3327547731217456, 'macro_P@15': 0.2479295809571039, 'micro_f1': 0.3590044964397491, 'micro_auc': 0.7900534740264826, 'loss': 0.4548525983401438}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018258333206176758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780cef7378424524b2f6a6cde95c8d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.3119578574092687, 'macro_auc': 0.8068498543512816, 'macro_P@5': 0.4683632157316368, 'macro_P@8': 0.3875072296124928, 'macro_P@15': 0.2876421823790245, 'micro_f1': 0.4266519418369225, 'micro_auc': 0.8483854356706886, 'loss': 0.418168379501863}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01826167106628418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #2",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6ff2f777974933a8c6f3b34157710d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #2:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.4681839216955071, 'macro_auc': 0.8578421483135082, 'macro_P@5': 0.5465410364492933, 'macro_P@8': 0.44410178527151006, 'macro_P@15': 0.30751301760476074, 'micro_f1': 0.5718088463083013, 'micro_auc': 0.9007597033324726, 'loss': 0.33670645575278363}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01806020736694336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0476fbb64240708df68c8f18ced49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.5656584059014245, 'macro_auc': 0.8896869463074637, 'macro_P@5': 0.6112203585887798, 'macro_P@8': 0.49942163100057835, 'macro_P@15': 0.3389627915943706, 'micro_f1': 0.6401588702559577, 'micro_auc': 0.9178320806995225, 'loss': 0.3180786573074081}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017992734909057617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #3",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e671e01aa1345638b228e6963ee1d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #3:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.5840969109970001, 'macro_auc': 0.9028615089210945, 'macro_P@5': 0.6140342177039426, 'macro_P@8': 0.4955058269278453, 'macro_P@15': 0.3319282585337631, 'micro_f1': 0.6581529689385284, 'micro_auc': 0.933460059465855, 'loss': 0.2821390558137253}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01809096336364746,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f21aa619b6341f982518a3ba87ef6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6358289749940195, 'macro_auc': 0.9126141042381765, 'macro_P@5': 0.6496240601503759, 'macro_P@8': 0.52834008097166, 'macro_P@15': 0.35288220551378446, 'micro_f1': 0.682566404788627, 'micro_auc': 0.9360752010881085, 'loss': 0.2828578608957204}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017838478088378906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #4",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaf2cd4a88f4d5cb3764c5bcd118bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #4:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6186828677874759, 'macro_auc': 0.9184140033706834, 'macro_P@5': 0.6345152491941483, 'macro_P@8': 0.512924621869576, 'macro_P@15': 0.3389536325316142, 'micro_f1': 0.6842403628117915, 'micro_auc': 0.9440340657275609, 'loss': 0.26059475173003116}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01789093017578125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47d29657afc487ab5317cf3bb24e0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.654526486452205, 'macro_auc': 0.9199654226480638, 'macro_P@5': 0.6572585309427416, 'macro_P@8': 0.5360034702139965, 'macro_P@15': 0.3561596298438404, 'micro_f1': 0.6995544239338001, 'micro_auc': 0.9412792553544298, 'loss': 0.2732479241761294}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017886638641357422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #5",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bc2251ba284599a7f9d551cfeb5a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #5:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6364953033312252, 'macro_auc': 0.925435196754298, 'macro_P@5': 0.6438383337465906, 'macro_P@8': 0.5199448301512521, 'macro_P@15': 0.3419786759236301, 'micro_f1': 0.6957966335454345, 'micro_auc': 0.9484776468666495, 'loss': 0.2514623307545666}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01796865463256836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc46932aa064f669208b85228445add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6654281431541194, 'macro_auc': 0.9243064482654849, 'macro_P@5': 0.6629265471370733, 'macro_P@8': 0.5387507229612493, 'macro_P@15': 0.35793329477540003, 'micro_f1': 0.7065820425191958, 'micro_auc': 0.9443640314282997, 'loss': 0.2691144353964112}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01793837547302246,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #6",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04d7d5b7e8344b1868f3533859d4e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #6:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6506117866487523, 'macro_auc': 0.9308519813324625, 'macro_P@5': 0.6504835110339697, 'macro_P@8': 0.5255083064716092, 'macro_P@15': 0.34477229523101083, 'micro_f1': 0.706081186817314, 'micro_auc': 0.9519217545648224, 'loss': 0.24312253614423773}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01781296730041504,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd139120e014818b8a5b5cbd6906a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6666913874381774, 'macro_auc': 0.9255708072249207, 'macro_P@5': 0.6687102371312897, 'macro_P@8': 0.5431607865818392, 'macro_P@15': 0.35878156930788513, 'micro_f1': 0.7050601556970983, 'micro_auc': 0.9454557647343709, 'loss': 0.26379375701600855}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01774120330810547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #7",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9546039084460093c315a3b9de9515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #7:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6668120851079968, 'macro_auc': 0.9355642886056635, 'macro_P@5': 0.6587155963302752, 'macro_P@8': 0.5306843540788495, 'macro_P@15': 0.3462682866352591, 'micro_f1': 0.7150088874567322, 'micro_auc': 0.954644468604605, 'loss': 0.2376098987966658}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01777482032775879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f5f2ebe7154d0cb4dd6e644d91f1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6779272105907668, 'macro_auc': 0.9275698025025229, 'macro_P@5': 0.6667437825332562, 'macro_P@8': 0.5415702718334298, 'macro_P@15': 0.35885868517447467, 'micro_f1': 0.702651515151515, 'micro_auc': 0.9456529532883726, 'loss': 0.26840461763468654}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017955303192138672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #8",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed57248b96924091914d3ab2ca1ad15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #8:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6776115160187425, 'macro_auc': 0.9392591528807818, 'macro_P@5': 0.6636002975452517, 'macro_P@8': 0.5353644929333002, 'macro_P@15': 0.34756591453839164, 'micro_f1': 0.7205379530430819, 'micro_auc': 0.9569133983269229, 'loss': 0.2311639167927942}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01777172088623047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324cb020302b43c190c3b4adf55d9663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6824366343145697, 'macro_auc': 0.9287086201394, 'macro_P@5': 0.6718334297281665, 'macro_P@8': 0.544679005205321, 'macro_P@15': 0.35882012724117984, 'micro_f1': 0.7125991348233598, 'micro_auc': 0.9462501127603415, 'loss': 0.267686814205213}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017958879470825195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #9",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b31fd0626474a6d95aa82a4672e6b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #9:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.688758662961108, 'macro_auc': 0.9421879127474156, 'macro_P@5': 0.6688569303248202, 'macro_P@8': 0.5402925861641458, 'macro_P@15': 0.34993801140590136, 'micro_f1': 0.7301672850894468, 'micro_auc': 0.9592384823780034, 'loss': 0.22500637739072205}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01753830909729004,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e6e8c66ff945e58f586da1d54a076f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6774346859098632, 'macro_auc': 0.9277785977202594, 'macro_P@5': 0.6728744939271255, 'macro_P@8': 0.5444621168305379, 'macro_P@15': 0.35932138037401196, 'micro_f1': 0.7125886524822695, 'micro_auc': 0.946473319911615, 'loss': 0.265248597481034}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017604827880859375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #10",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c787657a4dd4ceba38e2677ca0b80bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #10:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6923354782672697, 'macro_auc': 0.9449281151222944, 'macro_P@5': 0.6741879494173072, 'macro_P@8': 0.5420437639474337, 'macro_P@15': 0.3504421853045706, 'micro_f1': 0.7333222770429951, 'micro_auc': 0.9611943410155319, 'loss': 0.22029881367805917}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018069028854370117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f78ed796d7648ffae8d4f3c85cb0b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6786261388258009, 'macro_auc': 0.928043716370938, 'macro_P@5': 0.6733371891266627, 'macro_P@8': 0.5448235974551764, 'macro_P@15': 0.35932138037401196, 'micro_f1': 0.7106585441771534, 'micro_auc': 0.9468550884902983, 'loss': 0.264350131966851}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01768803596496582,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #11",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c43b37b1844c63ab63028f6a97344a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #11:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6997910647656757, 'macro_auc': 0.9471004489481989, 'macro_P@5': 0.6783287875030996, 'macro_P@8': 0.5456236052566328, 'macro_P@15': 0.352029093313497, 'micro_f1': 0.7390472249521542, 'micro_auc': 0.9626826440962111, 'loss': 0.21623278789133893}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017831087112426758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141a6062986841c5b88d7c12966e04c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6815499292988052, 'macro_auc': 0.9278511328542918, 'macro_P@5': 0.6682475419317525, 'macro_P@8': 0.5438837478311163, 'macro_P@15': 0.3588201272411799, 'micro_f1': 0.7120460940640493, 'micro_auc': 0.9453472410520811, 'loss': 0.26816986284472727}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017501354217529297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #12",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844f841ed3ca40d79199a2599d0ff5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #12:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.7054397137537339, 'macro_auc': 0.9494038194058209, 'macro_P@5': 0.6820976940242995, 'macro_P@8': 0.5488780064468138, 'macro_P@15': 0.3529051987767584, 'micro_f1': 0.7444526053358437, 'micro_auc': 0.9641229585872544, 'loss': 0.21178249796859833}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017858266830444336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 55,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0a4840546427ab321de9e9dff34d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_f1': 0.6773145001647426, 'macro_auc': 0.9273170871790305, 'macro_P@5': 0.6681318681318682, 'macro_P@8': 0.5415702718334298, 'macro_P@15': 0.3577790630422209, 'micro_f1': 0.7094650205761316, 'micro_auc': 0.9445045657744806, 'loss': 0.27401237216862767}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017547130584716797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 53,
       "postfix": null,
       "prefix": "Training at epoch #13",
       "rate": null,
       "total": 253,
       "unit": "batches",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5699bbd734a44dd48a346c3f1dbe0462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #13:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run with validation (pos_weights = 2 and AdamW) (for test data, best epoch:- )\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_with_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_data_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.data.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_vocab_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [24], line 2\u001b[0m, in \u001b[0;36mrun_with_validation\u001b[0;34m(training_data, valid_data, test_data, vocab, saved_data_file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_validation\u001b[39m(training_data, valid_data, test_data, vocab, saved_data_file_path):\n\u001b[0;32m----> 2\u001b[0m     best_model, scores \u001b[38;5;241m=\u001b[39m \u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_data_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved_data_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../model/checkpoint.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, scores\n",
      "Cell \u001b[0;32mIn [23], line 28\u001b[0m, in \u001b[0;36m_train_model\u001b[0;34m(train_data, valid_data, test_data, vocab, saved_data_file_path, checkpoint_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m criterions \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(pos_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m                   train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     21\u001b[0m                   valid_dataloader\u001b[38;5;241m=\u001b[39mvalid_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m                   vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m     27\u001b[0m                   checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint_path)\n\u001b[0;32m---> 28\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(model\u001b[38;5;241m=\u001b[39mbest_model,vocab\u001b[38;5;241m=\u001b[39mvocab,criterions\u001b[38;5;241m=\u001b[39mcriterions,\n\u001b[1;32m     31\u001b[0m                       n_training_labels\u001b[38;5;241m=\u001b[39mn_labels)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model, optimiser, evaluator, trainer, criterions\n",
      "Cell \u001b[0;32mIn [22], line 89\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_epoch)\u001b[0m\n\u001b[1;32m     87\u001b[0m         evaluator \u001b[38;5;241m=\u001b[39m Evaluator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_training_labels)\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m             train_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#             valid_scores = evaluator.evaluate(self.valid_dataloader)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m             test_scores \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataloader)\n",
      "Cell \u001b[0;32mIn [22], line 58\u001b[0m, in \u001b[0;36mTrainer.train_single_epoch\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     56\u001b[0m             output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     57\u001b[0m             pred_probs\u001b[38;5;241m.\u001b[39mextend(output)\n\u001b[0;32m---> 58\u001b[0m             \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m             losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#             print('pred probs:- ', output)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#             print('true labels:- ', label_batch)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py:221\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Tensor \u001b[38;5;129;01mand\u001b[39;00m has_torch_function(relevant_args):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    215\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    216\u001b[0m         relevant_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39mretain_graph,\n\u001b[1;32m    220\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph)\n\u001b[0;32m--> 221\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 130\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run with validation (without scheduler, lr = 0.001)\n",
    "run_with_validation(training_data, valid_data, test_data, vocab, saved_data_file_path=\"{}.data.pkl\".format(saved_vocab_path.split(\".pkl\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58efcbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a49ca608a64374a7342499a9ec9de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #1:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.21919215787074936, 'macro_auc': 0.7205536077479173, 'macro_P@5': 0.39466898090751307, 'macro_P@8': 0.3305231837341929, 'macro_P@15': 0.24584676419538806, 'micro_f1': 0.35322260952771517, 'micro_auc': 0.7852663463071183, 'loss': 0.458369336816162}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cc3b6fb37641f798f4a1054a971708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.3723741274531583, 'macro_auc': 0.8103973329483206, 'macro_P@5': 0.49057258530942743, 'macro_P@8': 0.40630422209369577, 'macro_P@15': 0.29284750337381915, 'micro_f1': 0.4840527381147765, 'micro_auc': 0.8527622587258634, 'loss': 0.4051440946080468}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4625008c937d45b78d16abbe2695e6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #2:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.4574984086826218, 'macro_auc': 0.8562459416189229, 'macro_P@5': 0.5503843292834119, 'macro_P@8': 0.4459304487974213, 'macro_P@15': 0.30764525993883796, 'micro_f1': 0.572856144211045, 'micro_auc': 0.9006715418132534, 'loss': 0.33650450614601257}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94126f14c0e34a31bfc9b2ef295ad874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.5782132207818501, 'macro_auc': 0.8853126726975209, 'macro_P@5': 0.5983805668016193, 'macro_P@8': 0.4916859456333141, 'macro_P@15': 0.3365336417967997, 'micro_f1': 0.6269097622894069, 'micro_auc': 0.9147692269584915, 'loss': 0.3241847399960865}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf089f227b84f449ec095348893512f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #3:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.5794341038668559, 'macro_auc': 0.9022279362342144, 'macro_P@5': 0.6127696503843293, 'macro_P@8': 0.49497892387800646, 'macro_P@15': 0.331324902884536, 'micro_f1': 0.6559517185292986, 'micro_auc': 0.9329226269680297, 'loss': 0.28392952115168213}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2b732611744d89ad0d18701357fa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6390777352062662, 'macro_auc': 0.910999204210944, 'macro_P@5': 0.6476576055523424, 'macro_P@8': 0.5250144592249856, 'macro_P@15': 0.3520339309812994, 'micro_f1': 0.6806214369641848, 'micro_auc': 0.9356878179700139, 'loss': 0.2849907923828472}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13005ab42a284e2eaeb4ce65d7aa912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #4:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6212538839822589, 'macro_auc': 0.917062161791922, 'macro_P@5': 0.6355318621373667, 'macro_P@8': 0.5113594098685842, 'macro_P@15': 0.33868088271758, 'micro_f1': 0.6862549487015238, 'micro_auc': 0.9435379754356136, 'loss': 0.2620882324786054}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abadea92b564488a980da3f8f30b8def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6527239077303519, 'macro_auc': 0.915113611646671, 'macro_P@5': 0.6558704453441295, 'macro_P@8': 0.5354973973395026, 'macro_P@15': 0.35450163871216506, 'micro_f1': 0.6976317238847072, 'micro_auc': 0.9388607256034497, 'loss': 0.27623401419682936}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4df760302f1477784901a11f7457538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #5:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6338056679454287, 'macro_auc': 0.9236453082659274, 'macro_P@5': 0.6429456979915695, 'macro_P@8': 0.5199913215968262, 'macro_P@15': 0.341416646003802, 'micro_f1': 0.6965256465314074, 'micro_auc': 0.9477730168772576, 'loss': 0.2528790415746892}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7175ca8e4ed4e48aef6ca11b07f875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6635262756907941, 'macro_auc': 0.9205777015428579, 'macro_P@5': 0.6624638519375362, 'macro_P@8': 0.5391844997108155, 'macro_P@15': 0.3577019471756314, 'micro_f1': 0.7040136023983176, 'micro_auc': 0.9425354303411476, 'loss': 0.2708630075508898}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e0c043b688401c928fc0a5495bbc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #6:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6575915424282827, 'macro_auc': 0.9285947303003032, 'macro_P@5': 0.6511281924125961, 'macro_P@8': 0.5243925117778329, 'macro_P@15': 0.3431027357632862, 'micro_f1': 0.7049982231327215, 'micro_auc': 0.9505687533900966, 'loss': 0.24554597660015695}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0bd5b6c589409d957e89bc2faaaf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6662013195080153, 'macro_auc': 0.9239955344342334, 'macro_P@5': 0.6658183921341815, 'macro_P@8': 0.5406304222093696, 'macro_P@15': 0.35708502024291505, 'micro_f1': 0.7098596683069072, 'micro_auc': 0.9433301772519387, 'loss': 0.2696151629090309}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc878ed822440696b96513aa56e03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #7:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6668885108490944, 'macro_auc': 0.9352213946316676, 'macro_P@5': 0.6579965286387306, 'macro_P@8': 0.5306533597818002, 'macro_P@15': 0.34636746838581706, 'micro_f1': 0.7141787786164308, 'micro_auc': 0.9545523801365936, 'loss': 0.23659668580109894}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b802f4745a4bbdb6a6ede24f4ad567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6708757733146093, 'macro_auc': 0.9257315678127678, 'macro_P@5': 0.6691729323308271, 'macro_P@8': 0.5436668594563332, 'macro_P@15': 0.3587044534412956, 'micro_f1': 0.7035689535689535, 'micro_auc': 0.9455650409584168, 'loss': 0.26806038225238976}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335318cd8e6d4b1c9714315156ddd1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #8:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6758366565212038, 'macro_auc': 0.9389008363775581, 'macro_P@5': 0.6626084800396728, 'macro_P@8': 0.5351940242995289, 'macro_P@15': 0.34858252748161006, 'micro_f1': 0.7214380604450349, 'micro_auc': 0.9568976044287552, 'loss': 0.23116033003028674}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd2f198fa8647668e1ebd030770cbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6692296097096108, 'macro_auc': 0.9270199019702511, 'macro_P@5': 0.6669751301330249, 'macro_P@8': 0.5415702718334298, 'macro_P@15': 0.3595912859070754, 'micro_f1': 0.7120829828987945, 'micro_auc': 0.9453566792322841, 'loss': 0.26910434487191115}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7a660954e747d5b1340ade54026556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #9:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "{'macro_f1': 0.6825426354314073, 'macro_auc': 0.9416183674606124, 'macro_P@5': 0.6682866352591122, 'macro_P@8': 0.5390683114306968, 'macro_P@15': 0.34867344408628814, 'micro_f1': 0.7259835980483752, 'micro_auc': 0.9586427619885575, 'loss': 0.2262248347399263}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda0ab173b6a4aedba236821f877270e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0001\n",
      "{'macro_f1': 0.6792066803614639, 'macro_auc': 0.9273386930037067, 'macro_P@5': 0.6698669751301329, 'macro_P@8': 0.5423655292076345, 'macro_P@15': 0.3592442645074225, 'micro_f1': 0.709510420850627, 'micro_auc': 0.9456070017570444, 'loss': 0.2697854069146243}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650b6f525f7d42fa8a9915375ddbed14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #10:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0001\n",
      "{'macro_f1': 0.7088472553771268, 'macro_auc': 0.949050227110308, 'macro_P@5': 0.6801140590131416, 'macro_P@8': 0.548630052070419, 'macro_P@15': 0.3528969336308786, 'micro_f1': 0.7448816611006244, 'micro_auc': 0.9640383024289989, 'loss': 0.21264235999273218}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0215620b61143ff81c788fa9340e677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0001\n",
      "{'macro_f1': 0.6812697769580416, 'macro_auc': 0.9281775027881392, 'macro_P@5': 0.6742625795257375, 'macro_P@8': 0.5459803354540197, 'macro_P@15': 0.3599383073067284, 'micro_f1': 0.7161777335804367, 'micro_auc': 0.9473748856646915, 'loss': 0.26529228606007316}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c64c025a29a4cbd925933bd8f9898b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #11:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0001\n",
      "{'macro_f1': 0.712404698396276, 'macro_auc': 0.9509779544188551, 'macro_P@5': 0.6855938507314654, 'macro_P@8': 0.5506756756756757, 'macro_P@15': 0.3537482436565006, 'micro_f1': 0.7492382630324387, 'micro_auc': 0.9654610877387079, 'loss': 0.20837834171155695}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c365ab303574a5fa58eb22de7d51533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0001\n",
      "{'macro_f1': 0.6806598928614889, 'macro_auc': 0.9281315429219801, 'macro_P@5': 0.6725274725274726, 'macro_P@8': 0.5457634470792365, 'macro_P@15': 0.35970695970695965, 'micro_f1': 0.7169880288769077, 'micro_auc': 0.947047180741073, 'loss': 0.2674814091487364}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238c699113a24682ae53642b476dc7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #12:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0001\n",
      "{'macro_f1': 0.7144344015147472, 'macro_auc': 0.9514381372689867, 'macro_P@5': 0.6856682370443837, 'macro_P@8': 0.5526438135383089, 'macro_P@15': 0.35368212248946196, 'micro_f1': 0.7508957781585917, 'micro_auc': 0.9658594987785031, 'loss': 0.20693368367526843}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52e622f6d0405eb27c4eee52d9e0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1e-05\n",
      "{'macro_f1': 0.680370196249654, 'macro_auc': 0.9279364237709115, 'macro_P@5': 0.6733371891266628, 'macro_P@8': 0.5452573742047426, 'macro_P@15': 0.3596298438403701, 'micro_f1': 0.7170104033582771, 'micro_auc': 0.946907741286612, 'loss': 0.26767749434167687}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9be60e506846918d3a5ffdc7f6819b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #13:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1e-05\n",
      "{'macro_f1': 0.7168858062344741, 'macro_auc': 0.9527214270794981, 'macro_P@5': 0.6875526903049838, 'macro_P@8': 0.5534496652615919, 'macro_P@15': 0.35449210678568477, 'micro_f1': 0.7535195158976065, 'micro_auc': 0.9667018361649691, 'loss': 0.20464383086314786}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c618f3ce242e486b98519c3846d3d290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1e-05\n",
      "{'macro_f1': 0.6799136850659098, 'macro_auc': 0.927963056787339, 'macro_P@5': 0.6739155581260845, 'macro_P@8': 0.5451850780798149, 'macro_P@15': 0.3594756121071911, 'micro_f1': 0.7161774744027305, 'micro_auc': 0.9470109236812969, 'loss': 0.2675183694471012}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35b537280824af797a6e7bf84f82856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #14:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1e-05\n",
      "{'macro_f1': 0.7172236054150841, 'macro_auc': 0.9528731211454474, 'macro_P@5': 0.6890900074386312, 'macro_P@8': 0.5547979171832382, 'macro_P@15': 0.35477312174559883, 'micro_f1': 0.7534260797342193, 'micro_auc': 0.9668421464563247, 'loss': 0.20440380899566907}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7247b7053b48799e2ade5714618fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0000000000000002e-06\n",
      "{'macro_f1': 0.6797008224024416, 'macro_auc': 0.9279771836562479, 'macro_P@5': 0.6743782533256217, 'macro_P@8': 0.544679005205321, 'macro_P@15': 0.3595912859070754, 'micro_f1': 0.715719671163192, 'micro_auc': 0.9470316832805878, 'loss': 0.26763054782694035}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d3ea2460bf48bea20ab4bf679732e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #15:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0000000000000002e-06\n",
      "{'macro_f1': 0.7178033999571077, 'macro_auc': 0.9529180976684283, 'macro_P@5': 0.6891643937515497, 'macro_P@8': 0.5542090255393007, 'macro_P@15': 0.3545334325150839, 'micro_f1': 0.7535324424909032, 'micro_auc': 0.9668678951835434, 'loss': 0.2040818035013591}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757bf451881c4f2dbd2c002f44db881f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0000000000000002e-06\n",
      "{'macro_f1': 0.6797615327394941, 'macro_auc': 0.9279735697279311, 'macro_P@5': 0.674146905725853, 'macro_P@8': 0.5446067090803933, 'macro_P@15': 0.35951417004048586, 'micro_f1': 0.7157846922552804, 'micro_auc': 0.9470249047512989, 'loss': 0.2676939209753817}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4164fba9f0b449d28fa679659eebcd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #16:   0%|          | 0/253 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run with validation (scheduler, initial lr = 0.001)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_with_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_data_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.data.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_vocab_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [44], line 2\u001b[0m, in \u001b[0;36mrun_with_validation\u001b[0;34m(training_data, valid_data, test_data, vocab, saved_data_file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_validation\u001b[39m(training_data, valid_data, test_data, vocab, saved_data_file_path):\n\u001b[0;32m----> 2\u001b[0m     best_model, scores \u001b[38;5;241m=\u001b[39m \u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_data_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved_data_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../model/checkpoint.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, scores\n",
      "Cell \u001b[0;32mIn [43], line 28\u001b[0m, in \u001b[0;36m_train_model\u001b[0;34m(train_data, valid_data, test_data, vocab, saved_data_file_path, checkpoint_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m criterions \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(pos_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m                   train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     21\u001b[0m                   valid_dataloader\u001b[38;5;241m=\u001b[39mvalid_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m                   vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m     27\u001b[0m                   checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint_path)\n\u001b[0;32m---> 28\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(model\u001b[38;5;241m=\u001b[39mbest_model,vocab\u001b[38;5;241m=\u001b[39mvocab,criterions\u001b[38;5;241m=\u001b[39mcriterions,\n\u001b[1;32m     31\u001b[0m                       n_training_labels\u001b[38;5;241m=\u001b[39mn_labels)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model, optimiser, evaluator, trainer, criterions\n",
      "Cell \u001b[0;32mIn [48], line 89\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_epoch)\u001b[0m\n\u001b[1;32m     87\u001b[0m         evaluator \u001b[38;5;241m=\u001b[39m Evaluator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_training_labels)\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m             train_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#             valid_scores = evaluator.evaluate(self.valid_dataloader)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m             test_scores \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataloader)\n",
      "Cell \u001b[0;32mIn [48], line 58\u001b[0m, in \u001b[0;36mTrainer.train_single_epoch\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     56\u001b[0m             output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     57\u001b[0m             pred_probs\u001b[38;5;241m.\u001b[39mextend(output)\n\u001b[0;32m---> 58\u001b[0m             \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m             losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#             print('pred probs:- ', output)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#             print('true labels:- ', label_batch)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py:221\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Tensor \u001b[38;5;129;01mand\u001b[39;00m has_torch_function(relevant_args):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    215\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    216\u001b[0m         relevant_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39mretain_graph,\n\u001b[1;32m    220\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph)\n\u001b[0;32m--> 221\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 130\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run with validation (with scheduler, initial lr = 0.001, best epoch: 15)\n",
    "run_with_validation(training_data, valid_data, test_data, vocab, saved_data_file_path=\"{}.data.pkl\".format(saved_vocab_path.split(\".pkl\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107bfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
