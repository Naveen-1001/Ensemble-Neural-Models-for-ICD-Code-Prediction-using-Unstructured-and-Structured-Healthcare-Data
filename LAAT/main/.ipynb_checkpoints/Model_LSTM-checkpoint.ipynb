{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71afa6b7",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "6a9cb6ed",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import tqdm.notebook as tqdm\n",
    "from torch import optim\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from collections import Counter\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "d7cbab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 23 14:15:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    57W / 300W |  32283MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    56W / 300W |    925MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    58W / 300W |   3260MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    57W / 300W |    925MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    202902      C   /usr/bin/python3                31723MiB |\n",
      "|    0   N/A  N/A    291963      C   /usr/bin/python3                  555MiB |\n",
      "|    1   N/A  N/A    202902      C   /usr/bin/python3                  461MiB |\n",
      "|    1   N/A  N/A    291963      C   /usr/bin/python3                  461MiB |\n",
      "|    2   N/A  N/A    202902      C   /usr/bin/python3                  461MiB |\n",
      "|    2   N/A  N/A    291963      C   /usr/bin/python3                  461MiB |\n",
      "|    2   N/A  N/A    346194      C   /usr/bin/python3                 2333MiB |\n",
      "|    3   N/A  N/A    202902      C   /usr/bin/python3                  461MiB |\n",
      "|    3   N/A  N/A    291963      C   /usr/bin/python3                  461MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "ac72555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir =  \"../cache\"\n",
    "data_dir = \"../data/mimic3_new\"\n",
    "ID_COL_NAME = \"HADM_ID\"\n",
    "LABEL_COL_NAME = \"ICD9_CODE\"\n",
    "TEXT_COL_NAME = \"TEXT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69129c7b",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "d7afed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "n_epoch=10\n",
    "optimiser=\"adamw\" # \"adam\", \"sgd\", \"adadelta\", \"adamw\",\"adagrad\"\n",
    "main_metric=\"micro_f1\"\n",
    "multilabel=1\n",
    "shuffle_data=1\n",
    "dropout=0.3\n",
    "max_seq_length=2500\n",
    "min_seq_length=-1\n",
    "min_word_frequency=-1\n",
    "embedding_mode=\"word2vec\"\n",
    "embedding_size=100\n",
    "embedding_file=\"../data/mimic3_new/processed_50.embed\"\n",
    "d_a=256 #\"The dimension of the first dense layer for self attention\"\n",
    "n_labels=50\n",
    "\n",
    "#RNN\n",
    "hidden_size =  256\n",
    "n_layers = 1\n",
    "bidirectional =1\n",
    "use_last_hidden_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "6d3ef67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self,\n",
    "                 training_data: list,\n",
    "                 training_labels: list,\n",
    "                 min_word_frequency: int = -1,\n",
    "                 max_vocab_size: int = -1,\n",
    "                 word_embedding_mode: str = \"word2vec\",\n",
    "                 word_embedding_file: str = None,\n",
    "                 use_gpu: bool = True\n",
    "                 ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
    "        self.word_embedding_mode = word_embedding_mode\n",
    "        self.word_embedding_file = word_embedding_file\n",
    "        self.word_embedding_size = 100\n",
    "        self.word_embeddings = None\n",
    "\n",
    "        self.training_data = training_data\n",
    "\n",
    "        self.PAD_TOKEN = '_PAD'\n",
    "        self.UNK_TOKEN = '_UNK'\n",
    "        self.word2index = None\n",
    "        self.index2word = None\n",
    "\n",
    "        self.label2index = None\n",
    "        self.index2label = None\n",
    "\n",
    "        self.vocab_words = [self.PAD_TOKEN, self.UNK_TOKEN]\n",
    "        self.all_labels = []\n",
    "\n",
    "        self.min_word_frequency = min_word_frequency\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "\n",
    "        self.update_labels(training_labels)\n",
    "\n",
    "    def index_of_word(self,word: str) -> int:\n",
    "        try:\n",
    "            return self.word2index[word]\n",
    "        except:\n",
    "            return self.word2index[self.UNK_TOKEN]\n",
    "\n",
    "    def index_of_label(self,label: str) -> int:\n",
    "        try:\n",
    "            return self.label2index[label]\n",
    "        except:\n",
    "            return 0\n",
    "    def update_labels(self, labels):\n",
    "        self.all_labels = []\n",
    "        self.index2label = []\n",
    "        self.label2index = []\n",
    "        all_labels = list(sorted(labels))\n",
    "        self.label2index = {label: idx for idx, label in enumerate(all_labels)}\n",
    "        self.index2label = {idx: label for idx, label in enumerate(all_labels)}\n",
    "        self.all_labels = all_labels\n",
    "            \n",
    "    def prepare_vocab(self):\n",
    "        self._build_vocab()\n",
    "\n",
    "        # load pretrain word embeddings\n",
    "        if self.word_embedding_file is not None:\n",
    "            self.word_embeddings = torch.FloatTensor(self._load_embeddings())\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        all_words_df = pd.read_csv('../data/mimic3_new/vocab.csv',header=None)\n",
    "        all_words = all_words_df.iloc[:,0].tolist()\n",
    "        all_words.sort()\n",
    "\n",
    "        self.vocab_words += all_words\n",
    "\n",
    "        self.word2index = {word: idx for idx, word in enumerate(self.vocab_words)}\n",
    "        self.index2word = {idx: word for idx, word in enumerate(self.vocab_words)}\n",
    "\n",
    "\n",
    "    def _load_embeddings(self):\n",
    "        if self.word_embedding_file is None:\n",
    "            return None\n",
    "        return self._load_word_embeddings()\n",
    "\n",
    "    def _load_word_embeddings(self):\n",
    "        unknown_vec = np.random.uniform(-0.25, 0.25, self.word_embedding_size)\n",
    "        embeddings = [unknown_vec] * (len(self.vocab_words))\n",
    "        embeddings[0] = np.zeros(self.word_embedding_size)\n",
    "        for line in open(self.word_embedding_file, \"rt\"):\n",
    "            split = line.rstrip().split(\" \")\n",
    "            word = split[0]\n",
    "            vector = np.array([float(num) for num in split[1:]]).astype(np.float32)\n",
    "#             print(word,': ',vector)\n",
    "            if len(vector) > 0:\n",
    "                if word in self.word2index:\n",
    "                    embeddings[self.word2index[word]] = vector\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "        return embeddings\n",
    "    def n_words(self):\n",
    "        return len(self.vocab_words)\n",
    "\n",
    "    def n_labels(self):\n",
    "        return len(self.all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "fc5dfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path) -> list:\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    id_data = data[ID_COL_NAME]\n",
    "    text_data = data[TEXT_COL_NAME]\n",
    "\n",
    "    hierarchical_label_data = []\n",
    "    label_data = data[LABEL_COL_NAME].tolist()\n",
    "    \n",
    "    output = []\n",
    "    for i in tqdm.tqdm(range(len(label_data)), desc=\"Reading data\"):\n",
    "        labels = label_data[i].split(';')\n",
    "        print(labels)\n",
    "        output.append((text_data[i], labels, id_data[i]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "a07b35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached_data(file_path: str) -> tuple:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        f.close()\n",
    "    return data[\"vocab\"], data[\"training_data\"], data[\"valid_data\"], data[\"test_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "3f6718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    cache_folder = \"{}/{}\".format(cache_dir, \"mimic3_single_50\")\n",
    "#     device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    save_vocab_file_name = \"{}.pkl\".format(\"save_vocab\")\n",
    "    cached_file_name = os.path.join(cache_folder, save_vocab_file_name)\n",
    "    if os.path.exists(cached_file_name):\n",
    "        vocab, training_data, valid_data, test_data = load_cached_data(cached_file_name)\n",
    "        data = training_data + valid_data + test_data\n",
    "        labels = []\n",
    "        for (feature, l, _) in data:\n",
    "            labels.extend(l)\n",
    "        unique_labels=list(set(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "        labels = unique_labels\n",
    "        vocab.update_labels(labels)\n",
    "        print(\"Loaded vocab and data from file\")\n",
    "    else:\n",
    "        training_data = read_data( data_dir + \"/train.csv\")\n",
    "        valid_data = read_data( data_dir + \"/dev.csv\")\n",
    "        test_data = read_data( data_dir + \"/test.csv\")\n",
    "    #     print(len(training_data),len(valid_data),len(test_data))\n",
    "        data = training_data + valid_data + test_data\n",
    "        labels = []\n",
    "        for (feature, l, _) in data:\n",
    "            labels.extend(l)\n",
    "        unique_labels=list(set(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "        labels = unique_labels\n",
    "        vocab = Vocab(data, labels,\n",
    "                          min_word_frequency,\n",
    "                          word_embedding_mode=embedding_mode,\n",
    "                          word_embedding_file=embedding_file)\n",
    "        print(\"Preparing the vocab\")\n",
    "        vocab.prepare_vocab()\n",
    "        saved_objects = {\"vocab\": vocab,\n",
    "                         \"training_data\": training_data,\n",
    "                         \"valid_data\": valid_data,\n",
    "                         \"test_data\": test_data}\n",
    "        with open(cached_file_name, 'wb') as f:\n",
    "            pickle.dump(saved_objects, f, pickle.HIGHEST_PROTOCOL)\n",
    "            f.close()\n",
    "        print(\"Saved vocab and data to files\")\n",
    "    return training_data, valid_data, test_data, vocab, cached_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "cb8dcb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab and data from file\n"
     ]
    }
   ],
   "source": [
    "training_data, valid_data, test_data, vocab, saved_vocab_path = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "095d5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5278, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "pos_labels = defaultdict(int)\n",
    "for val in training_data:\n",
    "    labels = val[1]\n",
    "    for label in labels:\n",
    "        pos_labels[label]+=1\n",
    "\n",
    "for key in pos_labels.keys():\n",
    "    pos_labels[key] = (len(training_data)-pos_labels[key])/pos_labels[key]\n",
    "\n",
    "weights = []\n",
    "for key in vocab.label2index.keys():\n",
    "    weights.append(pos_labels[key])\n",
    "\n",
    "weights = torch.FloatTensor(weights)\n",
    "weights = weights.to(device)\n",
    "print(weights.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "55dbe24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_mode: str,\n",
    "                 pretrained_word_embeddings: torch.Tensor,\n",
    "                 vocab_size: int,\n",
    "                 embedding_size: int):\n",
    "        \n",
    "        self.embedding_mode = embedding_mode\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embeddings.weight = nn.Parameter(copy.deepcopy(pretrained_word_embeddings), requires_grad=False)\n",
    "        self.output_size = embedding_size\n",
    "        \n",
    "    def forward(self, batch_data: torch.LongTensor): # batch_data shape: [batch_size x max_padded_text_length]\n",
    "        embeds = self.embeddings(batch_data)  # [batch_size x max_seq_size x embedding_size]\n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "ca2f6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, size: int, n_labels=None):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.d_a = d_a\n",
    "        self.n_labels = n_labels\n",
    "        self.linear = nn.Linear(self.size, self.n_labels, bias = True)\n",
    "        self._init_weights(mean=0.0, std=0.03)\n",
    "\n",
    "    def _init_weights(self, mean=0.0, std=0.03) -> None:\n",
    "        torch.nn.init.normal_(self.linear.weight,mean, std)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weighted_output = self.linear(x)   \n",
    "        return weighted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "46f47efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab: Vocab):\n",
    "        super(Model, self).__init__()\n",
    "        self.vocab_size = vocab.n_words()\n",
    "        self.vocab = vocab\n",
    "        self.use_last_hidden_state = use_last_hidden_state\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bool(bidirectional)\n",
    "        self.n_directions = int(self.bidirectional) + 1\n",
    "        self.output_size = self.hidden_size * self.n_directions\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.embedding = EmbeddingLayer(embedding_mode=embedding_mode,\n",
    "                                     embedding_size=embedding_size,\n",
    "                                     pretrained_word_embeddings=vocab.word_embeddings,\n",
    "                                     vocab_size=vocab.n_words())\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.embedding.output_size, self.hidden_size, num_layers=self.n_layers,\n",
    "                               bidirectional=self.bidirectional, dropout=(self.dropout if self.n_layers > 1 else 0))\n",
    "        \n",
    "        self.use_dropout = dropout > 0\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear = LinearLayer(size=self.output_size, n_labels=self.vocab.n_labels())\n",
    "\n",
    "    def init_hidden(self, batch_size) -> Variable:\n",
    "        h = Variable(torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)).to(device)\n",
    "        c = Variable(torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)).to(device)\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, batch_data: torch.LongTensor, lengths: torch.LongTensor) -> tuple:\n",
    "        batch_size = batch_data.size()[0]\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.embedding(batch_data)\n",
    "        \n",
    "        if self.use_dropout:\n",
    "            embeds = self.dropout(embeds)\n",
    "            \n",
    "        self.rnn.flatten_parameters()\n",
    "        embeds = pack_padded_sequence(embeds, lengths.cpu(), batch_first=True)\n",
    "        rnn_output, hidden = self.rnn(embeds, hidden) \n",
    "        hidden = hidden[0]\n",
    "        rnn_output = pad_packed_sequence(rnn_output)[0]\n",
    "        rnn_output = rnn_output.permute(1, 0, 2)\n",
    "        \n",
    "        hidden_forward = hidden[-1]\n",
    "        hidden_backward = hidden[0]        \n",
    "        last_rnn_output = torch.cat((hidden_forward, hidden_backward), 1)\n",
    "        \n",
    "        output = self.linear(last_rnn_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a79faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "e1d85c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): EmbeddingLayer(\n",
       "    (embeddings): Embedding(66322, 100)\n",
       "  )\n",
       "  (rnn): LSTM(100, 256, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): LinearLayer(\n",
       "    (linear): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(vocab)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "3c79c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_data: list, vocab, sort: bool = True):\n",
    "        super(TextDataset, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.multilabel = multilabel\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.min_seq_length = min_seq_length\n",
    "        self.PAD_ID = self.vocab.index_of_word(self.vocab.PAD_TOKEN) # 0\n",
    "        indexed_data = []\n",
    "        self.n_instances = len(text_data)\n",
    "        print('Length of text data:- ', self.n_instances)\n",
    "        self.n_total_tokens = 0\n",
    "\n",
    "        n_label_level = 1\n",
    "        self.label_count = dict()\n",
    "        self.labels = set()\n",
    "        for text, labels, _id in tqdm.tqdm(text_data, unit=\"samples\", desc=\"Processing data\"):\n",
    "            label_list = []\n",
    "            for label in labels:\n",
    "                if label in self.vocab.label2index:\n",
    "                    label = self.vocab.index_of_label(label)\n",
    "                    if label not in self.label_count:\n",
    "                        self.label_count[label] = 1\n",
    "                    else:\n",
    "                        self.label_count[label] += 1\n",
    "                    self.labels.add(label)\n",
    "                    label_list.append(label)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if len(label_list) == 0:\n",
    "                continue\n",
    "\n",
    "            word_seq = []\n",
    "            sent_words = text.strip().split()\n",
    "#             print('sent words:- ', len(sent_words))\n",
    "            for word in sent_words:\n",
    "                word_idx = vocab.index_of_word(word)\n",
    "#                 if word_idx==vocab.word2index['_UNK']:\n",
    "#                     continue\n",
    "                word_seq.append(word_idx)\n",
    "                self.n_total_tokens += 1\n",
    "                if len(word_seq) >= self.max_seq_length:\n",
    "                    break\n",
    "            if len(word_seq) > 0:\n",
    "                indexed_data.append((word_seq, label_list, _id))\n",
    "#             print('word sequence:- ', len(word_seq))\n",
    "\n",
    "        if sort:\n",
    "            self.indexed_data = sorted(indexed_data, key=lambda x: -len(x[0]))\n",
    "        else:\n",
    "            self.indexed_data = indexed_data\n",
    "            self.shuffle_data()\n",
    "\n",
    "        self.labels = sorted(list(self.labels))\n",
    "        self.size = len(self.indexed_data)\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        random.shuffle(self.indexed_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        word_seq, label_list, _id = self.indexed_data[index]\n",
    "        if len(word_seq) > self.max_seq_length:\n",
    "            word_seq = word_seq[:self.max_seq_length]\n",
    "\n",
    "        one_hot_label_list = [0] * self.vocab.n_labels()\n",
    "        for label in label_list:\n",
    "            one_hot_label_list[label] = 1\n",
    "        return word_seq, one_hot_label_list, _id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "5b54069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_and_cache_data(train_data, valid_data, test_data, vocab, saved_data_file_path):\n",
    "    if os.path.exists(saved_data_file_path):\n",
    "        try:\n",
    "            with open(saved_data_file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                data[\"train\"].multilabel = bool(multilabel)\n",
    "                data[\"valid\"].multilabel = bool(multilabel)\n",
    "                data[\"test\"].multilabel = bool(multilabel)\n",
    "\n",
    "                return data[\"train\"], data[\"valid\"], data[\"test\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Build train/valid/test data loaders\n",
    "    train_dataset = TextDataset(train_data, vocab,sort=True)\n",
    "\n",
    "    valid_dataset = TextDataset(valid_data, vocab,sort=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, vocab, sort=True)\n",
    "    # try:\n",
    "    with open(saved_data_file_path, 'wb') as f:\n",
    "        data = {\"train\": train_dataset, \"valid\": valid_dataset, \"test\": test_dataset}\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "8167d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataLoader(DataLoader):\n",
    "    def __init__(self, vocab, **kwargs):\n",
    "        super(TextDataLoader, self).__init__( **kwargs)\n",
    "        self.collate_fn = self._collate_fn # recieves is a list of tuples of (word seq, one_hot_label_list, _id)\n",
    "        self.PAD_ID = vocab.index_of_word(vocab.PAD_TOKEN)\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "#         print('collate_fn called:- ')\n",
    "#         print(len(batch[0][0]))\n",
    "        length_batch = []\n",
    "\n",
    "#         self.first_linear = nn.Linear(self.size, self.d_a, bias=False)\n",
    "#         self.second_linear = nn.Linear(self.d_a, n_labels, bias=False)\n",
    "#         self.third_linear = nn.Linear(self.size , n_labels, bias=True)\n",
    "        feature_batch = []\n",
    "        label_batch = []\n",
    "\n",
    "        id_batch = []\n",
    "        multilabel = True\n",
    "        for features, labels, _id in batch: # labels are one-hot encoded\n",
    "            feature_length = len(features)\n",
    "            feature_batch.append(torch.LongTensor(features))\n",
    "\n",
    "            length_batch.append(feature_length)\n",
    "            label_batch.append(labels)\n",
    "            id_batch.append(_id)\n",
    "\n",
    "        feature_batch, label_batch, length_batch, id_batch = \\\n",
    "            self.sort_batch(feature_batch, label_batch, length_batch, id_batch)\n",
    "        \n",
    "        padded_batch = pad_sequence(feature_batch, batch_first=True)\n",
    "        feature_batch = torch.LongTensor(padded_batch)\n",
    "        \n",
    "        label_batch = np.stack(label_batch, axis=0)\n",
    "        \n",
    "        label_batch = torch.FloatTensor(label_batch.tolist()) # converts list to tensor\n",
    "#         print('before longtensor length batch',length_batch)\n",
    "        length_batch = torch.LongTensor(length_batch)\n",
    "#         print('after longtensor length batch',length_batch)\n",
    "\n",
    "#         print('shape of feature batch:-', feature_batch.shape)\n",
    "#         print('length batch:-', length_batch)\n",
    "#         print('shape of label batch:-', label_batch.shape)\n",
    "#         print('id batch:-', id_batch)\n",
    "#         print('type of length batch:- ', type(length_batch))\n",
    "        return feature_batch, label_batch, length_batch, id_batch\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_batch(features, labels, lengths, id_batch):\n",
    "        sorted_indices = sorted(range(len(features)), key=lambda i: features[i].size(0), reverse=True)\n",
    "        sorted_features = []\n",
    "        sorted_labels = []\n",
    "        sorted_lengths = []\n",
    "        sorted_ids = []\n",
    "\n",
    "        for index in sorted_indices:\n",
    "            sorted_features.append(features[index])\n",
    "\n",
    "            sorted_labels.append(labels[index])\n",
    "            sorted_lengths.append(lengths[index])\n",
    "\n",
    "            sorted_ids.append(id_batch[index])\n",
    "\n",
    "        return sorted_features, sorted_labels, sorted_lengths, sorted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "f66ab735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self,model: torch.nn.Module, vocab, criterions, n_training_labels):\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.index_to_label = vocab.index2label\n",
    "        self.multilabel = multilabel\n",
    "        self.criterions = criterions\n",
    "        self.n_training_labels = n_training_labels\n",
    "\n",
    "    def evaluate(self, dataloader: TextDataLoader) -> dict:\n",
    "\n",
    "        self.model.eval()\n",
    "        pred_probs = []\n",
    "        true_labels = []\n",
    "        ids = []\n",
    "\n",
    "        losses = []\n",
    "        all_loss_list = []\n",
    "\n",
    "        for text_batch, label_batch, length_batch, id_batch in tqdm.tqdm(dataloader, unit=\"batches\", desc=\"Evaluating\"):\n",
    "\n",
    "            text_batch = text_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            length_batch = length_batch.to(device)\n",
    "            \n",
    "            true_labels.extend(label_batch.cpu().numpy())\n",
    "            ids.extend(id_batch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(text_batch, length_batch)\n",
    "#                 output, attn_weights = self.model(text_batch, length_batch)\n",
    "\n",
    "            probs = [None] * len(output)\n",
    "            \n",
    "            loss = self.criterions(output, label_batch)\n",
    "            output = torch.sigmoid(output)\n",
    "            all_loss_list.append(loss.item())\n",
    "            output = output.detach().cpu().numpy()\n",
    "            probs = output.tolist()\n",
    "            pred_probs.extend(output)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        scores = OrderedDict()\n",
    "        scores = calculate_eval_metrics(ids, true_labels, pred_probs, self.multilabel)\n",
    "        scores[\"loss\"] = np.mean(all_loss_list).item()\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "0075522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eval_metrics(ids, true_labels, pred_probs, is_multilabel):\n",
    "    true_labels = np.asarray(true_labels)\n",
    "    pred_probs = np.asarray(pred_probs)\n",
    "    pred_labels = np.rint(pred_probs)\n",
    "    \n",
    "    macro_scores = calculate_scores(true_labels, pred_labels, pred_probs, \"macro\", is_multilabel)\n",
    "    micro_scores = calculate_scores(true_labels, pred_labels, pred_probs, \"micro\", is_multilabel)\n",
    "    \n",
    "    scores = macro_scores\n",
    "    scores.update(micro_scores)\n",
    "    scores[\"ids\"] = ids\n",
    "    scores[\"true_labels\"] = true_labels\n",
    "    scores[\"pred_probs\"] = pred_probs\n",
    "    return scores\n",
    "\n",
    "def calculate_scores(true_labels, pred_labels, pred_probs, average=\"macro\", is_multilabel=True):\n",
    "    max_size = min(len(true_labels), len(pred_labels))\n",
    "    true_labels = true_labels[: max_size]\n",
    "    pred_labels = pred_labels[: max_size]\n",
    "    pred_probs = pred_probs[: max_size]\n",
    "    p_1 = 0\n",
    "    p_5 = 0\n",
    "    p_8 = 0\n",
    "    p_10 = 0\n",
    "    p_15 = 0\n",
    "    if pred_probs is not None:\n",
    "        if average == \"macro\":\n",
    "            accuracy = macro_accuracy(true_labels, pred_labels)  # categorical accuracy\n",
    "            precision, recall, f1 = macro_f1(true_labels, pred_labels)\n",
    "            p_ks = precision_at_k(true_labels, pred_probs, [1, 5, 8, 10, 15])\n",
    "            p_1 = p_ks[0]\n",
    "            p_5 = p_ks[1]\n",
    "            p_8 = p_ks[2]\n",
    "            p_10 = p_ks[3]\n",
    "            p_15 = p_ks[4]\n",
    "\n",
    "        else:\n",
    "            accuracy = micro_accuracy(true_labels, pred_labels)\n",
    "            precision, recall, f1 = micro_f1(true_labels, pred_labels)\n",
    "        auc_score = roc_auc(true_labels, pred_probs, average)\n",
    "    else:\n",
    "        auc_score = -1\n",
    "\n",
    "    output = {\"{}_precision\".format(average): precision, \"{}_recall\".format(average): recall,\n",
    "              \"{}_f1\".format(average): f1, \"{}_accuracy\".format(average): accuracy,\n",
    "              \"{}_auc\".format(average): auc_score, \"{}_P@1\".format(average): p_1, \"{}_P@5\".format(average): p_5,\n",
    "              \"{}_P@8\".format(average): p_8, \"{}_P@10\".format(average): p_10, \"{}_P@15\".format(average): p_15}\n",
    "    \n",
    "    return output\n",
    "\n",
    "def average_scores(scores):\n",
    "    avg_scores = dict()\n",
    "    for key in scores:\n",
    "        if key.startswith(\"level\"):\n",
    "            for metric in scores[key]:\n",
    "                if metric.startswith(\"macro\") or metric.startswith(\"micro\") or metric == \"loss\":\n",
    "                    if metric not in avg_scores:\n",
    "                        avg_scores[metric] = []\n",
    "                    avg_scores[metric].append(scores[key][metric])\n",
    "\n",
    "    for metric in avg_scores:\n",
    "        avg_scores[metric] = sum(avg_scores[metric]) / len(avg_scores[metric])\n",
    "    return avg_scores\n",
    "\n",
    "def union_size(x, y, axis):\n",
    "    return np.logical_or(x, y).sum(axis=axis).astype(float)\n",
    "\n",
    "\n",
    "def intersect_size(x, y, axis):\n",
    "    return np.logical_and(x, y).sum(axis=axis).astype(float)\n",
    "\n",
    "def macro_precision(true_labels, pred_labels):\n",
    "    num = intersect_size(true_labels, pred_labels, 0) / (pred_labels.sum(axis=0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "\n",
    "def macro_recall(true_labels, pred_labels):\n",
    "    num = intersect_size(true_labels, pred_labels, 0) / (true_labels.sum(axis=0) + 1e-10)\n",
    "#     print('macro recall num:- ', num)\n",
    "    return np.mean(num)\n",
    "\n",
    "\n",
    "def macro_f1(true_labels, pred_labels):\n",
    "    prec = macro_precision(true_labels, pred_labels)\n",
    "    rec = macro_recall(true_labels, pred_labels)\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.\n",
    "    else:\n",
    "        f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def macro_accuracy(true_labels, pred_labels):\n",
    "    num = intersect_size(true_labels, pred_labels, 0) / (union_size(true_labels, pred_labels, 0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "\n",
    "def micro_precision(true_labels, pred_labels):\n",
    "    flat_true = true_labels.ravel()\n",
    "    flat_pred = pred_labels.ravel()\n",
    "    if flat_pred.sum(axis=0) == 0:\n",
    "        return 0.0\n",
    "    return intersect_size(flat_true, flat_pred, 0) / flat_pred.sum(axis=0)\n",
    "\n",
    "\n",
    "def micro_recall(true_labels, pred_labels):\n",
    "    flat_true = true_labels.ravel()\n",
    "    flat_pred = pred_labels.ravel()\n",
    "    return intersect_size(flat_true, flat_pred, 0) / flat_true.sum(axis=0)\n",
    "\n",
    "def micro_f1(true_labels, pred_labels):\n",
    "    prec = micro_precision(true_labels, pred_labels)\n",
    "    rec = micro_recall(true_labels, pred_labels)\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.\n",
    "    else:\n",
    "        f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def micro_accuracy(true_labels, pred_labels):\n",
    "    flat_true = true_labels.ravel()\n",
    "    flat_pred = pred_labels.ravel()\n",
    "    return intersect_size(flat_true, flat_pred, 0) / union_size(flat_true, flat_pred, 0)\n",
    "\n",
    "\n",
    "def recall_at_k(true_labels, pred_probs, k):\n",
    "    # num true labels in top k predictions / num true labels\n",
    "    sortd = np.argsort(pred_probs)[:, ::-1]\n",
    "    topk = sortd[:, :k]\n",
    "\n",
    "    # get recall at k for each example\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = true_labels[i, tk].sum()\n",
    "        denom = true_labels[i, :].sum()\n",
    "        vals.append(num_true_in_top_k / float(denom))\n",
    "\n",
    "    vals = np.array(vals)\n",
    "    vals[np.isnan(vals)] = 0.\n",
    "\n",
    "    return np.mean(vals)\n",
    "\n",
    "\n",
    "def precision_at_k(true_labels, pred_probs, ks=[1, 5, 8, 10, 15]):\n",
    "    # num true labels in top k predictions / k\n",
    "    sorted_pred = np.argsort(pred_probs)[:, ::-1]\n",
    "    output = []\n",
    "    for k in ks:\n",
    "        topk = sorted_pred[:, :k]\n",
    "\n",
    "        # get precision at k for each example\n",
    "        vals = []\n",
    "        for i, tk in enumerate(topk):\n",
    "            if len(tk) > 0:\n",
    "                num_true_in_top_k = true_labels[i, tk].sum()\n",
    "                denom = len(tk)\n",
    "                vals.append(num_true_in_top_k / float(denom))\n",
    "\n",
    "        output.append(np.mean(vals))\n",
    "    return output\n",
    "\n",
    "\n",
    "def roc_auc(true_labels, pred_probs, average=\"macro\"):\n",
    "    if pred_probs.shape[0] <= 1:\n",
    "        return\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    if average == \"macro\":\n",
    "        # get AUC for each label individually\n",
    "        relevant_labels = []\n",
    "        auc_labels = {}\n",
    "        for i in range(true_labels.shape[1]):\n",
    "            # only if there are true positives for this label\n",
    "            if true_labels[:, i].sum() > 0:\n",
    "                fpr[i], tpr[i], _ = roc_curve(true_labels[:, i], pred_probs[:, i])\n",
    "                if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
    "                    auc_score = auc(fpr[i], tpr[i])\n",
    "                    if not np.isnan(auc_score):\n",
    "                        auc_labels[\"auc_%d\" % i] = auc_score\n",
    "                        relevant_labels.append(i)\n",
    "\n",
    "        # macro-AUC: just average the auc scores\n",
    "        aucs = []\n",
    "        for i in relevant_labels:\n",
    "            aucs.append(auc_labels['auc_%d' % i])\n",
    "        score = np.mean(aucs)\n",
    "    else:\n",
    "        # micro-AUC: just look at each individual prediction\n",
    "        flat_pred = pred_probs.ravel()\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(true_labels.ravel(), flat_pred)\n",
    "        score = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def multiclass_roc_auc(true_labels, pred_labels, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(true_labels)\n",
    "    true_labels = lb.transform(true_labels)\n",
    "    pred_labels = lb.transform(pred_labels)\n",
    "    return roc_auc_score(true_labels, pred_labels, average=average)\n",
    "\n",
    "def average_scores(scores):\n",
    "    avg_scores = dict()\n",
    "    for key in scores:\n",
    "        if key.startswith(\"level\"):\n",
    "            for metric in scores[key]:\n",
    "                if metric.startswith(\"macro\") or metric.startswith(\"micro\") or metric == \"loss\":\n",
    "                    if metric not in avg_scores:\n",
    "                        avg_scores[metric] = []\n",
    "                    avg_scores[metric].append(scores[key][metric])\n",
    "\n",
    "    for metric in avg_scores:\n",
    "        avg_scores[metric] = sum(avg_scores[metric]) / len(avg_scores[metric])\n",
    "    return avg_scores\n",
    "\n",
    "def normalise_labels(labels, n_label):\n",
    "    norm_labels = []\n",
    "    for label in labels:\n",
    "        one_hot_vector_label = [0] * n_label\n",
    "        one_hot_vector_label[label] = 1\n",
    "        norm_labels.append(one_hot_vector_label)\n",
    "    return np.asarray(norm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "3e2041d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module,\n",
    "                 train_dataloader: TextDataLoader,\n",
    "                 valid_dataloader: TextDataLoader,\n",
    "                 test_dataloader: TextDataLoader,\n",
    "                 criterions,\n",
    "                 optimiser,\n",
    "#                  lr_scheduler,\n",
    "                 vocab,\n",
    "                 checkpoint_path,\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.criterions = criterions\n",
    "        self.optimiser = optimiser\n",
    "#         self.lr_scheduler = lr_scheduler\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.multilabel = multilabel\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.n_training_labels = n_labels\n",
    "        self.main_metric = main_metric\n",
    "        self.start_epoch = 0\n",
    "\n",
    "    def train_single_epoch(self, index):\n",
    "        self.model.train()\n",
    "        self.train_dataloader.dataset.shuffle_data()\n",
    "        losses = []\n",
    "        true_labels = []\n",
    "        pred_probs = []\n",
    "        ids = []\n",
    "        all_loss_list = []\n",
    "        progress_bar = tqdm.tqdm(self.train_dataloader, unit=\"batches\", desc=\"Training at epoch #{}\".format(index))\n",
    "        progress_bar.clear()\n",
    "        self.optimiser.zero_grad()\n",
    "        batch_id = 0\n",
    "\n",
    "        for text_batch, label_batch, length_batch, id_batch in progress_bar:\n",
    "            batch_id += 1\n",
    "            text_batch = text_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            length_batch = length_batch.to(device)\n",
    "\n",
    "#             output, attn_weights = self.model(text_batch, length_batch)\n",
    "            \n",
    "            output = self.model(text_batch, length_batch)\n",
    "            true_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "            ids.extend(id_batch)\n",
    "\n",
    "            loss = self.criterions(output, label_batch)\n",
    "            output = torch.sigmoid(output)\n",
    "            all_loss_list.append(loss.item())\n",
    "            output = output.detach().cpu().numpy()\n",
    "            pred_probs.extend(output)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "#             print('pred probs:- ', output)\n",
    "#             print('true labels:- ', label_batch)\n",
    "\n",
    "            self.optimiser.step()\n",
    "#             self.lr_scheduler.step()\n",
    "            self.optimiser.zero_grad()\n",
    "        \n",
    "#         print('pred labels', pred_probs[0:3])\n",
    "\n",
    "        scores = OrderedDict()\n",
    "        scores = calculate_eval_metrics(ids, true_labels, pred_probs, self.multilabel)\n",
    "        scores[\"loss\"] = np.mean(all_loss_list).item()\n",
    "\n",
    "        progress_bar.refresh(True)\n",
    "        progress_bar.clear(True)\n",
    "        progress_bar.close()\n",
    "#         print('lr {}'.format(self.optimiser.param_groups[0]['lr']))\n",
    "        print('loss:- ', scores['loss'], '  micro auc:- ', scores['micro_auc'], '  macro auc:- ', scores['macro_auc'])\n",
    "        return scores\n",
    "\n",
    "    @staticmethod\n",
    "    def format_number(number):\n",
    "        return abs(round(number, ndigits=ndigits))\n",
    "\n",
    "    def train(self, n_epoch: int = 100):\n",
    "        evaluator = Evaluator(self.model, self.vocab, self.criterions, self.n_training_labels)\n",
    "        for e in range(self.start_epoch + 1, n_epoch + 1):\n",
    "            train_scores = self.train_single_epoch(e)\n",
    "            valid_scores = evaluator.evaluate(self.valid_dataloader)\n",
    "            print('loss:- ', valid_scores['loss'], '  micro auc:- ', valid_scores['micro_auc'], '  macro auc:- ', valid_scores['macro_auc'])\n",
    "        test_scores = evaluator.evaluate(self.test_dataloader)\n",
    "        return self.model, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "ee0e163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_model(train_data, valid_data, test_data, vocab, saved_data_file_path=None,checkpoint_path=None):\n",
    "    model = Model(vocab)\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset, valid_dataset, test_dataset = _load_and_cache_data(train_data, valid_data, test_data,\n",
    "                                                                      vocab, saved_data_file_path)\n",
    "    train_dataloader = TextDataLoader(dataset=train_dataset, vocab=vocab, batch_size=BATCH_SIZE)\n",
    "\n",
    "    valid_dataloader = TextDataLoader(dataset=valid_dataset, vocab=vocab, batch_size=BATCH_SIZE)\n",
    "\n",
    "    test_dataloader = TextDataLoader(dataset=test_dataset, vocab=vocab, batch_size=BATCH_SIZE)\n",
    "\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "    \n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=50)\n",
    "    \n",
    "    criterions = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(8))\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      valid_dataloader=valid_dataloader,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      criterions=criterions,\n",
    "                      optimiser=optimiser,\n",
    "#                       lr_scheduler = lr_scheduler,\n",
    "                      vocab=vocab,\n",
    "                      checkpoint_path=checkpoint_path)\n",
    "    best_model, scores = trainer.train(n_epoch=n_epoch)\n",
    "\n",
    "    evaluator = Evaluator(model=best_model,vocab=vocab,criterions=criterions,\n",
    "                          n_training_labels=n_labels)\n",
    "\n",
    "    del model, optimiser, evaluator, trainer, criterions\n",
    "    return best_model, scores  # either on valid or test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "13164513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_validation(training_data, valid_data, test_data, vocab, saved_data_file_path):\n",
    "    best_model, scores = _train_model(\n",
    "        train_data=training_data, valid_data=valid_data, test_data=test_data,\n",
    "        vocab=vocab, saved_data_file_path=saved_data_file_path, checkpoint_path=\"../model/checkpoint.pkl\")\n",
    "\n",
    "    return best_model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "772dacdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722ce17a302a42ab8444244350297b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #1:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  1.0437986511659576   micro auc:-  0.7555552828777765   macro auc:-  0.6759364415867642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa28c60a5bd48289f8b151097966a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  1.0497038609485336   micro auc:-  0.7579472738738303   macro auc:-  0.702332035251362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7467c934db544818244f5e3e2c8b774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #2:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.9490461164588853   micro auc:-  0.8063703768029692   macro auc:-  0.7457704852010147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d42f211f2f24f86a01306c26a386316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.9914112650803503   micro auc:-  0.7923196300124369   macro auc:-  0.7416038644115842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23050ccd080b461392c75dc1339f70be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #3:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8881700705843946   micro auc:-  0.8345866462773253   macro auc:-  0.7835719690079387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac15b28756b4525ab93165c14becfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.9321344240667856   micro auc:-  0.8217467663189092   macro auc:-  0.7715823490246667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1bf37a2ba0430ab91267a09db1960f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #4:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8507122677428753   micro auc:-  0.8500918606789616   macro auc:-  0.8035272594503036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fafe3279dc94f98a62a3302384fa4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.9152444679724988   micro auc:-  0.8297774971333585   macro auc:-  0.7782350710667357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a1c51727bc493aaa278a2cdb820069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #5:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8223903890702841   micro auc:-  0.8614682266374724   macro auc:-  0.8174640703637205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32ae1b074984e51b9d922baa1050e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8995331211138498   micro auc:-  0.8365395961061287   macro auc:-  0.7884102658638118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454a2320e3a7493db59f8b80fcd01b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #6:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.7948914788759381   micro auc:-  0.8715461315777597   macro auc:-  0.8301011631481019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29def6423c743db9b77336f46e1cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8758302327945148   micro auc:-  0.8457305695250587   macro auc:-  0.7978898199523705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb0c7b9b50e4fcdae1524c00a363f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #7:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.771882602699448   micro auc:-  0.8795750677544121   macro auc:-  0.8398253656951934\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5666cc21a0ee41718ee733b9d5749865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8597647767079059   micro auc:-  0.8527670553730985   macro auc:-  0.8037121368909866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f404fb6a8cc44a4b59e3b89d47e08f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #8:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.7465210945684208   micro auc:-  0.8880060589009818   macro auc:-  0.849796260897729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0035650eb1c4cc1968ac229a7b3dcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8499323194704685   micro auc:-  0.8577022547661926   macro auc:-  0.8102031924048593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e96411ba5b644c88a936c7528ee0b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #9:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.7322968448649786   micro auc:-  0.8925773734436255   macro auc:-  0.8557693790228315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b677cb37dd9041698592ca766ffef192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8410736522093643   micro auc:-  0.8608811876100424   macro auc:-  0.8143666786407308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bad9c511fc4c1190d7ba165763243c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training at epoch #10:   0%|          | 0/1009 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.7182304879541558   micro auc:-  0.8968526247422538   macro auc:-  0.8620212517701753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8522088c0dfd454f876da3a35cc3da39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/197 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.8410312176355855   micro auc:-  0.8617473270286682   macro auc:-  0.8167491602115523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdf619fc04347099e3944b295174b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/217 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, test_scores = run_with_validation(training_data, valid_data, test_data, vocab, saved_data_file_path=\"{}.data.pkl\".format(saved_vocab_path.split(\".pkl\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "89879854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro auc:-  0.8621733895126819\n",
      "macro auc:-  0.8143088123516844\n",
      "\n",
      "macro F1:-  0.43694100355330756\n",
      "micro_F1:-  0.4430170575692963\n",
      "\n",
      "P@5:-  0.4875650665124349\n",
      "P@8:-  0.4050751879699248\n",
      "P@15:-  0.2980913823019087\n"
     ]
    }
   ],
   "source": [
    "print('micro auc:- ', test_scores['micro_auc'])\n",
    "print('macro auc:- ', test_scores['macro_auc'])\n",
    "print('\\nmacro F1:- ', test_scores['macro_f1'])\n",
    "print('micro_F1:- ', test_scores['micro_f1'])\n",
    "print('\\nP@5:- ', test_scores['macro_P@5'])\n",
    "print('P@8:- ', test_scores['macro_P@8'])\n",
    "print('P@15:- ', test_scores['macro_P@15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e88dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
